## 指南

抽取结果的质量取决于许多因素。

以下是一组指南，可帮助您从模型中提取最佳性能：

* 将模型温度设置为`0`。
* 改进提示语。提示语应该准确和简洁。
* 记录架构：确保记录架构以向LLM提供更多信息。
* 提供参考示例！多样化的示例将有所帮助，包括不需要抽取任何内容的示例。
* 如果有大量示例，请使用检索器检索最相关的示例。
* 使用最佳的可用LLM/Chat模型（例如gpt-4，claude-3等）进行基准测试--与模型提供者确认最新且最好的模型是哪个！
* 如果架构非常大，请尝试将其分解为多个较小的架构，运行单独的抽取操作并合并结果。
* 确保架构允许模型拒绝提取信息。如果不允许，模型将被迫虚构信息！
* 添加验证/修正步骤（请一个LLM来更正或验证抽取结果）。

## 基准测试

* 使用[LangSmith 🦜️🛠️](https://docs.smith.langchain.com/)为您的用例创建和基准测试数据。
* 您的LLM足够好吗？使用现有数据集使用[langchain-benchmarks 🦜💯 ](https://github.com/langchain-ai/langchain-benchmarks)来测试您的LLM。

## 要记住！ 😶‍🌫️

* LLM非常出色，但并非所有情况都需要使用！如果您从单个结构化来源（例如linkedin）提取信息，使用LLM并不是一个好主意-传统的Web抓取将更便宜和可靠。

* 如果需要**完美质量**，您可能需要计划让一个人参与其中--即使是最好的LLM在处理复杂的抽取任务时也会犯错误。
