# æ£€ç´¢

æ£€ç´¢æ˜¯èŠå¤©æœºå™¨äººåœ¨å…¶è®­ç»ƒæ•°æ®ä¹‹å¤–ä½¿ç”¨æ•°æ®å¢å¼ºå…¶å“åº”çš„å¸¸ç”¨æŠ€æœ¯ã€‚æœ¬èŠ‚å°†ä»‹ç»å¦‚ä½•åœ¨èŠå¤©æœºå™¨äººçš„ä¸Šä¸‹æ–‡ä¸­å®ç°æ£€ç´¢ï¼Œä½†å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ£€ç´¢æ˜¯ä¸€ä¸ªéå¸¸å¾®å¦™å’Œæ·±å…¥çš„ä¸»é¢˜ - æˆ‘ä»¬é¼“åŠ±ä½ æ¢ç´¢[æ–‡æ¡£çš„å…¶ä»–éƒ¨åˆ†](/use_cases/question_answering/)ï¼Œå…¶ä¸­å¯¹æ­¤è¿›è¡Œäº†æ›´æ·±å…¥çš„ä»‹ç»ï¼

## è®¾ç½®

æ‚¨éœ€è¦å®‰è£…ä¸€äº›è½¯ä»¶åŒ…ï¼Œå¹¶å°†æ‚¨çš„OpenAI APIå¯†é’¥è®¾ç½®ä¸ºåä¸º`OPENAI_API_KEY`çš„ç¯å¢ƒå˜é‡ï¼š

```python
ï¼…pip install --upgrade --quiet langchain langchain-openai chromadb beautifulsoup4

ï¼ƒè®¾ç½®ç¯å¢ƒå˜é‡OPENAI_API_KEYæˆ–ä».envæ–‡ä»¶åŠ è½½ï¼š
import dotenv

dotenv.load_dotenv()
```

    [33mè­¦å‘Šï¼šæ‚¨æ­£åœ¨ä½¿ç”¨pipç‰ˆæœ¬22.0.4ï¼› ä½†æ˜¯ï¼Œç‰ˆæœ¬23.3.2å¯ç”¨ã€‚
    æ‚¨åº”è¯¥è€ƒè™‘é€šè¿‡'/ Users / jacoblee / .pyenv / versions / 3.10.5 / bin / python -m pip install --upgrade pip'å‘½ä»¤è¿›è¡Œå‡çº§ã€‚[0m[33m
    [0mæ³¨æ„ï¼šæ‚¨å¯èƒ½éœ€è¦é‡æ–°å¯åŠ¨å†…æ ¸æ‰èƒ½ä½¿ç”¨æ›´æ–°çš„è½¯ä»¶åŒ…ã€‚
    




    True



è®©æˆ‘ä»¬è¿˜è®¾ç½®ä¸€ä¸ªèŠå¤©æ¨¡å‹ï¼Œæˆ‘ä»¬å°†åœ¨ä¸‹é¢çš„ç¤ºä¾‹ä¸­ä½¿ç”¨å®ƒã€‚

```python
from langchain_openai import ChatOpenAI

chat = ChatOpenAI(model="gpt-3.5-turbo-1106", temperature=0.2)
```

## åˆ›å»ºä¸€ä¸ªæ£€ç´¢å™¨

æˆ‘ä»¬å°†ä½¿ç”¨[LangSmithæ–‡æ¡£](https://docs.smith.langchain.com/overview)ä½œä¸ºæºææ–™ï¼Œå¹¶å°†å†…å®¹å­˜å‚¨åœ¨çŸ¢é‡å­˜å‚¨ä¸­ä»¥ä¾›ç¨åæ£€ç´¢ã€‚è¯·æ³¨æ„ï¼Œæ­¤ç¤ºä¾‹å°†å¿½ç•¥æœ‰å…³è§£æå’Œå­˜å‚¨æ•°æ®æºçš„ç‰¹å®šå†…å®¹ - æ‚¨å¯ä»¥åœ¨æ­¤å¤„æŸ¥çœ‹æ›´å¤šæœ‰å…³åˆ›å»ºæ£€ç´¢ç³»ç»Ÿçš„è¯¦ç»†æ–‡æ¡£ã€‚

è®©æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªæ–‡æ¡£åŠ è½½å™¨ä»æ–‡æ¡£ä¸­æå–æ–‡æœ¬ï¼š

```python
from langchain_community.document_loaders import WebBaseLoader

loader = WebBaseLoader("https://docs.smith.langchain.com/overview")
data = loader.load()
```

ç„¶åï¼Œæˆ‘ä»¬å°†å…¶åˆ†å‰²ä¸ºè¾ƒå°çš„å—ï¼ŒLLMçš„ä¸Šä¸‹æ–‡çª—å£å¯ä»¥å¤„ç†ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨çŸ¢é‡æ•°æ®åº“ä¸­ï¼š

```python
from langchain_text_splitters import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)
all_splits = text_splitter.split_documents(data)
```

ç„¶åï¼Œæˆ‘ä»¬åµŒå…¥å¹¶å°†è¿™äº›å—å­˜å‚¨åœ¨çŸ¢é‡æ•°æ®åº“ä¸­ï¼š

```python
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())
```

æœ€åï¼Œè®©æˆ‘ä»¬ä»åˆå§‹åŒ–çš„çŸ¢é‡å­˜å‚¨ä¸­åˆ›å»ºä¸€ä¸ªæ£€ç´¢å™¨ï¼š

```python
# kæ˜¯è¦æ£€ç´¢çš„å—æ•°
retriever = vectorstore.as_retriever(k=4)

docs = retriever.invoke("Can LangSmith help test my LLM applications?")

docs
```

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸Šé¢æ£€ç´¢å™¨çš„è°ƒç”¨ç»“æœï¼Œå…¶ä¸­åŒ…å«ä¸€äº›LangSmithæ–‡æ¡£çš„éƒ¨åˆ†ï¼Œè¿™äº›æ–‡æ¡£åŒ…å«æœ‰å…³æˆ‘ä»¬çš„èŠå¤©æœºå™¨äººå¯ä»¥åœ¨å›ç­”é—®é¢˜æ—¶ä½¿ç”¨çš„æµ‹è¯•ä¿¡æ¯ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬æœ‰äº†ä¸€ä¸ªå¯ä»¥ä»LangSmithæ–‡æ¡£ä¸­è¿”å›ç›¸å…³æ•°æ®çš„æ£€ç´¢å™¨ï¼

## æ–‡æ¡£é“¾

ç°åœ¨æˆ‘ä»¬æœ‰äº†ä¸€ä¸ªå¯ä»¥è¿”å›LangChainæ–‡æ¡£çš„æ£€ç´¢å™¨ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªé“¾ï¼Œå¯ä»¥å°†å®ƒä»¬ä½œä¸ºä¸Šä¸‹æ–‡æ¥å›ç­”é—®é¢˜ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ª`create_stuff_documents_chain`å¸®åŠ©å‡½æ•°æ¥å°†æ‰€æœ‰è¾“å…¥æ–‡æ¡£â€œå¡«å……â€åˆ°æç¤ºä¸­ã€‚å®ƒè¿˜å°†å¤„ç†å°†æ–‡æ¡£æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²ã€‚

é™¤äº†èŠå¤©æ¨¡å‹å¤–ï¼Œè¯¥å‡½æ•°è¿˜æœŸæœ›æœ‰ä¸€ä¸ªå…·æœ‰â€œcontextâ€å˜é‡çš„æç¤ºï¼Œä»¥åŠä¸€ä¸ªåä¸ºâ€œmessagesâ€çš„èŠå¤©å†å²æ¶ˆæ¯çš„å ä½ç¬¦ã€‚æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªåˆé€‚çš„æç¤ºå¹¶å°†å…¶ä¼ é€’å¦‚ä¸‹ï¼š

```python
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

SYSTEM_TEMPLATE = """
æ ¹æ®ä¸‹é¢çš„ä¸Šä¸‹æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ä»»ä½•ä¸é—®é¢˜ç›¸å…³çš„ä¿¡æ¯ï¼Œè¯·ä¸è¦æé€ ä¿¡æ¯ï¼Œåªéœ€è¯´â€œæˆ‘ä¸çŸ¥é“â€ï¼š

<context>
{context}
</context>
"""

question_answering_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            SYSTEM_TEMPLATE,
        ),
        MessagesPlaceholder(variable_name="messages"),
    ]
)

document_chain = create_stuff_documents_chain(chat, question_answering_prompt)
```

æˆ‘ä»¬å¯ä»¥å•ç‹¬è°ƒç”¨æ­¤`document_chain`æ¥å›ç­”é—®é¢˜ã€‚è®©æˆ‘ä»¬ä½¿ç”¨ä¸Šé¢æ£€ç´¢åˆ°çš„æ–‡æ¡£å’Œç›¸åŒçš„é—®é¢˜`å¦‚ä½•ä½¿ç”¨LangSmithè¿›è¡Œæµ‹è¯•ï¼Ÿ`ï¼š

```python
from langchain_core.messages import HumanMessage

document_chain.invoke(
    {
        "context": docs,
        "messages": [
            HumanMessage(content="Can LangSmith help test my LLM applications?")
        ],
    }
)
```

çœ‹èµ·æ¥å¾ˆå¥½ï¼ä¸ºäº†å¯¹æ¯”ï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•æ²¡æœ‰ä¸Šä¸‹æ–‡æ–‡æ¡£å¹¶æ¯”è¾ƒç»“æœï¼š

```python
document_chain.invoke(
    {
        "context": [],
        "messages": [
            HumanMessage(content="Can LangSmith help test my LLM applications?")
        ],
    }
)
```

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°LLMæ²¡æœ‰è¿”å›ä»»ä½•ç»“æœã€‚

## æ£€ç´¢é“¾

è®©æˆ‘ä»¬å°†è¿™ä¸ªæ–‡æ¡£é“¾ä¸æ£€ç´¢å™¨ç»“åˆèµ·æ¥ã€‚ä¸‹é¢æ˜¯è¿™ç§æƒ…å†µä¸‹çš„ä¸€ç§æ–¹å¼ï¼š

```python
from typing import Dict

from langchain_core.runnables import RunnablePassthrough


def parse_retriever_input(params: Dict):
    return params["messages"][-1].content


retrieval_chain = RunnablePassthrough.assign(
    context=parse_retriever_input | retriever,
).assign(
    answer=document_chain,
)
```

ç»™å®šä¸€ä¸ªè¾“å…¥æ¶ˆæ¯åˆ—è¡¨ï¼Œæˆ‘ä»¬æå–åˆ—è¡¨ä¸­æœ€åä¸€æ¡æ¶ˆæ¯çš„å†…å®¹ï¼Œå¹¶å°†å…¶ä¼ é€’ç»™æ£€ç´¢å™¨ä»¥è·å–ä¸€äº›æ–‡æ¡£ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†è¿™äº›æ–‡æ¡£ä½œä¸ºä¸Šä¸‹æ–‡ä¼ é€’ç»™æˆ‘ä»¬çš„æ–‡æ¡£é“¾ï¼Œä»¥ç”Ÿæˆæœ€ç»ˆçš„å“åº”ã€‚

è°ƒç”¨æ­¤é“¾ç»“åˆäº†ä¸Šé¢æ¦‚è¿°çš„ä¸¤ä¸ªæ­¥éª¤ï¼š

```python
retrieval_chain.invoke(
    {
        "messages": [
            HumanMessage(content="Can LangSmith help test my LLM applications?")
        ],
    }
)
```

çœ‹èµ·æ¥å¾ˆå¥½ï¼
=======
## è¿›ä¸€æ­¥é˜…è¯»

æœ¬æŒ‡å—åªæ˜¯æ¶‰åŠåˆ°æ£€ç´¢æŠ€å·§çš„è¡¨é¢çŸ¥è¯†ã€‚å¦‚æœæƒ³äº†è§£æ›´å¤šæœ‰å…³ä¸åŒæ‘„å–ã€å‡†å¤‡å’Œæ£€ç´¢æœ€ç›¸å…³æ•°æ®çš„æ–¹å¼ï¼Œè¯·æŸ¥çœ‹[æ­¤éƒ¨åˆ†](/docs/modules/data_connection/)çš„æ–‡æ¡£ã€‚