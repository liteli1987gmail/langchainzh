# å¿«é€Ÿå…¥é—¨

[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain/blob/master/docs/docs/use_cases/chatbots.ipynb)

## æ¦‚è¿°

æˆ‘ä»¬å°†æ¼”ç¤ºå¦‚ä½•è®¾è®¡å’Œå®ç°ä¸€ä¸ªåŸºäºLLMçš„èŠå¤©æœºå™¨äººçš„ç¤ºä¾‹ã€‚ä¸‹é¢æ˜¯æˆ‘ä»¬å°†ä½¿ç”¨çš„é«˜çº§ç»„ä»¶ï¼š

- `èŠå¤©æ¨¡å‹`ã€‚èŠå¤©æœºå™¨äººçš„ç•Œé¢æ˜¯åŸºäºæ¶ˆæ¯è€Œä¸æ˜¯åŸå§‹æ–‡æœ¬ï¼Œå› æ­¤æœ€é€‚åˆä½¿ç”¨èŠå¤©æ¨¡å‹è€Œä¸æ˜¯æ–‡æœ¬LLMã€‚[è¿™é‡Œ](/docs/integrations/chat)åˆ—å‡ºäº†èŠå¤©æ¨¡å‹çš„é›†æˆåˆ—è¡¨ï¼Œ[è¿™é‡Œ](/modules/model_io/chat)æä¾›äº†å…³äºLangChainä¸­èŠå¤©æ¨¡å‹ç•Œé¢çš„æ–‡æ¡£ã€‚æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨`LLM`ï¼ˆå‚è§[è¿™é‡Œ](/modules/model_io/llms)ï¼‰æ¥åˆ›å»ºèŠå¤©æœºå™¨äººï¼Œä½†èŠå¤©æ¨¡å‹æ›´é€‚åˆå…·æœ‰å¯¹è¯æ€§è´¨å’Œæœ¬åœ°æ”¯æŒæ¶ˆæ¯ç•Œé¢çš„åŠŸèƒ½ã€‚
- `æç¤ºæ¨¡æ¿`ï¼Œç®€åŒ–äº†ç»„è£…æç¤ºçš„è¿‡ç¨‹ï¼Œè¿™äº›æç¤ºç»“åˆäº†é»˜è®¤æ¶ˆæ¯ã€ç”¨æˆ·è¾“å…¥ã€èŠå¤©å†å²è®°å½•å’Œï¼ˆå¯é€‰ï¼‰å…¶ä»–æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ã€‚
- `èŠå¤©å†å²è®°å½•`ï¼Œå…è®¸èŠå¤©æœºå™¨äººâ€œè®°ä½â€è¿‡å»çš„äº¤äº’å¹¶åœ¨å›ç­”åç»­é—®é¢˜æ—¶è€ƒè™‘å®ƒä»¬ã€‚è¯¦ç»†ä¿¡æ¯è¯·å‚é˜…[è¿™é‡Œ](/modules/memory/chat_messages/)ã€‚
- `æ£€ç´¢å™¨`ï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœæ‚¨æƒ³æ„å»ºä¸€ä¸ªå¯ä»¥ä½¿ç”¨ç‰¹å®šé¢†åŸŸçš„æœ€æ–°çŸ¥è¯†ä½œä¸ºä¸Šä¸‹æ–‡æ¥å¢å¼ºå…¶å“åº”çš„èŠå¤©æœºå™¨äººï¼Œè¿™å°†éå¸¸æœ‰ç”¨ã€‚è¯¦ç»†ä¿¡æ¯è¯·å‚é˜…[è¿™é‡Œ](/modules/data_connection/retrievers)ã€‚

æˆ‘ä»¬å°†ä»‹ç»å¦‚ä½•å°†ä¸Šè¿°ç»„ä»¶ç»„åˆåœ¨ä¸€èµ·ï¼Œåˆ›å»ºä¸€ä¸ªå¼ºå¤§çš„å¯¹è¯å‹èŠå¤©æœºå™¨äººã€‚

## å¿«é€Ÿå…¥é—¨

é¦–å…ˆï¼Œè®©æˆ‘ä»¬å®‰è£…ä¸€äº›ä¾èµ–é¡¹å¹¶è®¾ç½®æ‰€éœ€çš„å‡­æ®ï¼š


```python
%pip install --upgrade --quiet langchain langchain-openai

# è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY æˆ–ä» .env æ–‡ä»¶ä¸­åŠ è½½ï¼š
import dotenv

dotenv.load_dotenv()
```

    [33mWARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.
    You should consider upgrading via the '/Users/jacoblee/.pyenv/versions/3.10.5/bin/python -m pip install --upgrade pip' command.[0m[33m
    [0mNote: you may need to restart the kernel to use updated packages.
    




    True



è®©æˆ‘ä»¬åˆå§‹åŒ–èŠå¤©æ¨¡å‹ï¼Œå®ƒå°†ä½œä¸ºèŠå¤©æœºå™¨äººçš„æ ¸å¿ƒï¼š


```python
from langchain_openai import ChatOpenAI

chat = ChatOpenAI(model="gpt-3.5-turbo-1106", temperature=0.2)
```

å¦‚æœè°ƒç”¨èŠå¤©æ¨¡å‹ï¼Œè¾“å‡ºå°†æ˜¯ä¸€ä¸ª `AIMessage`ï¼š


```python
from langchain_core.messages import HumanMessage

chat.invoke(
    [
        HumanMessage(
            content="Translate this sentence from English to French: I love programming."
        )
    ]
)
```




    AIMessage(content="J'adore programmer.")



æ¨¡å‹æœ¬èº«æ²¡æœ‰ä»»ä½•çŠ¶æ€çš„æ¦‚å¿µã€‚ ä¾‹å¦‚ï¼Œå¦‚æœä½ é—®ä¸€ä¸ªåç»­é—®é¢˜ï¼š


```python
chat.invoke([HumanMessage(content="What did you just say?")])
```




    AIMessage(content='I said, "What did you just say?"')



æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å®ƒæ²¡æœ‰æŠŠä¹‹å‰çš„å¯¹è¯è½¬æ¢ä¸ºä¸Šä¸‹æ–‡ï¼Œå¹¶ä¸”æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦å°†æ•´ä¸ªå¯¹è¯å†å²è®°å½•ä¼ é€’ç»™æ¨¡å‹ã€‚è®©æˆ‘ä»¬çœ‹çœ‹å½“æˆ‘ä»¬è¿™æ ·åšæ—¶ä¼šå‘ç”Ÿä»€ä¹ˆï¼š


```python
from langchain_core.messages import AIMessage

chat.invoke(
    [
        HumanMessage(
            content="Translate this sentence from English to French: I love programming."
        ),
        AIMessage(content="J'adore la programmation."),
        HumanMessage(content="What did you just say?"),
    ]
)
```




    AIMessage(content='I said "J\'adore la programmation," which means "I love programming" in French.')



ç°åœ¨æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªå¾ˆå¥½çš„å›ç­”ï¼

è¿™æ˜¯èŠå¤©æœºå™¨äººè¿›è¡Œå¯¹è¯äº¤äº’çš„åŸºæœ¬æ€æƒ³ã€‚

## æç¤ºæ¨¡æ¿

è®©æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªæç¤ºæ¨¡æ¿ï¼Œä»¥ä½¿æ ¼å¼åŒ–æ›´å®¹æ˜“ä¸€äº›ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡å°†å…¶å¯¼å…¥æ¨¡å‹æ¥åˆ›å»ºä¸€ä¸ªé“¾å¼ç»“æ„ï¼š


```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a helpful assistant. Answer all questions to the best of your ability.",
        ),
        MessagesPlaceholder(variable_name="messages"),
    ]
)

chain = prompt | chat
```

ä¸Šé¢çš„ `MessagesPlaceholder` å°†èŠå¤©æ¶ˆæ¯ä½œä¸º `chat_history` ç›´æ¥æ’å…¥é“¾å¼ç»“æ„çš„è¾“å…¥ä¸­ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·è°ƒç”¨é“¾å¼ç»“æ„ï¼š


```python
chain.invoke(
    {
        "messages": [
            HumanMessage(
                content="Translate this sentence from English to French: I love programming."
            ),
            AIMessage(content="J'adore la programmation."),
            HumanMessage(content="What did you just say?"),
        ],
    }
)
```




    AIMessage(content='I said "J\'adore la programmation," which means "I love programming" in French.')



## æ¶ˆæ¯å†å²è®°å½•

ä½œä¸ºç®¡ç†èŠå¤©å†å²è®°å½•çš„å¿«æ·æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ [`MessageHistory`](/modules/memory/chat_messages/) ç±»ï¼Œå®ƒè´Ÿè´£ä¿å­˜å’ŒåŠ è½½èŠå¤©æ¶ˆæ¯ã€‚æœ‰è®¸å¤šå†…ç½®çš„æ¶ˆæ¯å†å²è®°å½•é›†æˆï¼Œå¯ä»¥å°†æ¶ˆæ¯æŒä¹…åŒ–åˆ°å„ç§æ•°æ®åº“ä¸­ï¼Œä½†æ˜¯åœ¨è¿™ä¸ªå¿«é€Ÿå…¥é—¨ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªå†…å­˜ä¸­çš„ç¤ºä¾‹æ¶ˆæ¯å†å²è®°å½• `ChatMessageHistory`ã€‚

ä»¥ä¸‹æ˜¯ç›´æ¥ä½¿ç”¨å®ƒçš„ç¤ºä¾‹ï¼š


```python
from langchain.memory import ChatMessageHistory

demo_ephemeral_chat_history = ChatMessageHistory()

demo_ephemeral_chat_history.add_user_message("hi!")

demo_ephemeral_chat_history.add_ai_message("whats up?")

demo_ephemeral_chat_history.messages
```




    [HumanMessage(content='hi!'), AIMessage(content='whats up?')]



ä¸€æ—¦æˆ‘ä»¬è¿™æ ·åšï¼Œæˆ‘ä»¬å¯ä»¥å°†å­˜å‚¨çš„æ¶ˆæ¯ç›´æ¥ä½œä¸ºå‚æ•°ä¼ é€’ç»™æˆ‘ä»¬çš„é“¾å¼ç»“æ„ï¼š


```python
demo_ephemeral_chat_history.add_user_message(
    "Translate this sentence from English to French: I love programming."
)

response = chain.invoke({"messages": demo_ephemeral_chat_history.messages})

response
```




    AIMessage(content='The translation of "I love programming" in French is "J\'adore la programmation."')




```python
demo_ephemeral_chat_history.add_ai_message(response)

demo_ephemeral_chat_history.add_user_message("What did you just say?")

chain.invoke({"messages": demo_ephemeral_chat_history.messages})
```




    AIMessage(content='I said "J\'adore la programmation," which is the French translation for "I love programming."')



ç°åœ¨æˆ‘ä»¬æœ‰äº†ä¸€ä¸ªåŸºæœ¬çš„èŠå¤©æœºå™¨äººï¼

è™½ç„¶è¿™ä¸ªé“¾å¼ç»“æ„å¯ä»¥ä½œä¸ºä¸€ä¸ªç‹¬ç«‹çš„èŠå¤©æœºå™¨äººå¹¶å…·æœ‰æ¨¡å‹çš„å†…éƒ¨çŸ¥è¯†ï¼Œä½†é€šå¸¸ä¼šæœ‰ç”¨çš„æ˜¯å¼•å…¥ä¸€äº›å½¢å¼çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆretrieval-augmented generationï¼Œç®€ç§°RAGï¼‰ä»¥ä¾¿äºèšç„¦äºé¢†åŸŸç‰¹å®šçŸ¥è¯†ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬å°†ä»‹ç»è¿™ä¸ªå†…å®¹ã€‚


## Retrievers

æˆ‘ä»¬å¯ä»¥è®¾ç½®å¹¶ä½¿ç”¨ [`Retriever`](/modules/data_connection/retrievers/) æ¥ä¸ºæˆ‘ä»¬çš„èŠå¤©æœºå™¨äººæä¾›é¢†åŸŸç‰¹å®šçš„çŸ¥è¯†ã€‚ä¸ºäº†å±•ç¤ºè¿™ä¸€ç‚¹ï¼Œè®©æˆ‘ä»¬æ‰©å±•ä¸Šé¢åˆ›å»ºçš„ç®€å•èŠå¤©æœºå™¨äººï¼Œä»¥ä¾¿èƒ½å¤Ÿå›ç­”æœ‰å…³ LangSmith çš„é—®é¢˜ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨ [LangSmith æ–‡æ¡£](https://docs.smith.langchain.com/overview) ä½œä¸ºæºææ–™ï¼Œå¹¶å°†å…¶å­˜å‚¨åˆ° vectorstore ä»¥ä¾›ä»¥åæ£€ç´¢ã€‚è¯·æ³¨æ„ï¼Œæ­¤ç¤ºä¾‹å°†å¿½ç•¥å›´ç»•è§£æå’Œå­˜å‚¨æ•°æ®æºçš„ä¸€äº›ç»†èŠ‚ - æ‚¨å¯ä»¥åœ¨æ­¤å¤„æŸ¥çœ‹æ›´è¯¦ç»†çš„[å…³äºåˆ›å»ºæ£€ç´¢ç³»ç»Ÿçš„æ–‡æ¡£](/use_cases/question_answering/)ã€‚

è®©æˆ‘ä»¬è®¾ç½®æˆ‘ä»¬çš„æ£€ç´¢å™¨ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†å®‰è£…ä¸€äº›å¿…éœ€çš„ä¾èµ–é¡¹ï¼š

```python
%pip install --upgrade --quiet chromadb beautifulsoup4
```

ç„¶åï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªæ–‡æ¡£åŠ è½½å™¨ä»ç½‘é¡µä¸­æå–æ•°æ®ï¼š

```python
from langchain_community.document_loaders import WebBaseLoader

loader = WebBaseLoader("https://docs.smith.langchain.com/overview")
data = loader.load()
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å®ƒåˆ†æˆæ›´å°çš„å—ï¼Œä»¥ä¾¿ LLM çš„ä¸Šä¸‹æ–‡çª—å£å¯ä»¥å¤„ç†ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨å‘é‡æ•°æ®åº“ä¸­ï¼š

```python
from langchain_text_splitters import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)
all_splits = text_splitter.split_documents(data)
```

ç„¶åï¼Œæˆ‘ä»¬å°†è¿™äº›å—è¿›è¡ŒåµŒå…¥å¹¶å­˜å‚¨åœ¨å‘é‡æ•°æ®åº“ä¸­ï¼š

```python
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())
```

æœ€åï¼Œè®©æˆ‘ä»¬ä»åˆå§‹åŒ–çš„å‘é‡æ•°æ®åº“åˆ›å»ºä¸€ä¸ªæ£€ç´¢å™¨ï¼š

```python
# k æ˜¯è¦æ£€ç´¢çš„å—æ•°
retriever = vectorstore.as_retriever(k=4)

docs = retriever.invoke("how can langsmith help with testing?")

docs
```

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œè°ƒç”¨ä¸Šé¢çš„æ£€ç´¢å™¨ä¼šè¿”å›ä¸€äº›åŒ…å«æœ‰å…³æµ‹è¯•çš„ä¿¡æ¯çš„ LangSmith æ–‡æ¡£éƒ¨åˆ†ï¼Œæˆ‘ä»¬çš„èŠå¤©æœºå™¨äººå¯ä»¥åœ¨å›ç­”é—®é¢˜æ—¶ä½¿ç”¨å®ƒä»¬ä½œä¸ºä¸Šä¸‹æ–‡ã€‚

## å¤„ç†æ–‡æ¡£

è®©æˆ‘ä»¬ä¿®æ”¹ä¸Šä¸€ä¸ªæç¤ºï¼Œä»¥æ¥å—æ–‡æ¡£ä½œä¸ºä¸Šä¸‹æ–‡ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ [`create_stuff_documents_chain`](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html#langchain.chains.combine_documents.stuff.create_stuff_documents_chain) è¾…åŠ©å‡½æ•°å°†æ‰€æœ‰è¾“å…¥æ–‡æ¡£â€œstuffâ€åˆ°æç¤ºä¸­ï¼Œè¯¥å‡½æ•°è¿˜æ–¹ä¾¿åœ°å¤„ç†æ ¼å¼ã€‚æˆ‘ä»¬ä½¿ç”¨ [`ChatPromptTemplate.from_messages`](/modules/model_io/prompts/quick_start#chatprompttemplate) æ–¹æ³•æ¥æ ¼å¼åŒ–æˆ‘ä»¬è¦ä¼ é€’ç»™æ¨¡å‹çš„æ¶ˆæ¯è¾“å…¥ï¼ŒåŒ…æ‹¬ä¸€ä¸ª [`MessagesPlaceholder`](/modules/model_io/prompts/quick_start#messagesplaceholder)ï¼Œå…¶ä¸­èŠå¤©å†å²æ¶ˆæ¯å°†ç›´æ¥æ³¨å…¥ï¼š

```python
from langchain.chains.combine_documents import create_stuff_documents_chain

chat = ChatOpenAI(model="gpt-3.5-turbo-1106")

question_answering_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "Answer the user's questions based on the below context:\n\n{context}",
        ),
        MessagesPlaceholder(variable_name="messages"),
    ]
)

document_chain = create_stuff_documents_chain(chat, question_answering_prompt)
```

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸Šé¢æ£€ç´¢åˆ°çš„åŸå§‹æ–‡æ¡£æ¥è°ƒç”¨è¿™ä¸ª `document_chain`ï¼š

```python
from langchain.memory import ChatMessageHistory

demo_ephemeral_chat_history = ChatMessageHistory()

demo_ephemeral_chat_history.add_user_message("how can langsmith help with testing?")

document_chain.invoke(
    {
        "messages": demo_ephemeral_chat_history.messages,
        "context": docs,
    }
)
```

å¤ªæ£’äº†ï¼æˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªä»è¾“å…¥æ–‡æ¡£ä¸­åˆæˆçš„ç­”æ¡ˆã€‚

## åˆ›å»ºä¸€ä¸ªæ£€ç´¢é“¾

æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬å°†æˆ‘ä»¬çš„æ£€ç´¢å™¨é›†æˆåˆ°é“¾ä¸­ã€‚æˆ‘ä»¬çš„æ£€ç´¢å™¨åº”è¯¥æ£€ç´¢ä¸æˆ‘ä»¬ä»ç”¨æˆ·ä¼ é€’çš„æœ€åä¸€æ¡æ¶ˆæ¯ç›¸å…³çš„ä¿¡æ¯ï¼Œå› æ­¤æˆ‘ä»¬æå–å®ƒå¹¶å°†å…¶ç”¨ä½œè·å–ç›¸å…³æ–‡æ¡£çš„è¾“å…¥ï¼Œç„¶åå°†å…¶ä½œä¸º `ä¸Šä¸‹æ–‡` æ·»åŠ åˆ°å½“å‰é“¾ä¸­ã€‚æˆ‘ä»¬å°† `ä¸Šä¸‹æ–‡` åŠ ä¸Šå…ˆå‰çš„ `messages` ä¼ é€’åˆ°æˆ‘ä»¬çš„æ–‡æ¡£é“¾ä¸­ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚

æˆ‘ä»¬è¿˜ä½¿ç”¨ [`RunnablePassthrough.assign()`](/expression_language/primitives/assign) æ–¹æ³•åœ¨æ¯æ¬¡è°ƒç”¨æ—¶ä¼ é€’ä¸­é—´æ­¥éª¤ã€‚è¿™æ˜¯å®ƒçš„æ ·å­ï¼š

```python
from typing import Dict

from langchain_core.runnables import RunnablePassthrough


def parse_retriever_input(params: Dict):
    return params["messages"][-1].content


retrieval_chain = RunnablePassthrough.assign(
    context=parse_retriever_input | retriever,
).assign(
    answer=document_chain,
)
```

```python
response = retrieval_chain.invoke(
    {
        "messages": demo_ephemeral_chat_history.messages,
    }
)

response
```

ä¸é”™ï¼æˆ‘ä»¬çš„èŠå¤©æœºå™¨äººç°åœ¨å¯ä»¥ä»¥å¯¹è¯æ–¹å¼å›ç­”é¢†åŸŸç‰¹å®šçš„é—®é¢˜ã€‚

é¡ºä¾¿è¯´ä¸€ä¸‹ï¼Œå¦‚æœæ‚¨ä¸æƒ³è¿”å›æ‰€æœ‰ä¸­é—´æ­¥éª¤ï¼Œå¯ä»¥åƒè¿™æ ·ä½¿ç”¨ `pipe` ç›´æ¥è¿›å…¥æ–‡æ¡£é“¾è€Œä¸æ˜¯æœ€åçš„ `.assign()` è°ƒç”¨æ¥å®šä¹‰æ‚¨çš„æ£€ç´¢é“¾ï¼š

```python
retrieval_chain_with_only_answer = (
    RunnablePassthrough.assign(
        context=parse_retriever_input | retriever,
    )
    | document_chain
)

retrieval_chain_with_only_answer.invoke(
    {
        "messages": demo_ephemeral_chat_history.messages,
    },
)
```

```python
demo_ephemeral_chat_history.add_ai_message(response["answer"])

demo_ephemeral_chat_history.add_user_message("tell me more about that!")

retrieval_chain.invoke(
    {
        "messages": demo_ephemeral_chat_history.messages,
    },
)
```

æ¼‚äº®ï¼æˆ‘ä»¬çš„èŠå¤©æœºå™¨äººç°åœ¨å¯ä»¥ä»¥å¯¹è¯æ–¹å¼å›ç­”é¢†åŸŸç‰¹å®šçš„é—®é¢˜ã€‚



## æŸ¥è¯¢è½¬æ¢

åœ¨ä¸Šé¢çš„ç¤ºä¾‹ä¸­ï¼Œå½“æˆ‘ä»¬è¯¢é—®äº†ä¸€ä¸ªè·Ÿè¿›é—®é¢˜â€œtell me more about that!â€æ—¶ï¼Œä½ å¯èƒ½ä¼šæ³¨æ„åˆ°æ£€ç´¢åˆ°çš„æ–‡æ¡£å¹¶æ²¡æœ‰ç›´æ¥åŒ…å«æœ‰å…³æµ‹è¯•çš„ä¿¡æ¯ã€‚è¿™æ˜¯å› ä¸ºæˆ‘ä»¬å°†â€œtell me more about that!â€åŸå°ä¸åŠ¨åœ°ä½œä¸ºæŸ¥è¯¢ä¼ é€’ç»™äº†æ£€ç´¢å™¨ã€‚æ£€ç´¢é“¾ä¸­çš„è¾“å‡ºä»ç„¶å¯ä»¥æ­£å¸¸å·¥ä½œï¼Œå› ä¸ºæ–‡æ¡£é“¾æ£€ç´¢é“¾å¯ä»¥æ ¹æ®èŠå¤©å†å²ç”Ÿæˆç­”æ¡ˆï¼Œä½†æ˜¯æˆ‘ä»¬å¯ä»¥è·å–æ›´å¤šä¸°å¯Œå’Œæœ‰ä¿¡æ¯çš„æ–‡æ¡£ï¼š

```python
retriever.invoke("how can langsmith help with testing?")
```

```python
retriever.invoke("tell me more about that!")
```

ä¸ºäº†è§£å†³è¿™ä¸ªå¸¸è§é—®é¢˜ï¼Œè®©æˆ‘ä»¬æ·»åŠ ä¸€ä¸ªâ€œæŸ¥è¯¢è½¬æ¢â€æ­¥éª¤ï¼Œä»¥åˆ é™¤è¾“å…¥ä¸­çš„å¼•ç”¨ã€‚æˆ‘ä»¬å°†å¯¹æˆ‘ä»¬çš„æ—§æ£€ç´¢å™¨è¿›è¡Œå¦‚ä¸‹å°è£…ï¼š

```python
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableBranch

# æˆ‘ä»¬éœ€è¦ä¸€ä¸ªæç¤ºï¼Œå°†å…¶ä¼ é€’ç»™LLMä»¥ç”Ÿæˆè½¬æ¢åçš„æœç´¢æŸ¥è¯¢

chat = ChatOpenAI(model="gpt-3.5-turbo-1106", temperature=0.2)

query_transform_prompt = ChatPromptTemplate.from_messages(
    [
        MessagesPlaceholder(variable_name="messages"),
        (
            "user",
            "æ ¹æ®ä¸Šé¢çš„å¯¹è¯ï¼Œç”Ÿæˆä¸€ä¸ªæœç´¢æŸ¥è¯¢ä»¥è·å–ä¸å¯¹è¯ç›¸å…³çš„ä¿¡æ¯ã€‚åªå›ç­”æŸ¥è¯¢ï¼Œä¸è¦æä¾›å…¶ä»–å†…å®¹ã€‚",
        ),
    ]
)

query_transforming_retriever_chain = RunnableBranch(
    (
        lambda x: len(x.get("messages", [])) == 1,
        # å¦‚æœåªæœ‰ä¸€æ¡ä¿¡æ¯ï¼Œåˆ™ç›´æ¥å°†è¯¥ä¿¡æ¯çš„å†…å®¹ä¼ é€’ç»™æ£€ç´¢å™¨
        (lambda x: x["messages"][-1].content) | retriever,
    ),
    # å¦‚æœæœ‰å¤šæ¡ä¿¡æ¯ï¼Œåˆ™å°†è¾“å…¥ä¼ é€’ç»™LLMé“¾ä»¥è½¬æ¢æŸ¥è¯¢ï¼Œç„¶åå†ä¼ é€’ç»™æ£€ç´¢å™¨
    query_transform_prompt | chat | StrOutputParser() | retriever,
).with_config(run_name="chat_retriever_chain")
```

ç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªæ–°çš„`query_transforming_retriever_chain`é‡æ–°åˆ›å»ºæˆ‘ä»¬ä¹‹å‰çš„é“¾ã€‚æ³¨æ„ï¼Œè¿™ä¸ªæ–°çš„é“¾æ¥å—ä¸€ä¸ªå­—å…¸ä½œä¸ºè¾“å…¥ï¼Œå¹¶è§£æä¸€ä¸ªå­—ç¬¦ä¸²ä»¥ä¼ é€’ç»™æ£€ç´¢å™¨ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸éœ€è¦åœ¨é¡¶å±‚è¿›è¡Œé¢å¤–çš„è§£æï¼š

```python
document_chain = create_stuff_documents_chain(chat, question_answering_prompt)

conversational_retrieval_chain = RunnablePassthrough.assign(
    context=query_transforming_retriever_chain,
).assign(
    answer=document_chain,
)

demo_ephemeral_chat_history = ChatMessageHistory()
```

æœ€åï¼Œè®©æˆ‘ä»¬æ¥è°ƒç”¨å®ƒï¼š

```python
demo_ephemeral_chat_history.add_user_message("how can langsmith help with testing?")

response = conversational_retrieval_chain.invoke(
    {"messages": demo_ephemeral_chat_history.messages},
)

demo_ephemeral_chat_history.add_ai_message(response["answer"])

response
```

```python
demo_ephemeral_chat_history.add_user_message("tell me more about that!")

conversational_retrieval_chain.invoke(
    {"messages": demo_ephemeral_chat_history.messages}
)
```

ç°åœ¨ï¼Œä½ çŸ¥é“å¦‚ä½•æ„å»ºä¸€ä¸ªå¯ä»¥å°†è¿‡å»çš„æ¶ˆæ¯å’Œé¢†åŸŸç‰¹å®šçš„çŸ¥è¯†é›†æˆåˆ°å…¶ç”Ÿæˆä¸­çš„å¯¹è¯èŠå¤©æœºå™¨äººã€‚åœ¨è¿™æ–¹é¢ï¼Œä½ è¿˜å¯ä»¥è¿›è¡Œè®¸å¤šå…¶ä»–ä¼˜åŒ–â€”â€”åœ¨ä»¥ä¸‹é¡µé¢ä¸ŠæŸ¥çœ‹æ›´å¤šä¿¡æ¯ï¼š

- [å†…å­˜ç®¡ç†](/use_cases/chatbots/memory_management)ï¼šè¿™åŒ…æ‹¬è‡ªåŠ¨æ›´æ–°èŠå¤©å†å²è®°å½•çš„æŒ‡å—ï¼Œä»¥åŠä¿®å‰ªã€æ±‡æ€»æˆ–ä»¥å…¶ä»–æ–¹å¼ä¿®æ”¹é•¿å¯¹è¯ä»¥ä¿æŒæœºå™¨äººçš„ä¸“æ³¨æ€§ã€‚
- [æ£€ç´¢](/use_cases/chatbots/retrieval)ï¼šæ·±å…¥ä»‹ç»å¦‚ä½•åœ¨èŠå¤©æœºå™¨äººä¸­ä½¿ç”¨ä¸åŒç±»å‹çš„æ£€ç´¢ã€‚
- [å·¥å…·ä½¿ç”¨](/use_cases/chatbots/tool_usage)ï¼šå¦‚ä½•è®©ä½ çš„èŠå¤©æœºå™¨äººä½¿ç”¨ä¸å…¶ä»–APIå’Œç³»ç»Ÿäº¤äº’çš„å·¥å…·ã€‚


---
title: å¿«é€Ÿå…¥é—¨
sidebar_position: 0
---

åœ¨è¿™ä¸ªå¿«é€Ÿå…¥é—¨ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨èƒ½å¤Ÿä»æ–‡æœ¬ä¸­æå–ä¿¡æ¯çš„[èŠå¤©æ¨¡å‹](/modules/model_io/chat/)æ¥è¿›è¡Œ**å‡½æ•°/å·¥å…·è°ƒç”¨**ã€‚

:::âš âš âš 


åªæœ‰åœ¨æ”¯æŒ**å‡½æ•°/å·¥å…·è°ƒç”¨**çš„[æ¨¡å‹](/modules/model_io/chat/function_calling)ä¸Šæ‰èƒ½ä½¿ç”¨**å‡½æ•°/å·¥å…·è°ƒç”¨**è¿›è¡Œæå–ã€‚
:::

## è®¾ç½®

æˆ‘ä»¬å°†ä½¿ç”¨èƒ½å¤Ÿè¿›è¡Œ**å‡½æ•°/å·¥å…·è°ƒç”¨**çš„LLMä¸Šå¯ç”¨çš„[ç»“æ„åŒ–è¾“å‡º](/modules/model_io/chat/structured_output)æ–¹æ³•ã€‚

é€‰æ‹©ä¸€ä¸ªæ¨¡å‹ï¼Œå®‰è£…ç›¸å…³ä¾èµ–å¹¶è®¾ç½®APIå¯†é’¥ï¼

```python
ï¼pip install langchain

ï¼ƒå®‰è£…èƒ½å¤Ÿè¿›è¡Œå·¥å…·è°ƒç”¨çš„æ¨¡å‹
ï¼ƒpip å®‰è£… langchain-openai
ï¼ƒpip å®‰è£… langchain-mistralai
ï¼ƒpip å®‰è£… langchain-fireworks

ï¼ƒä¸ºç›¸å…³æ¨¡å‹è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œæˆ–ä».envæ–‡ä»¶ä¸­åŠ è½½ï¼š
ï¼ƒå¯¼å…¥dotenv
ï¼ƒdotenv.load_dotenv()
```

## æ¨¡å¼

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦æè¿°æˆ‘ä»¬æƒ³è¦ä»æ–‡æœ¬ä¸­æå–çš„ä¿¡æ¯ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨Pydanticå®šä¹‰ä¸€ä¸ªç¤ºä¾‹æ¨¡å¼æ¥æå–ä¸ªäººä¿¡æ¯ã€‚

```python
from typing import Optional

from langchain_core.pydantic_v1 import BaseModel, Field


class Person(BaseModel):
    """å…³äºä¸ªäººçš„ä¿¡æ¯ã€‚"""

    # ^ å®ä½“Personçš„æ–‡æ¡£å­—ç¬¦ä¸²ã€‚
    # æ­¤æ–‡æ¡£å­—ç¬¦ä¸²å°†ä½œä¸ºæ¨¡å¼Personçš„æè¿°å‘é€ç»™LLMï¼Œ
    # å®ƒå¯ä»¥å¸®åŠ©æé«˜æå–ç»“æœã€‚

    # è¯·æ³¨æ„ï¼š
    # 1. æ¯ä¸ªå­—æ®µéƒ½æ˜¯`optional` â€”â€” è¿™å…è®¸æ¨¡å‹åœ¨æ‹’ç»æå–æ—¶è¿”å›`None`ï¼
    # 2. æ¯ä¸ªå­—æ®µéƒ½æœ‰ä¸€ä¸ª`description` â€”â€” è¿™ä¸ªæè¿°ç”±LLMä½¿ç”¨ã€‚
    # æœ‰ä¸€ä¸ªè‰¯å¥½çš„æè¿°å¯ä»¥å¸®åŠ©æé«˜æå–ç»“æœã€‚
    name: Optional[str] = Field(..., description="å§“å")
    hair_color: Optional[str] = Field(
        ..., description="å¦‚æœå·²çŸ¥ï¼Œè¿™æ˜¯äººçš„å¤´å‘é¢œè‰²"
    )
    height_in_meters: Optional[str] = Field(
        ..., description="ä»¥ç±³ä¸ºå•ä½çš„èº«é«˜"
    )
```

åœ¨å®šä¹‰æ¨¡å¼æ—¶æœ‰ä¸¤ä¸ªæœ€ä½³å®è·µï¼š

1. è®°å½•**å±æ€§**å’Œ**æ¨¡å¼**æœ¬èº«ï¼šè¿™äº›ä¿¡æ¯å°†è¢«å‘é€ç»™LLMï¼Œç”¨äºæé«˜æå–ä¿¡æ¯çš„è´¨é‡ã€‚
2. ä¸è¦å¼ºè¿«LLMè™šæ„ä¿¡æ¯ï¼ä»¥ä¸Šï¼Œæˆ‘ä»¬å¯¹å±æ€§ä½¿ç”¨äº†`Optional`ï¼Œå…è®¸LLMåœ¨ä¸çŸ¥é“ç­”æ¡ˆæ—¶è¾“å‡º`None`ã€‚

:::âš âš âš 


ä¸ºäº†è·å¾—æœ€ä½³æ€§èƒ½ï¼Œå¥½å¥½è®°å½•æ¨¡å¼å¹¶ç¡®ä¿æ¨¡å‹ä¸ä¼šåœ¨æ²¡æœ‰æ–‡æœ¬ä¸­æå–ä¿¡æ¯çš„æƒ…å†µä¸‹è¿”å›ç»“æœã€‚
:::

## æå–å™¨

è®©æˆ‘ä»¬ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„æ¨¡å¼åˆ›å»ºä¸€ä¸ªä¿¡æ¯æå–å™¨ã€‚

```python
from typing import Optional

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_openai import ChatOpenAI

# å®šä¹‰ä¸€ä¸ªè‡ªå®šä¹‰æç¤ºï¼Œæä¾›æŒ‡ç¤ºå’Œä»»ä½•é¢å¤–çš„ä¸Šä¸‹æ–‡ã€‚
# 1ï¼‰æ‚¨å¯ä»¥åœ¨æç¤ºæ¨¡æ¿ä¸­æ·»åŠ ç¤ºä¾‹ä»¥æé«˜æå–è´¨é‡
# 2ï¼‰å¼•å…¥å…¶ä»–å‚æ•°ä»¥è€ƒè™‘ä¸Šä¸‹æ–‡ï¼ˆä¾‹å¦‚ï¼ŒåŒ…æ‹¬ä»ä¸­æå–æ–‡æœ¬çš„æ–‡æ¡£çš„å…ƒæ•°æ®ç­‰ï¼‰ã€‚
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "æ‚¨æ˜¯ä¸€ç§ä¸“å®¶æå–ç®—æ³•ã€‚ä»…ä»æ–‡æœ¬ä¸­æå–ç›¸å…³ä¿¡æ¯ã€‚"
            "å¦‚æœæ‚¨ä¸çŸ¥é“è¦æå–çš„å±æ€§çš„å€¼ï¼Œè¯·è¿”å›å±æ€§çš„å€¼ä¸ºnullã€‚",
        ),
        # æœ‰å…³é€šè¿‡å‚è€ƒç¤ºä¾‹æé«˜æ€§èƒ½çš„è¯´æ˜ï¼Œè¯·å‚è§ how-to
        # MessagesPlaceholder('examples'),
        ("human", "{text}"),
    ]
)
```

æˆ‘ä»¬éœ€è¦ä½¿ç”¨æ”¯æŒå‡½æ•°/å·¥å…·è°ƒç”¨çš„æ¨¡å‹ã€‚

è¯·æŸ¥é˜…[ç»“æ„åŒ–è¾“å‡º](/modules/model_io/chat/structured_output)ä»¥è·å–å¯ä¸æ­¤APIä¸€èµ·ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨ã€‚

```python
from langchain_mistralai import ChatMistralAI

llm = ChatMistralAI(model="mistral-large-latest", temperature=0)

runnable = prompt | llm.with_structured_output(schema=Person)
```

è®©æˆ‘ä»¬æ¥æµ‹è¯•ä¸€ä¸‹

```python
text = "è‰¾ä¼¦Â·å²å¯†æ–¯èº«é«˜6è‹±å°ºï¼Œå¤´å‘æ˜¯é‡‘é»„è‰²ã€‚"
runnable.invoke({"text": text})
```

::::

    Person(name='è‰¾ä¼¦Â·å²å¯†æ–¯', hair_color='é‡‘é»„è‰²', height_in_meters='1.8288')

:::âš âš âš 

 

æå–æ˜¯ç”Ÿæˆå¼çš„ ğŸ¤¯

LLMæ˜¯ç”Ÿæˆæ¨¡å‹ï¼Œå› æ­¤å®ƒä»¬å¯ä»¥æ‰§è¡Œä¸€äº›å¾ˆé…·çš„äº‹æƒ…ï¼Œæ¯”å¦‚å³ä½¿æä¾›çš„æ˜¯è‹±å°ºï¼Œä¹Ÿèƒ½æ­£ç¡®æå–å‡ºä»¥ç±³ä¸ºå•ä½çš„äººç‰©èº«é«˜ï¼

:::

## å¤šä¸ªå®ä½“

åœ¨**å¤§å¤šæ•°æƒ…å†µ**ä¸‹ï¼Œæ‚¨åº”è¯¥æå–ä¸€ä¸ªå®ä½“çš„åˆ—è¡¨ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå•ç‹¬çš„å®ä½“ã€‚

è¿™å¯ä»¥é€šè¿‡åœ¨å½¼æ­¤ä¹‹é—´åµŒå¥—æ¨¡å‹æ¥è½»æ¾å®ç°ã€‚

```python
from typing import List, Optional

from langchain_core.pydantic_v1 import BaseModel, Field


class Person(BaseModel):
    """å…³äºä¸ªäººçš„ä¿¡æ¯ã€‚"""

    # ^ å®ä½“Personçš„æ–‡æ¡£å­—ç¬¦ä¸²ã€‚
    # æ­¤æ–‡æ¡£å­—ç¬¦ä¸²å°†ä½œä¸ºæ¨¡å¼Personçš„æè¿°å‘é€ç»™LLMï¼Œ
    # å®ƒå¯ä»¥å¸®åŠ©æé«˜æå–ç»“æœã€‚

    # è¯·æ³¨æ„ï¼š
    # 1. æ¯ä¸ªå­—æ®µéƒ½æ˜¯`optional` â€”â€” è¿™å…è®¸æ¨¡å‹åœ¨æ‹’ç»æå–æ—¶è¿”å›`None`ï¼
    # 2. æ¯ä¸ªå­—æ®µéƒ½æœ‰ä¸€ä¸ª`description` â€”â€” è¿™ä¸ªæè¿°ç”±LLMä½¿ç”¨ã€‚
    # æœ‰ä¸€ä¸ªè‰¯å¥½çš„æè¿°å¯ä»¥å¸®åŠ©æé«˜æå–ç»“æœã€‚
    name: Optional[str] = Field(..., description="å§“å")
    hair_color: Optional[str] = Field(
        ..., description="å¦‚æœå·²çŸ¥ï¼Œè¿™æ˜¯äººçš„å¤´å‘é¢œè‰²"
    )
    height_in_meters: Optional[str] = Field(
        ..., description="ä»¥ç±³ä¸ºå•ä½çš„èº«é«˜"
    )


class Data(BaseModel):
    """å…³äºäººçš„æå–æ•°æ®ã€‚"""

    # åˆ›å»ºä¸€ä¸ªæ¨¡å‹ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥æå–å¤šä¸ªå®ä½“ã€‚
    people: List[Person]
```

:::âš âš âš 


æå–å¯èƒ½ä¸å®Œç¾ã€‚è¯·ç»§ç»­é˜…è¯»å¦‚ä½•ä½¿ç”¨**å‚è€ƒç¤ºä¾‹**æ¥æé«˜æå–è´¨é‡ï¼Œä»¥åŠæŸ¥çœ‹**æŒ‡å—**éƒ¨åˆ†ï¼
:::

```python
runnable = prompt | llm.with_structured_output(schema=Data)
text = "æˆ‘çš„åå­—æ˜¯æ°å¤«ï¼Œæˆ‘çš„å¤´å‘æ˜¯é»‘è‰²çš„ï¼Œæˆ‘çš„èº«é«˜æ˜¯6è‹±å°ºã€‚å®‰å¨œçš„å¤´å‘é¢œè‰²å’Œæˆ‘ä¸€æ ·ã€‚"
runnable.invoke({"text": text})
```

::::

    Data(people=[Person(name='æ°å¤«', hair_color=None, height_in_meters=None), Person(name='å®‰å¨œ', hair_color=None, height_in_meters=None)])

:::âš âš âš 



å½“æ¨¡å¼é€‚åº”æå–**å¤šä¸ªå®ä½“**æ—¶ï¼Œå¦‚æœæ–‡æœ¬ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œå®ƒè¿˜å…è®¸æ¨¡å‹æå–**æ— å®ä½“**ï¼Œä»è€Œæä¾›ä¸€ä¸ªç©ºåˆ—è¡¨ã€‚

è¿™é€šå¸¸æ˜¯ä¸€ä¸ª**å¥½äº‹**ï¼å®ƒå…è®¸ä¸ºå®ä½“æŒ‡å®š**å¿…éœ€**å±æ€§ï¼Œè€Œä¸ä¸€å®šè¦å¼ºè¿«æ¨¡å‹æ£€æµ‹åˆ°æ­¤å®ä½“ã€‚

:::

------
## ä¸‹ä¸€æ­¥

ç°åœ¨ä½ å·²ç»äº†è§£äº†ä½¿ç”¨LangChainè¿›è¡Œæå–çš„åŸºç¡€çŸ¥è¯†ï¼Œä½ å¯ä»¥ç»§ç»­é˜…è¯»å…¶ä»–çš„æ“ä½œæŒ‡å—ï¼š

- [æ·»åŠ ç¤ºä¾‹](/use_cases/extraction/how_to/examples): å­¦ä¹ å¦‚ä½•ä½¿ç”¨**å‚è€ƒç¤ºä¾‹**æ¥æ”¹è¿›æ€§èƒ½ã€‚
- [å¤„ç†é•¿æ–‡æœ¬](/use_cases/extraction/how_to/handle_long_text): å¦‚æœæ–‡æœ¬è¶…å‡ºLLMçš„ä¸Šä¸‹æ–‡çª—å£æ€ä¹ˆåŠï¼Ÿ
- [å¤„ç†æ–‡ä»¶](/use_cases/extraction/how_to/handle_files): ä½¿ç”¨LangChainæ–‡æ¡£åŠ è½½å™¨å’Œè§£æå™¨ä»æ–‡ä»¶ï¼ˆå¦‚PDFï¼‰ä¸­æå–çš„ç¤ºä¾‹ã€‚
- [ä½¿ç”¨è§£ææ–¹æ³•](/use_cases/extraction/how_to/parse): ä½¿ç”¨åŸºäºæç¤ºçš„æ–¹æ³•æ¥æå–ä¸æ”¯æŒ**å·¥å…·/å‡½æ•°è°ƒç”¨**çš„æ¨¡å‹ã€‚
- [æŒ‡å—](/use_cases/extraction/guidelines): è·å–æå–ä»»åŠ¡çš„è‰¯å¥½æ€§èƒ½çš„æŒ‡å—ã€‚# Quickstart

åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»åˆ›å»ºå›¾æ•°æ®åº“ä¸Šçš„é—®ç­”é“¾çš„åŸºæœ¬æ–¹æ³•ã€‚è¿™äº›ç³»ç»Ÿå°†ä½¿æˆ‘ä»¬èƒ½å¤Ÿå¯¹å›¾æ•°æ®åº“ä¸­çš„æ•°æ®æå‡ºé—®é¢˜ï¼Œå¹¶å¾—åˆ°è‡ªç„¶è¯­è¨€å›ç­”ã€‚

## âš ï¸ å®‰å…¨æç¤º âš ï¸

æ„å»ºå›¾æ•°æ®åº“çš„é—®ç­”ç³»ç»Ÿéœ€è¦æ‰§è¡Œæ¨¡å‹ç”Ÿæˆçš„å›¾æŸ¥è¯¢ã€‚è¿™æ ·åšå­˜åœ¨å›ºæœ‰çš„é£é™©ã€‚ç¡®ä¿æ‚¨çš„æ•°æ®åº“è¿æ¥æƒé™å§‹ç»ˆå°½å¯èƒ½åœ°é€‚ç”¨äºé“¾è·¯/ä»£ç†çš„éœ€æ±‚ã€‚è¿™å°†å‡è½»å»ºç«‹æ¨¡å‹é©±åŠ¨ç³»ç»Ÿçš„é£é™©ï¼Œä½†å¹¶ä¸èƒ½å®Œå…¨æ¶ˆé™¤ã€‚æœ‰å…³ä¸€èˆ¬å®‰å…¨æ€§æœ€ä½³å®è·µï¼Œè¯·å‚é˜…[è¿™é‡Œ](/docs/security)ã€‚

## æ¶æ„

ä»é«˜å±‚æ¥çœ‹ï¼Œå¤§å¤šæ•°å›¾é“¾çš„æ­¥éª¤å¦‚ä¸‹ï¼š

1. **å°†é—®é¢˜è½¬æ¢ä¸ºå›¾æ•°æ®åº“æŸ¥è¯¢**ï¼šæ¨¡å‹å°†ç”¨æˆ·è¾“å…¥è½¬æ¢ä¸ºå›¾æ•°æ®åº“æŸ¥è¯¢ï¼ˆä¾‹å¦‚Cypherï¼‰ã€‚
2. **æ‰§è¡Œå›¾æ•°æ®åº“æŸ¥è¯¢**ï¼šæ‰§è¡Œå›¾æ•°æ®åº“æŸ¥è¯¢ã€‚
3. **å›ç­”é—®é¢˜**ï¼šæ¨¡å‹ä½¿ç”¨æŸ¥è¯¢ç»“æœå›ç­”ç”¨æˆ·çš„è¾“å…¥ã€‚

![sql_usecase.png](/img/graph_usecase.png)

## è®¾ç½®

é¦–å…ˆï¼Œè·å–æ‰€éœ€çš„è½¯ä»¶åŒ…å¹¶è®¾ç½®ç¯å¢ƒå˜é‡ã€‚
åœ¨æœ¬ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Neo4jå›¾æ•°æ®åº“ã€‚

```python
%pip install --upgrade --quiet  langchain langchain-community langchain-openai neo4j
```

åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬é»˜è®¤ä½¿ç”¨OpenAIæ¨¡å‹ã€‚

```python
import getpass
import os

os.environ["OPENAI_API_KEY"] = getpass.getpass()

# å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šä»¥ä½¿ç”¨LangSmithã€‚ä¸æ˜¯å¿…éœ€çš„ã€‚
# os.environ["LANGCHAIN_API_KEY"] = getpass.getpass()
# os.environ["LANGCHAIN_TRACING_V2"] = "true"
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰Neo4jå‡­æ®ã€‚
æŒ‰ç…§[å®‰è£…æ­¥éª¤](https://neo4j.com/docs/operations-manual/current/installation/)è®¾ç½®Neo4jæ•°æ®åº“ã€‚

```python
os.environ["NEO4J_URI"] = "bolt://localhost:7687"
os.environ["NEO4J_USERNAME"] = "neo4j"
os.environ["NEO4J_PASSWORD"] = "password"
```

ä»¥ä¸‹ç¤ºä¾‹å°†åˆ›å»ºä¸Neo4jæ•°æ®åº“çš„è¿æ¥ï¼Œå¹¶ä½¿ç”¨å…³äºç”µå½±åŠå…¶æ¼”å‘˜çš„ç¤ºä¾‹æ•°æ®å¡«å……å®ƒã€‚

```python
from langchain_community.graphs import Neo4jGraph

graph = Neo4jGraph()

# å¯¼å…¥ç”µå½±ä¿¡æ¯

movies_query = """
LOAD CSV WITH HEADERS FROM 
'https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/movies/movies_small.csv'
AS row
MERGE (m:Movie {id:row.movieId})
SET m.released = date(row.released),
    m.title = row.title,
    m.imdbRating = toFloat(row.imdbRating)
FOREACH (director in split(row.director, '|') | 
    MERGE (p:Person {name:trim(director)})
    MERGE (p)-[:DIRECTED]->(m))
FOREACH (actor in split(row.actors, '|') | 
    MERGE (p:Person {name:trim(actor)})
    MERGE (p)-[:ACTED_IN]->(m))
FOREACH (genre in split(row.genres, '|') | 
    MERGE (g:Genre {name:trim(genre)})
    MERGE (m)-[:IN_GENRE]->(g))
"""

graph.query(movies_query)
```

## å›¾æ¨¡å¼

ä¸ºäº†ä½¿LLMèƒ½å¤Ÿç”ŸæˆCypherè¯­å¥ï¼Œå®ƒéœ€è¦æœ‰å…³å›¾æ¨¡å¼ä¿¡æ¯ã€‚å½“æ‚¨å®ä¾‹åŒ–å›¾å¯¹è±¡æ—¶ï¼Œå®ƒä¼šæ£€ç´¢æœ‰å…³å›¾æ¨¡å¼çš„ä¿¡æ¯ã€‚å¦‚æœæ‚¨ç¨åå¯¹å›¾è¿›è¡Œä»»ä½•æ›´æ”¹ï¼Œåˆ™å¯ä»¥è¿è¡Œ`refresh_schema`æ–¹æ³•æ¥åˆ·æ–°æ¨¡å¼ä¿¡æ¯ã€‚

```python
graph.refresh_schema()
print(graph.schema)
```

èŠ‚ç‚¹å±æ€§å¦‚ä¸‹æ‰€ç¤ºï¼š
```
Movie {imdbRating: FLOAT, id: STRING, released: DATE, title: STRING},Person {name: STRING},Genre {name: STRING},Chunk {id: STRING, question: STRING, query: STRING, text: STRING, embedding: LIST}
```

å…³ç³»å±æ€§å¦‚ä¸‹æ‰€ç¤ºï¼š


```
(:Movie)-[:IN_GENRE]->(:Genre),(:Person)-[:DIRECTED]->(:Movie),(:Person)-[:ACTED_IN]->(:Movie)
```

å¤ªæ£’äº†ï¼æˆ‘ä»¬æœ‰äº†ä¸€ä¸ªå¯æŸ¥è¯¢çš„å›¾æ•°æ®åº“ã€‚ç°åœ¨è®©æˆ‘ä»¬å°è¯•å°†å…¶ä¸LLMè¿æ¥èµ·æ¥ã€‚

## Chain

è®©æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„é“¾ï¼Œå°†é—®é¢˜è½¬æ¢ä¸ºCypheræŸ¥è¯¢ï¼Œæ‰§è¡ŒæŸ¥è¯¢ï¼Œå¹¶ä½¿ç”¨ç»“æœå›ç­”åŸå§‹é—®é¢˜ã€‚

LangChainé™„å¸¦äº†ä¸€ä¸ªå†…ç½®é“¾ï¼Œç”¨äºæ­¤å·¥ä½œæµç¨‹ï¼Œè¯¥é“¾è®¾è®¡ç”¨äºä¸Neo4jä¸€èµ·ä½¿ç”¨ï¼š[GraphCypherQAChain](/docs/integrations/graphs/neo4j_cypher)

```python
from langchain.chains import GraphCypherQAChain
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
chain = GraphCypherQAChain.from_llm(graph=graph, llm=llm, verbose=True)
response = chain.invoke({"query": "What was the cast of the Casino?"})
response
```

```
[1m> Entering new GraphCypherQAChain chain...[0m
Generated Cypher:
[32;1m[1;3mMATCH (:Movie {title: "Casino"})<-[:ACTED_IN]-(actor:Person)
RETURN actor.name[0m
Full Context:
[32;1m[1;3m[{'actor.name': 'Joe Pesci'}, {'actor.name': 'Robert De Niro'}, {'actor.name': 'Sharon Stone'}, {'actor.name': 'James Woods'}][0m

[1m> Finished chain.[0m
```

```
{'query': 'What was the cast of the Casino?',
 'result': 'The cast of Casino included Joe Pesci, Robert De Niro, Sharon Stone, and James Woods.'}
```

# éªŒè¯å…³ç³»æ–¹å‘

LLMå¾ˆéš¾å¤„ç†ç”Ÿæˆçš„Cypherè¯­å¥ä¸­çš„å…³ç³»æ–¹å‘ã€‚ç”±äºå›¾æ¨¡å¼æ˜¯é¢„å®šä¹‰çš„ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`validate_cypher`å‚æ•°æ¥éªŒè¯å’Œå¯é€‰ä¿®å¤ç”Ÿæˆçš„Cypherè¯­å¥ä¸­çš„å…³ç³»æ–¹å‘ã€‚

```python
chain = GraphCypherQAChain.from_llm(
    graph=graph, llm=llm, verbose=True, validate_cypher=True
)
response = chain.invoke({"query": "What was the cast of the Casino?"})
response
```

```
[1m> Entering new GraphCypherQAChain chain...[0m
Generated Cypher:
[32;1m[1;3mMATCH (:Movie {title: "Casino"})<-[:ACTED_IN]-(actor:Person)
RETURN actor.name[0m
Full Context:
[32;1m[1;3m[{'actor.name': 'Joe Pesci'}, {'actor.name': 'Robert De Niro'}, {'actor.name': 'Sharon Stone'}, {'actor.name': 'James Woods'}][0m

[1m> Finished chain.[0m
```

```
{'query': 'What was the cast of the Casino?',
 'result': 'The cast of Casino included Joe Pesci, Robert De Niro, Sharon Stone, and James Woods.'}
```

### ä¸‹ä¸€æ­¥

å¯¹äºæ›´å¤æ‚çš„æŸ¥è¯¢ç”Ÿæˆï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›åˆ›å»ºfew-shot promptsæˆ–æ·»åŠ æŸ¥è¯¢æ£€æŸ¥æ­¥éª¤ã€‚æœ‰å…³è¿™äº›é«˜çº§æŠ€æœ¯å’Œæ›´å¤šæŠ€æœ¯ï¼Œè¯·æŸ¥çœ‹ä»¥ä¸‹é“¾æ¥ï¼š

* [Prompting strategies](/use_cases/graph/prompting)ï¼šé«˜çº§æç¤ºå·¥ç¨‹æŠ€æœ¯ã€‚
* [Mapping values](/use_cases/graph/mapping)ï¼šå°†é—®é¢˜ä¸­çš„å€¼æ˜ å°„åˆ°æ•°æ®åº“çš„æŠ€æœ¯ã€‚
* [Semantic layer](/use_cases/graph/semantic)ï¼šå®ç°è¯­ä¹‰å±‚çš„æŠ€æœ¯ã€‚
* [Constructing graphs](/use_cases/graph/constructing)ï¼šæ„å»ºçŸ¥è¯†å›¾è°±çš„æŠ€æœ¯ã€‚

---


# å¿«é€Ÿå…¥é—¨

è¿™ä¸ªé¡µé¢å°†å±•ç¤ºå¦‚ä½•åœ¨ä¸€ä¸ªåŸºæœ¬çš„ç«¯åˆ°ç«¯ç¤ºä¾‹ä¸­ä½¿ç”¨æŸ¥è¯¢åˆ†æã€‚è¿™å°†æ¶µç›–åˆ›å»ºä¸€ä¸ªç®€å•çš„æœç´¢å¼•æ“ï¼Œå±•ç¤ºå°†åŸå§‹ç”¨æˆ·é—®é¢˜ä¼ é€’ç»™æœç´¢å¼•æ“æ—¶å‡ºç°çš„æ•…éšœæ¨¡å¼ï¼Œä»¥åŠä½¿ç”¨æŸ¥è¯¢åˆ†ææ¥è§£å†³è¿™ä¸ªé—®é¢˜çš„ç¤ºä¾‹ã€‚æœ‰è®¸å¤šä¸åŒçš„æŸ¥è¯¢åˆ†ææŠ€æœ¯ï¼Œè¿™ä¸ªç«¯åˆ°ç«¯ç¤ºä¾‹å¹¶ä¸ä¼šå±•ç¤ºæ‰€æœ‰çš„æŠ€æœ¯ã€‚

ä¸ºäº†è¿™ä¸ªç¤ºä¾‹ï¼Œæˆ‘ä»¬å°†åœ¨LangChainçš„YouTubeè§†é¢‘ä¸Šè¿›è¡Œæ£€ç´¢ã€‚

## è®¾ç½®
#### å®‰è£…ä¾èµ–é¡¹


```python
# %pip install -qU langchain langchain-community langchain-openai youtube-transcript-api pytube chromadb
```

#### è®¾ç½®ç¯å¢ƒå˜é‡

æˆ‘ä»¬å°†åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ä½¿ç”¨OpenAIï¼š

```python
import getpass
import os

os.environ["OPENAI_API_KEY"] = getpass.getpass()

# å¯é€‰çš„ï¼Œå–æ¶ˆæ³¨é‡Šä»¥ä½¿ç”¨LangSmithè·Ÿè¸ªè¿è¡Œç»“æœã€‚åœ¨æ­¤æ³¨å†Œï¼šhttps://smith.langchain.comã€‚
# os.environ["LANGCHAIN_TRACING_V2"] = "true"
# os.environ["LANGCHAIN_API_KEY"] = getpass.getpass()
```

### åŠ è½½æ–‡æ¡£

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`YouTubeLoader`æ¥åŠ è½½ä¸€äº›LangChainè§†é¢‘çš„è½¬å½•æ–‡æœ¬ï¼š

```python
from langchain_community.document_loaders import YoutubeLoader

urls = [
    "https://www.youtube.com/watch?v=HAn9vnJy6S4",
    "https://www.youtube.com/watch?v=dA1cHGACXCo",
    "https://www.youtube.com/watch?v=ZcEMLz27sL4",
    "https://www.youtube.com/watch?v=hvAPnpSfSGo",
    "https://www.youtube.com/watch?v=EhlPDL4QrWY",
    "https://www.youtube.com/watch?v=mmBo8nlu2j0",
    "https://www.youtube.com/watch?v=rQdibOsL1ps",
    "https://www.youtube.com/watch?v=28lC4fqukoc",
    "https://www.youtube.com/watch?v=es-9MgxB-uc",
    "https://www.youtube.com/watch?v=wLRHwKuKvOE",
    "https://www.youtube.com/watch?v=ObIltMaRJvY",
    "https://www.youtube.com/watch?v=DjuXACWYkkU",
    "https://www.youtube.com/watch?v=o7C9ld6Ln-M",
]
docs = []
for url in urls:
    docs.extend(YoutubeLoader.from_youtube_url(url, add_video_info=True).load())
```

```python
import datetime

# æ·»åŠ ä¸€äº›é¢å¤–çš„å…ƒæ•°æ®ï¼šè§†é¢‘çš„å‘å¸ƒå¹´ä»½
for doc in docs:
    doc.metadata["publish_year"] = int(
        datetime.datetime.strptime(
            doc.metadata["publish_date"], "%Y-%m-%d %H:%M:%S"
        ).strftime("%Y")
    )
```

è¿™æ˜¯æˆ‘ä»¬åŠ è½½çš„è§†é¢‘çš„æ ‡é¢˜ï¼š

```python
[doc.metadata["title"] for doc in docs]
```

è¿™æ˜¯æ¯ä¸ªè§†é¢‘çš„å…ƒæ•°æ®ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¯ä¸ªæ–‡æ¡£è¿˜æœ‰ä¸€ä¸ªæ ‡é¢˜ã€è§‚çœ‹æ¬¡æ•°ã€å‘å¸ƒæ—¥æœŸå’Œé•¿åº¦ï¼š

```python
docs[0].metadata
```

è¿™æ˜¯ä¸€ä¸ªæ–‡æ¡£å†…å®¹çš„ç¤ºä¾‹ï¼š

```python
docs[0].page_content[:500]
```

### å¯¹æ–‡æ¡£è¿›è¡Œç´¢å¼•

æ¯å½“æˆ‘ä»¬è¿›è¡Œæ£€ç´¢æ—¶ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªæ–‡æ¡£ç´¢å¼•ï¼Œä»¥ä¾›æˆ‘ä»¬æŸ¥è¯¢ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªå‘é‡å­˜å‚¨æ¥ç´¢å¼•æˆ‘ä»¬çš„æ–‡æ¡£ï¼Œå¹¶ä¸”æˆ‘ä»¬å°†é¦–å…ˆå¯¹å®ƒä»¬è¿›è¡Œåˆ†å—ï¼Œä»¥ä½¿æˆ‘ä»¬çš„æ£€ç´¢æ›´ç®€æ´å’Œå‡†ç¡®ï¼š

```python
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)
chunked_docs = text_splitter.split_documents(docs)
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
vectorstore = Chroma.from_documents(
    chunked_docs,
    embeddings,
)
```

## æ— æŸ¥è¯¢åˆ†æçš„æ£€ç´¢

æˆ‘ä»¬å¯ä»¥ç›´æ¥å¯¹ç”¨æˆ·é—®é¢˜è¿›è¡Œç›¸ä¼¼æ€§æœç´¢ï¼Œä»¥æ‰¾åˆ°ä¸é—®é¢˜ç›¸å…³çš„æ–‡æœ¬å—ï¼š

```python
search_results = vectorstore.similarity_search("how do I build a RAG agent")
print(search_results[0].metadata["title"])
print(search_results[0].page_content[:500])
```

è¿™æ•ˆæœä¸é”™ï¼æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªç»“æœä¸é—®é¢˜ç›¸å½“ç›¸å…³ã€‚

å¦‚æœæˆ‘ä»¬æƒ³è¦æœç´¢ç‰¹å®šæ—¶é—´æ®µå†…çš„ç»“æœå‘¢ï¼Ÿ

```python
search_results = vectorstore.similarity_search("videos on RAG published in 2023")
print(search_results[0].metadata["title"])
print(search_results[0].metadata["publish_date"])
print(search_results[0].page_content[:500])
```

æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªç»“æœæ¥è‡ª2024å¹´ï¼ˆå°½ç®¡æˆ‘ä»¬è¦æ±‚æœç´¢2023å¹´çš„è§†é¢‘ï¼‰ï¼Œä¸è¾“å…¥å†…å®¹ä¸ç›¸å…³ã€‚ç”±äºæˆ‘ä»¬åªæ˜¯æœç´¢æ–‡æ¡£å†…å®¹ï¼Œç»“æœæ— æ³•æ ¹æ®ä»»ä½•æ–‡æ¡£å±æ€§è¿›è¡Œè¿‡æ»¤ã€‚

è¿™åªæ˜¯å¯èƒ½å‡ºç°çš„ä¸€ç§æ•…éšœæ¨¡å¼ã€‚ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä½¿ç”¨åŸºæœ¬çš„æŸ¥è¯¢åˆ†ææ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼

## æŸ¥è¯¢åˆ†æ

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æŸ¥è¯¢åˆ†ææ¥æ”¹è¿›æ£€ç´¢ç»“æœã€‚è¿™å°†æ¶‰åŠå®šä¹‰ä¸€ä¸ª**æŸ¥è¯¢æ¨¡å¼**ï¼Œå…¶ä¸­åŒ…å«ä¸€äº›æ—¥æœŸè¿‡æ»¤å™¨ï¼Œå¹¶ä½¿ç”¨å‡½æ•°è°ƒç”¨æ¨¡å‹å°†ç”¨æˆ·é—®é¢˜è½¬æ¢ä¸ºç»“æ„åŒ–æŸ¥è¯¢ã€‚

### æŸ¥è¯¢æ¨¡å¼
åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†ä¸ºå‘å¸ƒæ—¥æœŸè®¾å®šæ˜¾å¼çš„æœ€å°å’Œæœ€å¤§å±æ€§ï¼Œä»¥ä¾¿å¯ä»¥è¿›è¡Œè¿‡æ»¤ã€‚

```python
from typing import Optional

from langchain_core.pydantic_v1 import BaseModel, Field


class Search(BaseModel):
    """Search over a database of tutorial videos about a software library."""

    query: str = Field(
        ...,
        description="Similarity search query applied to video transcripts.",
    )
    publish_year: Optional[int] = Field(None, description="Year video was published")
```


### æŸ¥è¯¢ç”Ÿæˆ

ä¸ºäº†å°†ç”¨æˆ·çš„é—®é¢˜è½¬æ¢ä¸ºç»“æ„åŒ–æŸ¥è¯¢ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨OpenAIçš„å·¥å…·è°ƒç”¨APIã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ–°çš„[ChatModel.with_structured_output()](/modules/model_io/chat/structured_output)æ„é€ å‡½æ•°æ¥å¤„ç†å°†æ¨¡å¼ä¼ é€’ç»™æ¨¡å‹å¹¶è§£æè¾“å‡ºç»“æœã€‚

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI

system = """ä½ æ˜¯å°†ç”¨æˆ·é—®é¢˜è½¬æ¢ä¸ºæ•°æ®åº“æŸ¥è¯¢çš„ä¸“å®¶ã€‚ä½ å¯ä»¥è®¿é—®ä¸€ä¸ªå…³äºæ„å»ºåŸºäºLLMåº”ç”¨ç¨‹åºçš„è½¯ä»¶åº“çš„æ•™ç¨‹è§†é¢‘æ•°æ®åº“ã€‚ç»™å®šä¸€ä¸ªé—®é¢˜ï¼Œè¿”å›ä¸€ç³»åˆ—ä¼˜åŒ–æ£€ç´¢æœ€ç›¸å…³ç»“æœçš„æ•°æ®åº“æŸ¥è¯¢ã€‚

å¦‚æœæœ‰ç¼©ç•¥è¯æˆ–ä½ ä¸ç†Ÿæ‚‰çš„è¯è¯­ï¼Œè¯·ä¸è¦å°è¯•æ›´æ”¹å®ƒä»¬çš„æªè¾ã€‚"""
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system),
        ("human", "{question}"),
    ]
)
llm = ChatOpenAI(model="gpt-3.5-turbo-0125", temperature=0)
structured_llm = llm.with_structured_output(Search)
query_analyzer = {"question": RunnablePassthrough()} | prompt | structured_llm
```

    /Users/bagatur/langchain/libs/core/langchain_core/_api/beta_decorator.py:86: LangChainBetaWarning: The function `with_structured_output` is in beta. It is actively being worked on, so the API may change.
      warn_beta(
    
    
è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬çš„åˆ†æå™¨ä¸ºæˆ‘ä»¬ä¹‹å‰æœç´¢çš„é—®é¢˜ç”Ÿæˆäº†å“ªäº›æŸ¥è¯¢ï¼š

```python
query_analyzer.invoke("æˆ‘å¦‚ä½•æ„å»ºRAGä»£ç†")
```

æœç´¢ç»“æœè¾“å‡ºä¸ºï¼š

```python
Search(query='æ„å»º RAG ä»£ç†', publish_year=None)
```

```python
query_analyzer.invoke("2023å¹´å‘è¡¨çš„RAGè§†é¢‘")
```

æœç´¢ç»“æœè¾“å‡ºä¸ºï¼š

```python
Search(query='RAG', publish_year=2023)
```

## ä½¿ç”¨æŸ¥è¯¢åˆ†æè¿›è¡Œæ£€ç´¢

æˆ‘ä»¬çš„æŸ¥è¯¢åˆ†æçœ‹èµ·æ¥å¾ˆä¸é”™ï¼Œç°åœ¨è®©æˆ‘ä»¬å°è¯•ä½¿ç”¨ç”Ÿæˆçš„æŸ¥è¯¢æ¥è¿›è¡Œå®é™…çš„æ£€ç´¢ã€‚

**æ³¨æ„ï¼š**åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬æŒ‡å®šäº†`tool_choice="Search"`ã€‚è¿™å°†å¼ºåˆ¶LLMè°ƒç”¨ä¸€ä¸ª - ä¸”ä»…è°ƒç”¨ä¸€ä¸ª - å·¥å…·ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬å°†å§‹ç»ˆæœ‰ä¸€ä¸ªä¼˜åŒ–çš„æŸ¥è¯¢å¯ä¾›æŸ¥æ‰¾ã€‚è¯·æ³¨æ„ï¼Œè¿™å¹¶ä¸æ€»æ˜¯é€‚ç”¨çš„æƒ…å†µ - è¯·å‚é˜…å…¶ä»–æŒ‡å—ï¼Œäº†è§£åœ¨æ²¡æœ‰æˆ–æœ‰å¤šä¸ªä¼˜åŒ–æŸ¥è¯¢è¿”å›æ—¶å¦‚ä½•å¤„ç†ã€‚

```python
from typing import List

from langchain_core.documents import Document
```

```python
def retrieval(search: Search) -> List[Document]:
    if search.publish_year is not None:
        # è¿™æ˜¯ç‰¹å®šäºChromaçš„è¯­æ³•ï¼Œ
        # æˆ‘ä»¬ä½¿ç”¨çš„å‘é‡æ•°æ®åº“ã€‚
        _filter = {"publish_year": {"$eq": search.publish_year}}
    else:
        _filter = None
    return vectorstore.similarity_search(search.query, filter=_filter)
```

```python
retrieval_chain = query_analyzer | retrieval
```

æˆ‘ä»¬ç°åœ¨å¯ä»¥åœ¨ä¹‹å‰å‡ºç°é—®é¢˜çš„è¾“å…¥ä¸Šè¿è¡Œè¿™ä¸ªé“¾å¼æµç¨‹ï¼Œå¹¶çœ‹åˆ°å®ƒåªè¿”å›äº†é‚£ä¸€å¹´çš„ç»“æœï¼

```python
results = retrieval_chain.invoke("2023å¹´å‘è¡¨çš„RAGæ•™ç¨‹")
```

```python
[(doc.metadata["title"], doc.metadata["publish_date"]) for doc in results]
```

è¾“å‡ºç»“æœä¸ºï¼š

```python
[('å…¥é—¨å¤šæ¨¡LLM', '2023-12-20 00:00:00'),
 ('LangServeå’ŒLangChainæ¨¡æ¿ç½‘ç»œç ”è®¨ä¼š', '2023-11-02 00:00:00'),
 ('å…¥é—¨å¤šæ¨¡LLM', '2023-12-20 00:00:00'),
 ('ä»é›¶å¼€å§‹æ„å»ºç ”ç©¶åŠ©æ‰‹', '2023-11-16 00:00:00')]
```
------



# å¿«é€Ÿå…¥é—¨

LangChainæ‹¥æœ‰å¤šä¸ªç»„ä»¶ï¼Œæ—¨åœ¨å¸®åŠ©æ„å»ºé—®ç­”åº”ç”¨ç¨‹åºå’ŒRAGåº”ç”¨ç¨‹åºã€‚ä¸ºäº†ç†Ÿæ‚‰è¿™äº›ç»„ä»¶ï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªç®€å•çš„é—®ç­”åº”ç”¨ç¨‹åºï¼Œä½¿ç”¨æ–‡æœ¬æ•°æ®æºã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»å…¸å‹çš„é—®ç­”æ¶æ„ï¼Œè®¨è®ºç›¸å…³çš„LangChainç»„ä»¶ï¼Œå¹¶æä¾›æ›´é«˜çº§çš„é—®ç­”æŠ€æœ¯çš„å…¶ä»–èµ„æºã€‚æˆ‘ä»¬è¿˜å°†äº†è§£LangSmithå¦‚ä½•å¸®åŠ©æˆ‘ä»¬è·Ÿè¸ªå’Œç†è§£æˆ‘ä»¬çš„åº”ç”¨ç¨‹åºã€‚éšç€åº”ç”¨ç¨‹åºçš„å¤æ‚æ€§å¢åŠ ï¼ŒLangSmithå°†å˜å¾—è¶Šæ¥è¶Šæœ‰ç”¨ã€‚

## æ¶æ„

æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªå…¸å‹çš„RAGåº”ç”¨ç¨‹åºï¼Œå¦‚[é—®ç­”ä»‹ç»](/use_cases/question_answering/)ä¸­æ‰€è¿°ï¼Œå®ƒç”±ä¸¤ä¸ªä¸»è¦ç»„ä»¶ç»„æˆï¼š

**ç´¢å¼•**ï¼šç”¨äºä»æºä¸­æ‘„å–æ•°æ®å¹¶è¿›è¡Œç´¢å¼•çš„æµæ°´çº¿ã€‚_è¿™é€šå¸¸æ˜¯ç¦»çº¿å®Œæˆçš„ã€‚_

**æ£€ç´¢å’Œç”Ÿæˆ**ï¼šå®é™…çš„RAGé“¾ï¼Œå®ƒä¼šåœ¨è¿è¡Œæ—¶æ¥æ”¶ç”¨æˆ·æŸ¥è¯¢å¹¶ä»ç´¢å¼•ä¸­æ£€ç´¢ç›¸å…³æ•°æ®ï¼Œç„¶åå°†å…¶ä¼ é€’ç»™æ¨¡å‹ã€‚

ä»åŸå§‹æ•°æ®åˆ°ç­”æ¡ˆçš„å®Œæ•´è¿‡ç¨‹å¦‚ä¸‹æ‰€ç¤ºï¼š

### ç´¢å¼•

1. **åŠ è½½**ï¼šé¦–å…ˆæˆ‘ä»¬éœ€è¦åŠ è½½æ•°æ®ã€‚æˆ‘ä»¬å°†ä½¿ç”¨[DocumentLoaders](/modules/data_connection/document_loaders/)æ¥å®Œæˆè¿™ä¸€æ­¥ã€‚
2. **æ‹†åˆ†**ï¼š[Text splitters](/modules/data_connection/document_transformers/)å°†å¤§å‹çš„`Documents`æ‹†åˆ†æˆè¾ƒå°çš„å—ã€‚è¿™å¯¹äºç´¢å¼•æ•°æ®å’Œå°†æ•°æ®ä¼ é€’åˆ°æ¨¡å‹ä¸­éƒ½å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºè¾ƒå¤§çš„å—æ›´éš¾æœç´¢ï¼Œå¹¶ä¸”æ— æ³•é€‚åº”æ¨¡å‹çš„æœ‰é™ä¸Šä¸‹æ–‡çª—å£ã€‚
3. **å­˜å‚¨**ï¼šæˆ‘ä»¬éœ€è¦ä¸€ä¸ªåœ°æ–¹æ¥å­˜å‚¨å’Œç´¢å¼•æˆ‘ä»¬çš„æ‹†åˆ†ï¼Œä»¥ä¾¿ä»¥åè¿›è¡Œæœç´¢ã€‚é€šå¸¸ä½¿ç”¨[VectorStore](/modules/data_connection/vectorstores/)å’Œ[Embeddings](/modules/data_connection/text_embedding/)æ¨¡å‹æ¥å®Œæˆæ­¤æ“ä½œã€‚

### æ£€ç´¢å’Œç”Ÿæˆ

1. **æ£€ç´¢**ï¼šç»™å®šç”¨æˆ·è¾“å…¥ï¼Œæ£€ç´¢å™¨ä½¿ç”¨[Retriever](/modules/data_connection/retrievers/)ä»å­˜å‚¨ä¸­æ£€ç´¢ç›¸å…³çš„æ‹†åˆ†ã€‚
2. **ç”Ÿæˆ**ï¼š[ChatModel](/modules/model_io/chat/) / [LLM](/modules/model_io/llms/)é€šè¿‡åŒ…å«é—®é¢˜å’Œæ£€ç´¢æ•°æ®çš„æç¤ºæ¥ç”Ÿæˆç­”æ¡ˆã€‚

## è®¾ç½®

### ä¾èµ–å…³ç³»

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨OpenAIèŠå¤©æ¨¡å‹ã€åµŒå…¥å’ŒChromaå‘é‡å­˜å‚¨ï¼Œä½†è¿™é‡Œå±•ç¤ºçš„æ‰€æœ‰å†…å®¹éƒ½é€‚ç”¨äºä»»ä½•[ChatModel](/modules/model_io/chat/)æˆ–[LLM](/modules/model_io/llms/)ã€[Embeddings](/modules/data_connection/text_embedding/)å’Œ[VectorStore](/modules/data_connection/vectorstores/)æˆ–[Retriever](/modules/data_connection/retrievers/)ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨ä»¥ä¸‹è½¯ä»¶åŒ…ï¼š

```python
%pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-openai chromadb bs4
```

æˆ‘ä»¬éœ€è¦ä¸ºåµŒå…¥æ¨¡å‹è®¾ç½®ç¯å¢ƒå˜é‡`OPENAI_API_KEY`ï¼Œå¯ä»¥ç›´æ¥è®¾ç½®ï¼Œä¹Ÿå¯ä»¥ä»`.env`æ–‡ä»¶ä¸­åŠ è½½ï¼Œç¤ºä¾‹å¦‚ä¸‹ï¼š

```python
import getpass
import os

os.environ["OPENAI_API_KEY"] = getpass.getpass()

# import dotenv

# dotenv.load_dotenv()
```

### LangSmith

ä½¿ç”¨LangChainæ„å»ºçš„è®¸å¤šåº”ç”¨ç¨‹åºéƒ½åŒ…å«å¤šä¸ªæ­¥éª¤ï¼Œéœ€è¦å¤šæ¬¡è°ƒç”¨LLMã€‚éšç€è¿™äº›åº”ç”¨ç¨‹åºå˜å¾—è¶Šæ¥è¶Šå¤æ‚ï¼Œèƒ½å¤Ÿæ£€æŸ¥é“¾è·¯æˆ–ä»£ç†ä¸­ç¡®åˆ‡å‘ç”Ÿäº†ä»€ä¹ˆå˜å¾—è‡³å…³é‡è¦ã€‚æœ€å¥½çš„æ–¹æ³•æ˜¯ä½¿ç”¨[LangSmith](https://smith.langchain.com)ã€‚

è¯·æ³¨æ„ï¼ŒLangSmithä¸æ˜¯å¿…éœ€çš„ï¼Œä½†å®ƒæ˜¯æœ‰ç”¨çš„ã€‚å¦‚æœæ‚¨ç¡®å®æƒ³ä½¿ç”¨LangSmithï¼Œè¯·åœ¨ä¸Šé¢çš„é“¾æ¥ä¸Šæ³¨å†Œåï¼Œç¡®ä¿è®¾ç½®ç¯å¢ƒå˜é‡ä»¥å¼€å§‹è®°å½•è·Ÿè¸ªï¼š

```python
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = getpass.getpass()
```

## é¢„è§ˆ

åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°†åœ¨Lilian Wengçš„[LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/)åšæ–‡ä¸Šæ„å»ºä¸€ä¸ªé—®ç­”åº”ç”¨ç¨‹åºï¼Œä»¥ä¾¿äºæˆ‘ä»¬æé—®å…³äºåšæ–‡å†…å®¹çš„é—®é¢˜ã€‚

æˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªç®€å•çš„ç´¢å¼•æµæ°´çº¿å’ŒRAGé“¾ï¼Œåªéœ€çº¦20è¡Œä»£ç å³å¯å®Œæˆï¼š

```python
import bs4
from langchain import hub
from langchain_community.document_loaders import WebBaseLoader
from langchain_community.vectorstores import Chroma
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
```

import ChatModelTabs from "@theme/ChatModelTabs";

<ChatModelTabs customVarName="llm" />

```python
# åŠ è½½ã€æ‹†åˆ†å’Œç´¢å¼•åšæ–‡å†…å®¹ã€‚
loader = WebBaseLoader(
    web_paths=("https://lilianweng.github.io/posts/2023-06-23-agent/",),
    bs_kwargs=dict(
        parse_only=bs4.SoupStrainer(
            class_=("post-content", "post-title", "post-header")
        )
    ),
)
docs = loader.load()

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
splits = text_splitter.split_documents(docs)
vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())

# ä½¿ç”¨ç›¸å…³çš„åšæ–‡ç‰‡æ®µæ¥æ£€ç´¢å’Œç”Ÿæˆã€‚
retriever = vectorstore.as_retriever()
prompt = hub.pull("rlm/rag-prompt")

def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)


rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)
```

```python
rag_chain.invoke("ä»€ä¹ˆæ˜¯ä»»åŠ¡åˆ†è§£ï¼Ÿ")
```

```text
'ä»»åŠ¡åˆ†è§£æ˜¯ä¸€ç§å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºè¾ƒå°å’Œæ›´ç®€å•æ­¥éª¤çš„æŠ€æœ¯ã€‚å®ƒå¯ä»¥é€šè¿‡åƒChain of Thoughtæˆ–Tree of Thoughtsçš„æç¤ºæŠ€æœ¯ï¼Œæˆ–è€…ä½¿ç”¨ä»»åŠ¡ç‰¹å®šçš„è¯´æ˜æˆ–äººç±»è¾“å…¥æ¥å®Œæˆã€‚ä»»åŠ¡åˆ†è§£æœ‰åŠ©äºä»£ç†æå‰è§„åˆ’å’Œæ›´æœ‰æ•ˆåœ°ç®¡ç†å¤æ‚ä»»åŠ¡ã€‚'
```

```python
# æ¸…ç†
vectorstore.delete_collection()
```

è¯·æŸ¥çœ‹[LangSmithé“¾è·¯](https://smith.langchain.com/public/1c6ca97e-445b-4d00-84b4-c7befcbc59fe/r)

## è¯¦ç»†æŒ‡å—

è®©æˆ‘ä»¬é€æ­¥äº†è§£ä¸Šè¿°ä»£ç çš„æ¯ä¸€æ­¥ï¼Œä»¥ä¾¿çœŸæ­£ç†è§£å‘ç”Ÿäº†ä»€ä¹ˆã€‚

## 1. ç´¢å¼•ï¼šåŠ è½½ {#indexing-load}

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦åŠ è½½åšæ–‡å†…å®¹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨[DocumentLoaders](/modules/data_connection/document_loaders/)ï¼Œè¿™æ˜¯ä¸€ç§ä»æºåŠ è½½æ•°æ®å¹¶è¿”å›[Documents](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html)åˆ—è¡¨çš„å¯¹è±¡ã€‚`Document`æ˜¯ä¸€ä¸ªå…·æœ‰ä¸€äº›`page_content`ï¼ˆå­—ç¬¦ä¸²ï¼‰å’Œ`metadata`ï¼ˆå­—å…¸ï¼‰çš„å¯¹è±¡ã€‚

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨[WebBaseLoader](/docs/integrations/document_loaders/web_base)ï¼Œå®ƒä½¿ç”¨`urllib`ä»Web URLåŠ è½½HTMLï¼Œå¹¶ä½¿ç”¨`BeautifulSoup`å°†å…¶è§£æä¸ºæ–‡æœ¬ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡é€šè¿‡`bs_kwargs`ä¼ é€’å‚æ•°ç»™`BeautifulSoup`è§£æå™¨æ¥è‡ªå®šä¹‰HTMLåˆ°æ–‡æœ¬çš„è§£æï¼ˆå‚è§[BeautifulSoupæ–‡æ¡£](https://beautiful-soup-4.readthedocs.io/en/latest/#beautifulsoup)ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œåªæœ‰å…·æœ‰"class"ä¸º"post-content"ã€"post-title"æˆ–"post-header"çš„HTMLæ ‡ç­¾æ˜¯ç›¸å…³çš„ï¼Œå› æ­¤æˆ‘ä»¬å°†åˆ é™¤æ‰€æœ‰å…¶ä»–æ ‡ç­¾ã€‚

```python
import bs4
from langchain_community.document_loaders import WebBaseLoader

# Only keep post title, headers, and content from the full HTML.
bs4_strainer = bs4.SoupStrainer(class_=("post-title", "post-header", "post-content"))
loader = WebBaseLoader(
    web_paths=("https://lilianweng.github.io/posts/2023-06-23-agent/",),
    bs_kwargs={"parse_only": bs4_strainer},
)
docs = loader.load()
```

```python
len(docs[0].page_content)
```

```text
42824
```

```python
print(docs[0].page_content[:500])
```

```text


      LLM Powered Autonomous Agents

Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng


æ„å»ºä»¥LLMï¼ˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼‰ä½œä¸ºæ ¸å¿ƒæ§åˆ¶å™¨çš„ä»£ç†æ˜¯ä¸€ä¸ªå¾ˆé…·çš„æ¦‚å¿µã€‚å‡ ä¸ªæ¦‚å¿µéªŒè¯æ¼”ç¤ºï¼Œå¦‚AutoGPTï¼ŒGPT-Engineerå’ŒBabyAGIï¼Œéƒ½æ˜¯ä»¤äººé¼“èˆçš„ä¾‹å­ã€‚LLMçš„æ½œåŠ›è¶…è¶Šäº†ç”Ÿæˆå†™ä½œå‰¯æœ¬ã€æ•…äº‹ã€æ–‡ç« å’Œç¨‹åºçš„èƒ½åŠ›ï¼›å®ƒå¯ä»¥è¢«æ„å»ºæˆä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„é€šç”¨é—®é¢˜æ±‚è§£å™¨ã€‚
ä»£ç†ç³»ç»Ÿæ¦‚è¿°#
åœ¨
```

### æ·±å…¥äº†è§£

`DocumentLoader`ï¼šä»æºåŠ è½½æ•°æ®å¹¶ä½œä¸º`Documents`åˆ—è¡¨è¿›è¡ŒåŠ è½½çš„å¯¹è±¡ã€‚

- [æ–‡æ¡£](/modules/data_connection/document_loaders/)ï¼šå¦‚ä½•ä½¿ç”¨`DocumentLoader`çš„è¯¦ç»†æ–‡æ¡£ã€‚
- [é›†æˆ](/docs/integrations/document_loaders/)ï¼š160å¤šä¸ªå¯ä¾›é€‰æ‹©çš„é›†æˆã€‚
- [æ¥å£](https://api.python.langchain.com/en/latest/document_loaders/langchain_core.document_loaders.base.BaseLoader.html)ï¼šåŸºæœ¬æ¥å£çš„APIå‚è€ƒã€‚

## 2.ç´¢å¼•ï¼šåˆ†å‰² {#indexing-split}

æˆ‘ä»¬åŠ è½½çš„æ–‡æ¡£è¶…è¿‡42kä¸ªå­—ç¬¦ï¼Œè¿™å¤ªé•¿äº†ï¼Œæ— æ³•é€‚åº”è®¸å¤šæ¨¡å‹çš„ä¸Šä¸‹æ–‡çª—å£ã€‚å³ä½¿å¯¹äºèƒ½å¤Ÿé€‚åº”å®Œæ•´å¸–å­çš„æ¨¡å‹ï¼Œæ¨¡å‹ä¹Ÿå¯èƒ½å¾ˆéš¾åœ¨éå¸¸é•¿çš„è¾“å…¥ä¸­æ‰¾åˆ°ä¿¡æ¯ã€‚

ä¸ºäº†å¤„ç†è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å°†æŠŠ`Document`åˆ†æˆå—ï¼Œä»¥ä¾¿è¿›è¡ŒåµŒå…¥å’Œå‘é‡å­˜å‚¨ã€‚è¿™æ ·åº”è¯¥èƒ½å¤Ÿå¸®åŠ©æˆ‘ä»¬åœ¨è¿è¡Œæ—¶ä»…æ£€ç´¢ä¸æŸ¥è¯¢æœ€ç›¸å…³çš„éƒ¨åˆ†çš„åšå®¢æ–‡ç« ã€‚

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†æˆ‘ä»¬çš„æ–‡æ¡£åˆ†æˆ1000ä¸ªå­—ç¬¦ä¸€å—ï¼Œå—ä¹‹é—´é‡å 200ä¸ªå­—ç¬¦ã€‚é‡å æœ‰åŠ©äºç¼“è§£å°†è¯­å¥ä¸ä¸å…¶ç›¸å…³çš„é‡è¦ä¸Šä¸‹æ–‡åˆ†å¼€çš„å¯èƒ½æ€§ã€‚æˆ‘ä»¬ä½¿ç”¨[RecursiveCharacterTextSplitter](/modules/data_connection/document_transformers/recursive_text_splitter)ï¼Œè¯¥åˆ†å‰²å™¨å°†ä½¿ç”¨æ¢è¡Œç­‰å¸¸è§çš„åˆ†éš”ç¬¦é€’å½’åœ°æ‹†åˆ†æ–‡æ¡£ï¼Œç›´åˆ°æ¯ä¸ªå—çš„å¤§å°é€‚å½“ä¸ºæ­¢ã€‚è¿™æ˜¯é€šç”¨æ–‡æœ¬ç”¨ä¾‹çš„æ¨èæ–‡æœ¬åˆ†å‰²å™¨ã€‚

æˆ‘ä»¬è®¾ç½®`add_start_index=True`ï¼Œè¿™æ ·æ¯ä¸ªåˆ†å‰²çš„æ–‡æ¡£åœ¨åˆå§‹æ–‡æ¡£ä¸­çš„èµ·å§‹ä½ç½®çš„å­—ç¬¦ç´¢å¼•å°±è¢«ä¿ç•™ä¸ºå…ƒæ•°æ®å±æ€§â€œstart_indexâ€ã€‚

```python
from langchain_text_splitters import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000, chunk_overlap=200, add_start_index=True
)
all_splits = text_splitter.split_documents(docs)
```

```python
len(all_splits)
```

```text
66
```

```python
len(all_splits[0].page_content)
```

```text
969
```

```python
all_splits[10].metadata
```

```text
{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/',
 'start_index': 7056}
```

### æ·±å…¥äº†è§£

`TextSplitter`ï¼šå°†`Document`åˆ—è¡¨åˆ†å‰²æˆè¾ƒå°å—çš„å¯¹è±¡ã€‚æ˜¯`DocumentTransformer`çš„å­ç±»ã€‚

- æ¢ç´¢"ä¸Šä¸‹æ–‡æ„ŸçŸ¥åˆ†å‰²å™¨"ï¼Œå®ƒä¿ç•™äº†æ¯ä¸ªåˆ†å‰²åœ¨åŸå§‹`Document`ä¸­çš„ä½ç½®ï¼ˆâ€œä¸Šä¸‹æ–‡â€ï¼‰ï¼š - [Markdownæ–‡ä»¶](/modules/data_connection/document_transformers/markdown_header_metadata)
- [ä»£ç ï¼ˆpyæˆ–jsï¼‰](/docs/integrations/document_loaders/source_code)
- [ç§‘å­¦è®ºæ–‡](/docs/integrations/document_loaders/grobid)
- [æ¥å£](https://api.python.langchain.com/en/latest/base/langchain_text_splitters.base.TextSplitter.html)ï¼šåŸºæœ¬æ¥å£çš„APIå‚è€ƒã€‚

`DocumentTransformer`ï¼šå¯¹ä¸€ç»„`Document`æ‰§è¡Œå˜æ¢çš„å¯¹è±¡ã€‚

- [æ–‡æ¡£](/modules/data_connection/document_transformers/)ï¼šå¦‚ä½•ä½¿ç”¨`DocumentTransformers`çš„è¯¦ç»†æ–‡æ¡£ã€‚
- [é›†æˆ](/docs/integrations/document_transformers/)
- [æ¥å£](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.transformers.BaseDocumentTransformer.html)ï¼šåŸºæœ¬æ¥å£çš„APIå‚è€ƒã€‚

## 3.ç´¢å¼•ï¼šå­˜å‚¨ {#indexing-store}

ç°åœ¨æˆ‘ä»¬éœ€è¦å¯¹66ä¸ªæ–‡æœ¬å—è¿›è¡Œç´¢å¼•ï¼Œä»¥ä¾¿åœ¨è¿è¡Œæ—¶å¯ä»¥å¯¹å®ƒä»¬è¿›è¡Œæœç´¢ã€‚æœ€å¸¸è§çš„æ–¹æ³•æ˜¯åµŒå…¥æ¯ä¸ªæ–‡æ¡£åˆ†å‰²çš„å†…å®¹ï¼Œå¹¶å°†è¿™äº›åµŒå…¥æ’å…¥åˆ°å‘é‡æ•°æ®åº“ï¼ˆæˆ–å‘é‡å­˜å‚¨ï¼‰ä¸­ã€‚å½“æˆ‘ä»¬æƒ³è¦å¯¹æˆ‘ä»¬çš„åˆ†å‰²è¿›è¡Œæœç´¢æ—¶ï¼Œæˆ‘ä»¬ä¼šè·å–ä¸€ä¸ªæ–‡æœ¬æœç´¢æŸ¥è¯¢ï¼Œå¯¹å…¶è¿›è¡ŒåµŒå…¥ï¼Œç„¶åæ‰§è¡ŒæŸç§â€œç›¸ä¼¼åº¦â€æœç´¢ï¼Œä»¥è¯†åˆ«ä¸æˆ‘ä»¬æŸ¥è¯¢åµŒå…¥æœ€ç›¸ä¼¼çš„å­˜å‚¨åˆ†å‰²ã€‚æœ€ç®€å•çš„ç›¸ä¼¼åº¦åº¦é‡æ˜¯ä½™å¼¦ç›¸ä¼¼åº¦-æˆ‘ä»¬æµ‹é‡æ¯å¯¹åµŒå…¥ä¹‹é—´çš„è§’åº¦çš„ä½™å¼¦å€¼ï¼ˆå®ƒä»¬æ˜¯é«˜ç»´å‘é‡ï¼‰ã€‚

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨[Chroma](/docs/integrations/vectorstores/chroma)å‘é‡å­˜å‚¨å’Œ[OpenAIEmbeddings](/docs/integrations/text_embedding/openai)æ¨¡å‹ä¸€æ¬¡æ€§åµŒå…¥å’Œå­˜å‚¨æ‰€æœ‰æ–‡æ¡£åˆ†å‰²ã€‚

```python
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())
```

### æ·±å…¥äº†è§£

`Embeddings`ï¼šæ–‡æœ¬åµŒå…¥æ¨¡å‹çš„åŒ…è£…å™¨ï¼Œç”¨äºå°†æ–‡æœ¬è½¬æ¢ä¸ºåµŒå…¥ã€‚

- [æ–‡æ¡£](/modules/data_connection/text_embedding)ï¼šå¦‚ä½•ä½¿ç”¨åµŒå…¥çš„è¯¦ç»†æ–‡æ¡£ã€‚
- [é›†æˆ](/docs/integrations/text_embedding/)ï¼š30å¤šä¸ªå¯ä¾›é€‰æ‹©çš„é›†æˆã€‚
- [æ¥å£](https://api.python.langchain.com/en/latest/embeddings/langchain_core.embeddings.Embeddings.html)ï¼šåŸºæœ¬æ¥å£çš„APIå‚è€ƒã€‚

`VectorStore`ï¼šå‘é‡æ•°æ®åº“çš„åŒ…è£…å™¨ï¼Œç”¨äºå­˜å‚¨å’ŒæŸ¥è¯¢åµŒå…¥ã€‚

- [æ–‡æ¡£](/modules/data_connection/vectorstores/)ï¼šå¦‚ä½•ä½¿ç”¨å‘é‡å­˜å‚¨çš„è¯¦ç»†æ–‡æ¡£ã€‚
- [é›†æˆ](/docs/integrations/vectorstores/)ï¼š40å¤šä¸ªå¯ä¾›é€‰æ‹©çš„é›†æˆã€‚
- [æ¥å£](https://api.python.langchain.com/en/latest/vectorstores/langchain_core.vectorstores.VectorStore.html)ï¼šåŸºæœ¬æ¥å£çš„APIå‚è€ƒã€‚

è¿™å®Œæˆäº†**ç´¢å¼•**éƒ¨åˆ†çš„æµç¨‹ã€‚åœ¨è¿™ä¸€ç‚¹ä¸Šï¼Œæˆ‘ä»¬æ‹¥æœ‰äº†ä¸€ä¸ªå¯æŸ¥è¯¢çš„å‘é‡å­˜å‚¨ï¼Œå…¶ä¸­åŒ…å«äº†æˆ‘ä»¬çš„åšå®¢æ–‡ç« çš„åˆ†å—å†…å®¹ã€‚ç»™å®šä¸€ä¸ªç”¨æˆ·é—®é¢˜ï¼Œç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åº”è¯¥èƒ½å¤Ÿè¿”å›å›ç­”è¯¥é—®é¢˜çš„åšå®¢æ–‡ç« çš„ç‰‡æ®µã€‚

## 4.æ£€ç´¢å’Œç”Ÿæˆï¼šæ£€ç´¢ {#retrieval-and-generation-retrieve}

ç°åœ¨è®©æˆ‘ä»¬ç¼–å†™å®é™…çš„åº”ç”¨é€»è¾‘ã€‚æˆ‘ä»¬æƒ³åˆ›å»ºä¸€ä¸ªç®€å•çš„åº”ç”¨ç¨‹åºï¼Œæ¥å—ç”¨æˆ·æå‡ºçš„é—®é¢˜ï¼Œæœç´¢ä¸è¯¥é—®é¢˜ç›¸å…³çš„æ–‡æ¡£ï¼Œå°†æ£€ç´¢åˆ°çš„æ–‡æ¡£å’Œåˆå§‹é—®é¢˜ä¼ é€’ç»™æ¨¡å‹ï¼Œç„¶åè¿”å›ä¸€ä¸ªç­”æ¡ˆã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰æˆ‘ä»¬åœ¨æ–‡æ¡£ä¸Šè¿›è¡Œæœç´¢çš„é€»è¾‘ã€‚LangChainå®šä¹‰äº†ä¸€ä¸ª[æ£€ç´¢å™¨](/modules/data_connection/retrievers/)æ¥å£ï¼Œç”¨äºåŒ…è£…å¯ä»¥æ ¹æ®å­—ç¬¦ä¸²æŸ¥è¯¢è¿”å›ç›¸å…³`Documents`çš„ç´¢å¼•ã€‚

æœ€å¸¸è§çš„`æ£€ç´¢å™¨`ç±»å‹æ˜¯[VectorStoreRetriever](/modules/data_connection/retrievers/vectorstore)ï¼Œå®ƒä½¿ç”¨å‘é‡å­˜å‚¨çš„ç›¸ä¼¼åº¦æœç´¢åŠŸèƒ½æ¥æ–¹ä¾¿æ£€ç´¢ã€‚ä»»ä½•`VectorStore`éƒ½å¯ä»¥å¾ˆå®¹æ˜“åœ°é€šè¿‡`VectorStore.as_retriever()`è½¬æ¢ä¸º`Retriever`ï¼š

```python
retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 6})
```

```python
retrieved_docs = retriever.invoke("What are the approaches to Task Decomposition?")
```

```python
len(retrieved_docs)
```

```text
6
```

```python
print(retrieved_docs[0].page_content)
```

```text
Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.
Task decomposition can be done (1) by LLM with simple prompting like "Steps for XYZ.\n1.", "What are the subgoals for achieving XYZ?", (2) by using task-specific instructions; e.g. "Write a story outline." for writing a novel, or (3) with human inputs.
```
------

7ä¸ªç­‰å·å¼€å§‹ï¼Œ7ä¸ªç­‰å·ç»“æŸ### æ›´æ·±å…¥äº†è§£

å‘é‡å­˜å‚¨é€šå¸¸ç”¨äºæ£€ç´¢ï¼Œä½†è¿˜æœ‰å…¶ä»–æ–¹æ³•å¯ä»¥è¿›è¡Œæ£€ç´¢ã€‚

`Retriever`: ä¸€ä¸ªæ ¹æ®æ–‡æœ¬æŸ¥è¯¢è¿”å›`Document`çš„å¯¹è±¡

- [æ–‡æ¡£](/modules/data_connection/retrievers/): å…³äºæ¥å£å’Œå†…ç½®æ£€ç´¢æŠ€æœ¯çš„è¿›ä¸€æ­¥æ–‡æ¡£ã€‚å…¶ä¸­åŒ…æ‹¬ï¼š
  - `MultiQueryRetriever`[ç”Ÿæˆè¾“å…¥é—®é¢˜çš„å˜ç§](/modules/data_connection/retrievers/MultiQueryRetriever)ä»¥æé«˜æ£€ç´¢å‘½ä¸­ç‡ã€‚
  - `MultiVectorRetriever`ï¼ˆä¸‹å›¾ï¼‰ç”Ÿæˆ[åµŒå…¥çš„å˜ç§](/modules/data_connection/retrievers/multi_vector)ï¼Œä¹Ÿæ˜¯ä¸ºäº†æé«˜æ£€ç´¢å‘½ä¸­ç‡ã€‚
  - `æœ€å¤§è¾¹é™…ç›¸å…³æ€§`é€‰æ‹©[ç›¸å…³æ€§å’Œå·®å¼‚æ€§](https://www.cs.cmu.edu/~jgc/publication/The_Use_MMR_Diversity_Based_LTMIR_1998.pdf)ä¸­æ£€ç´¢åˆ°çš„æ–‡æ¡£ï¼Œä»¥é¿å…ä¼ é€’é‡å¤çš„ä¸Šä¸‹æ–‡ã€‚
  - åœ¨ä½¿ç”¨å…ƒæ•°æ®è¿‡æ»¤å™¨è¿›è¡Œå‘é‡å­˜å‚¨æ£€ç´¢æ—¶å¯ä»¥å¯¹æ–‡æ¡£è¿›è¡Œè¿‡æ»¤ï¼Œä¾‹å¦‚ä½¿ç”¨[è‡ªæŸ¥è¯¢æ£€ç´¢å™¨](/modules/data_connection/retrievers/self_query)ã€‚
- [é›†æˆ](/docs/integrations/retrievers/): ä¸æ£€ç´¢æœåŠ¡çš„é›†æˆã€‚
- [æ¥å£](https://api.python.langchain.com/en/latest/retrievers/langchain_core.retrievers.BaseRetriever.html):
  åŸºç¡€æ¥å£çš„APIå‚è€ƒã€‚

## 5. æ£€ç´¢å’Œç”Ÿæˆ: ç”Ÿæˆ {#retrieval-and-generation-generate}

è®©æˆ‘ä»¬å°†æ‰€æœ‰å†…å®¹æ•´åˆåˆ°ä¸€èµ·ï¼Œå½¢æˆä¸€ä¸ªé“¾æ¡ï¼Œè¯¥é“¾æ¡æ¥æ”¶ä¸€ä¸ªé—®é¢˜ï¼Œæ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼Œæ„å»ºä¸€ä¸ªæç¤ºï¼Œå°†å…¶ä¼ é€’ç»™æ¨¡å‹ï¼Œå¹¶è§£æè¾“å‡ºç»“æœã€‚

æˆ‘ä»¬å°†ä½¿ç”¨gpt-3.5-turbo OpenAIèŠå¤©æ¨¡å‹ï¼Œä½†å¯ä»¥æ›¿æ¢ä¸ºä»»ä½•LangChainçš„`LLM`æˆ–`ChatModel`ã€‚

import Tabs from "@theme/Tabs";
import TabItem from "@theme/TabItem";

<ChatModelTabs
  customVarName="llm"
  anthropicParams=`"model="claude-3-sonnet-20240229", temperature=0.2, max_tokens=1024"`
/>

æˆ‘ä»¬å°†ä½¿ç”¨RAGçš„æç¤ºï¼Œè¯¥æç¤ºå·²ç»å­˜å‚¨åœ¨LangChainçš„æç¤ºä¸­å¿ƒä¸­ï¼ˆ[æ­¤å¤„](https://smith.langchain.com/hub/rlm/rag-prompt)ï¼‰ã€‚

```python
from langchain import hub

prompt = hub.pull("rlm/rag-prompt")
```

```python
example_messages = prompt.invoke(
    {"context": "å¡«å……ä¸Šä¸‹æ–‡", "question": "å¡«å……é—®é¢˜"}
).to_messages()
example_messages
```

```text
[HumanMessage(content="æ‚¨æ˜¯ä¸€ä¸ªç”¨äºé—®ç­”ä»»åŠ¡çš„åŠ©æ‰‹ã€‚ä½¿ç”¨ä»¥ä¸‹æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ç‰‡æ®µæ¥å›ç­”é—®é¢˜ã€‚å¦‚æœæ‚¨ä¸çŸ¥é“ç­”æ¡ˆï¼Œåªéœ€è¯´ä¸çŸ¥é“å³å¯ã€‚æœ€å¤šä½¿ç”¨ä¸‰ä¸ªå¥å­ï¼Œä¿æŒç­”æ¡ˆç®€æ´ã€‚\né—®é¢˜: å¡«å……é—®é¢˜ \nä¸Šä¸‹æ–‡: å¡«å……ä¸Šä¸‹æ–‡ \nç­”æ¡ˆ:")]
```

```python
print(example_messages[0].content)
```

```text
æ‚¨æ˜¯ä¸€ä¸ªç”¨äºé—®ç­”ä»»åŠ¡çš„åŠ©æ‰‹ã€‚ä½¿ç”¨ä»¥ä¸‹æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ç‰‡æ®µæ¥å›ç­”é—®é¢˜ã€‚å¦‚æœæ‚¨ä¸çŸ¥é“ç­”æ¡ˆï¼Œåªéœ€è¯´ä¸çŸ¥é“å³å¯ã€‚æœ€å¤šä½¿ç”¨ä¸‰ä¸ªå¥å­ï¼Œä¿æŒç­”æ¡ˆç®€æ´ã€‚
é—®é¢˜: å¡«å……é—®é¢˜
ä¸Šä¸‹æ–‡: å¡«å……ä¸Šä¸‹æ–‡
ç­”æ¡ˆ:
```

æˆ‘ä»¬å°†ä½¿ç”¨[LCEL Runnable](/expression_language/)åè®®å®šä¹‰é“¾æ¡ï¼Œè¿™æ ·æˆ‘ä»¬å¯ä»¥ï¼š
- ä»¥é€æ˜æ–¹å¼å°†ç»„ä»¶å’Œå‡½æ•°ä¸²è”åœ¨ä¸€èµ·
- åœ¨LangSmithä¸­è‡ªåŠ¨è·Ÿè¸ªé“¾æ¡
- åœ¨å¼€ç®±å³ç”¨çš„æƒ…å†µä¸‹è·å–æµå¼å¤„ç†ã€å¼‚æ­¥å¤„ç†å’Œæ‰¹å¤„ç†è°ƒç”¨

```python
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough


def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)


rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)
```

```python
for chunk in rag_chain.stream("ä»€ä¹ˆæ˜¯ä»»åŠ¡åˆ†è§£?"):
    print(chunk, end="", flush=True)
```

```text
ä»»åŠ¡åˆ†è§£æ˜¯ä¸€ç§å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºè¾ƒå°å’Œæ›´ç®€å•æ­¥éª¤çš„æŠ€æœ¯ã€‚å®ƒæ¶‰åŠå°†å¤§å‹ä»»åŠ¡è½¬åŒ–ä¸ºå¤šä¸ªå¯ç®¡ç†çš„ä»»åŠ¡ï¼Œä»è€Œä½¿è‡ªä¸»ä»£ç†æˆ–æ¨¡å‹æ›´å®¹æ˜“ç†è§£å’Œæ‰§è¡Œã€‚ä»»åŠ¡åˆ†è§£å¯ä»¥é€šè¿‡å„ç§æ–¹æ³•æ¥å®ç°ï¼Œä¾‹å¦‚ä½¿ç”¨æç¤ºæŠ€æœ¯ï¼Œä»»åŠ¡ç‰¹å®šçš„æŒ‡ä»¤æˆ–äººç±»è¾“å…¥ã€‚
```

æŸ¥çœ‹[LangSmithè·Ÿè¸ª](https://smith.langchain.com/public/1799e8db-8a6d-4eb2-84d5-46e8d7d5a99b/r)

### æ›´è¿›ä¸€æ­¥

#### é€‰æ‹©æ¨¡å‹

`ChatModel`: åŸºäºLLMçš„èŠå¤©æ¨¡å‹ã€‚æ¥å—ä¸€ç³»åˆ—æ¶ˆæ¯å¹¶è¿”å›ä¸€æ¡æ¶ˆæ¯ã€‚

- [æ–‡æ¡£](/modules/model_io/chat/)
- [é›†æˆ](/docs/integrations/chat/): æœ‰è¶…è¿‡25ä¸ªé›†æˆä¾›é€‰æ‹©ã€‚
- [æ¥å£](https://api.python.langchain.com/en/latest/language_models/langchain_core.language_models.chat_models.BaseChatModel.html): åŸºç¡€æ¥å£çš„APIå‚è€ƒã€‚

`LLM`: æ–‡æœ¬è¾“å…¥æ–‡æœ¬è¾“å‡ºçš„LLMã€‚æ¥å—ä¸€ä¸ªå­—ç¬¦ä¸²å¹¶è¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚

- [æ–‡æ¡£](/modules/model_io/llms)
- [é›†æˆ](/docs/integrations/llms): æœ‰75å¤šä¸ªé›†æˆä¾›é€‰æ‹©ã€‚
- [æ¥å£](https://api.python.langchain.com/en/latest/language_models/langchain_core.language_models.llms.BaseLLM.html): åŸºç¡€æ¥å£çš„APIå‚è€ƒã€‚

åœ¨æœ¬åœ°è¿è¡Œæ¨¡å‹çš„RAGæŒ‡å—ï¼Œè¯·å‚é˜…[æ­¤å¤„](/use_cases/question_answering/local_retrieval_qa)ã€‚

#### è‡ªå®šä¹‰æç¤º

å¦‚ä¸Šæ‰€ç¤ºï¼Œæˆ‘ä»¬å¯ä»¥ä»æç¤ºä¸­å¿ƒåŠ è½½æç¤ºï¼ˆä¾‹å¦‚[æ­¤å¤„çš„RAGæç¤º](https://smith.langchain.com/hub/rlm/rag-prompt)ï¼‰ã€‚åŒæ—¶ï¼Œæç¤ºä¹Ÿå¯ä»¥å¾ˆå®¹æ˜“åœ°è¿›è¡Œè‡ªå®šä¹‰ï¼š

```python
from langchain_core.prompts import PromptTemplate

template = """ä½¿ç”¨ä»¥ä¸‹ä¸Šä¸‹æ–‡ç‰‡æ®µæ¥å›ç­”æœ€åçš„é—®é¢˜ã€‚
å¦‚æœæ‚¨ä¸çŸ¥é“ç­”æ¡ˆï¼Œåªéœ€è¯´ä¸çŸ¥é“ï¼Œä¸è¦è¯•å›¾èƒ¡ä¹±å›ç­”ã€‚
æœ€å¤šä½¿ç”¨ä¸‰ä¸ªå¥å­ï¼Œå¹¶å°½é‡ç®€æ˜æ‰¼è¦ã€‚
åœ¨ç­”æ¡ˆçš„æœ€åå§‹ç»ˆè¦è¯´"æ„Ÿè°¢æ‚¨çš„æé—®ï¼"

{context}

é—®é¢˜ï¼š{question}

æœ‰å¸®åŠ©çš„ç­”æ¡ˆï¼š"""
custom_rag_prompt = PromptTemplate.from_template(template)

rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | custom_rag_prompt
    | llm
    | StrOutputParser()
)

rag_chain.invoke("ä»€ä¹ˆæ˜¯ä»»åŠ¡åˆ†è§£?")
```

```text
'ä»»åŠ¡åˆ†è§£æ˜¯ä¸€ç§å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºè¾ƒå°å’Œæ›´ç®€å•æ­¥éª¤çš„æŠ€æœ¯ã€‚é€šè¿‡å°†å¤§å‹ä»»åŠ¡è½¬åŒ–ä¸ºå¤šä¸ªå¯ç®¡ç†çš„ä»»åŠ¡ï¼Œä»¥æ›´ç³»ç»Ÿå’Œç»„ç»‡åŒ–çš„æ–¹å¼è§£å†³é—®é¢˜ã€‚è°¢è°¢æ‚¨çš„æé—®ï¼'
```

æŸ¥çœ‹[LangSmithè·Ÿè¸ª](https://smith.langchain.com/public/da23c4d8-3b33-47fd-84df-a3a582eedf84/r)

## åç»­æ­¥éª¤

åœ¨çŸ­æ—¶é—´å†…æˆ‘ä»¬å·²ç»æ¶µç›–äº†å¾ˆå¤šå†…å®¹ã€‚åœ¨ä¸Šè¿°å„èŠ‚ä»¥åŠ**æ›´æ·±å…¥äº†è§£**ä¸­æåˆ°çš„**Go deeper**æºä»£ç ä¹‹å¤–ï¼Œä¸‹ä¸€æ­¥å¯ä»¥æ¢ç´¢çš„åŠŸèƒ½ã€é›†æˆå’Œæ‰©å±•åŒ…æ‹¬ï¼š

- [è¿”å›æºæ–‡ä»¶](/use_cases/question_answering/sources): å­¦ä¹ å¦‚ä½•è¿”å›æºæ–‡ä»¶
- [æµå¼å¤„ç†](/use_cases/question_answering/streaming): å­¦ä¹ å¦‚ä½•æµå¼å¤„ç†è¾“å‡ºå’Œä¸­é—´æ­¥éª¤
- [æ·»åŠ èŠå¤©å†å²è®°å½•](/use_cases/question_answering/chat_history): å­¦ä¹ å¦‚ä½•å°†èŠå¤©å†å²è®°å½•æ·»åŠ åˆ°æ‚¨çš„åº”ç”¨ç¨‹åºä¸­

# å¿«é€Ÿå¼€å§‹

åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»åˆ›å»ºåŸºäº SQL æ•°æ®åº“çš„é—®ç­”é“¾å’Œä»£ç†çš„åŸºæœ¬æ–¹æ³•ã€‚è¿™äº›ç³»ç»Ÿå°†å…è®¸æˆ‘ä»¬å¯¹ SQL æ•°æ®åº“ä¸­çš„æ•°æ®æé—®ï¼Œå¹¶è¿”å›è‡ªç„¶è¯­è¨€çš„ç­”æ¡ˆã€‚ä¸¤è€…ä¹‹é—´çš„ä¸»è¦åŒºåˆ«åœ¨äºï¼Œæˆ‘ä»¬çš„ä»£ç†å¯ä»¥å¾ªç¯æŸ¥è¯¢æ•°æ®åº“ï¼Œä»¥å›ç­”é—®é¢˜ã€‚

## âš ï¸ å®‰å…¨æ³¨æ„äº‹é¡¹ âš ï¸

æ„å»º SQL æ•°æ®åº“çš„é—®ç­”ç³»ç»Ÿéœ€è¦æ‰§è¡Œæ¨¡å‹ç”Ÿæˆçš„ SQL æŸ¥è¯¢ã€‚è¿™æ ·åšå­˜åœ¨é£é™©ã€‚è¯·ç¡®ä¿æ•°æ®åº“è¿æ¥æƒé™å§‹ç»ˆå°½é‡é™åˆ¶åœ¨é“¾/ä»£ç†æ‰€éœ€çš„èŒƒå›´å†…ã€‚è¿™å°†å‡è½»ä½†ä¸ä¼šæ¶ˆé™¤æ„å»ºæ¨¡å‹é©±åŠ¨ç³»ç»Ÿçš„é£é™©ã€‚æœ‰å…³ä¸€èˆ¬å®‰å…¨æœ€ä½³å®è·µçš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[æ­¤å¤„](/docs/security)ã€‚

## æ¶æ„

ä»é«˜å±‚æ¥çœ‹ï¼Œä»»ä½• SQL é“¾å’Œä»£ç†çš„æ­¥éª¤å¦‚ä¸‹ï¼š

1. **å°†é—®é¢˜è½¬æ¢ä¸º SQL æŸ¥è¯¢**ï¼šæ¨¡å‹å°†ç”¨æˆ·è¾“å…¥è½¬æ¢ä¸º SQL æŸ¥è¯¢ã€‚
2. **æ‰§è¡Œ SQL æŸ¥è¯¢**ï¼šæ‰§è¡Œ SQL æŸ¥è¯¢ã€‚
3. **å›ç­”é—®é¢˜**ï¼šæ¨¡å‹ä½¿ç”¨æŸ¥è¯¢ç»“æœå›ç­”ç”¨æˆ·è¾“å…¥çš„é—®é¢˜ã€‚

![sql_usecase.png](/img/sql_usecase.png)

## è®¾ç½®

é¦–å…ˆï¼Œè·å–æ‰€éœ€çš„è½¯ä»¶åŒ…å¹¶è®¾ç½®ç¯å¢ƒå˜é‡ï¼š

```python
%pip install --upgrade --quiet  langchain langchain-community langchain-openai
```

åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ OpenAI æ¨¡å‹ï¼š

```python
import getpass
import os

os.environ["OPENAI_API_KEY"] = getpass.getpass()

# å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šä»¥ä½¿ç”¨ LangSmithã€‚éå¿…éœ€ã€‚
# os.environ["LANGCHAIN_API_KEY"] = getpass.getpass()
# os.environ["LANGCHAIN_TRACING_V2"] = "true"
```

ä¸‹é¢çš„ç¤ºä¾‹å°†ä½¿ç”¨ Chinook æ•°æ®åº“çš„ SQLite è¿æ¥ã€‚æŒ‰ç…§[è¿™äº›å®‰è£…æ­¥éª¤](https://database.guide/2-sample-databases-sqlite/)åœ¨ä¸æ­¤ notebook ç›¸åŒçš„ç›®å½•ä¸­åˆ›å»º `Chinook.db`ï¼š

* å°†[æ­¤æ–‡ä»¶](https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql)ä¿å­˜ä¸º `Chinook_Sqlite.sql`
* è¿è¡Œ `sqlite3 Chinook.db`
* è¿è¡Œ `.read Chinook_Sqlite.sql`
* æµ‹è¯• `SELECT * FROM Artist LIMIT 10;`

ç°åœ¨ï¼Œ`Chinhook.db` å·²ç»åœ¨æˆ‘ä»¬çš„ç›®å½•ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨åŸºäº SQLAlchemy çš„ `SQLDatabase` ç±»ä¸å…¶äº¤äº’ï¼š

```python
from langchain_community.utilities import SQLDatabase

db = SQLDatabase.from_uri("sqlite:///Chinook.db")
print(db.dialect)
print(db.get_usable_table_names())
db.run("SELECT * FROM Artist LIMIT 10;")
```

è¿è¡Œç»“æœï¼š

```
sqlite
['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']
[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'AntÃ´nio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]
```

å¤ªå¥½äº†ï¼æˆ‘ä»¬æœ‰ä¸€ä¸ªå¯ä»¥æŸ¥è¯¢çš„ SQL æ•°æ®åº“ã€‚ç°åœ¨è®©æˆ‘ä»¬å°è¯•å°†å…¶è¿æ¥åˆ°ä¸€ä¸ª LLMã€‚

## é“¾

è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç®€å•çš„é“¾ï¼Œå®ƒæ¥å—ä¸€ä¸ªé—®é¢˜ï¼Œå°†å…¶è½¬æ¢ä¸º SQL æŸ¥è¯¢ï¼Œæ‰§è¡ŒæŸ¥è¯¢ï¼Œå¹¶ä½¿ç”¨æŸ¥è¯¢ç»“æœå›ç­”åŸå§‹é—®é¢˜ã€‚

### å°†é—®é¢˜è½¬æ¢ä¸º SQL æŸ¥è¯¢

SQL é“¾æˆ–ä»£ç†çš„ç¬¬ä¸€æ­¥æ˜¯æ¥å—ç”¨æˆ·è¾“å…¥å¹¶å°†å…¶è½¬æ¢ä¸º SQL æŸ¥è¯¢ã€‚LangChain æä¾›äº†ä¸€ä¸ªå†…ç½®é“¾æ¥å®ç°è¿™ä¸ªåŠŸèƒ½ï¼š[create_sql_query_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)ã€‚

```python
from langchain.chains import create_sql_query_chain
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
chain = create_sql_query_chain(llm, db)
response = chain.invoke({"question": "æœ‰å¤šå°‘å‘˜å·¥"})
response
```

è¿è¡Œç»“æœï¼š

```
'SELECT COUNT(*) FROM Employee'
```

æˆ‘ä»¬å¯ä»¥æ‰§è¡Œè¿™ä¸ªæŸ¥è¯¢ä»¥ç¡®ä¿å®ƒæ˜¯æœ‰æ•ˆçš„ï¼š

```python
db.run(response)
```

è¿è¡Œç»“æœï¼š

```
[(8,)]
```

æˆ‘ä»¬å¯ä»¥æŸ¥çœ‹[LangSmith è·Ÿè¸ª](https://smith.langchain.com/public/c8fa52ea-be46-4829-bde2-52894970b830/r)ä»¥æ›´å¥½åœ°äº†è§£æ­¤é“¾çš„æ“ä½œã€‚æˆ‘ä»¬è¿˜å¯ä»¥ç›´æ¥æ£€æŸ¥é“¾çš„æç¤ºä¿¡æ¯ã€‚æˆ‘ä»¬å¯ä»¥æŸ¥çœ‹æç¤ºï¼ˆå¦‚ä¸‹æ‰€ç¤ºï¼‰ï¼Œå¯ä»¥çœ‹åˆ°å®ƒæ˜¯ï¼š

* æ–¹è¨€ç‰¹å®šçš„ã€‚åœ¨æœ¬ä¾‹ä¸­æ˜ç¡®å¼•ç”¨äº† SQLiteã€‚
* æä¾›äº†æ‰€æœ‰å¯ç”¨è¡¨çš„å®šä¹‰ã€‚
* ä¸ºæ¯ä¸ªè¡¨æä¾›äº†ä¸‰ä¸ªç¤ºä¾‹è¡Œã€‚

è¿™ç§æŠ€æœ¯å—åˆ°äº†è¯¸å¦‚[æ­¤ç±»](https://arxiv.org/pdf/2204.00498.pdf)è®ºæ–‡çš„å¯å‘ï¼Œè¯¥è®ºæ–‡å»ºè®®å‘ç”¨æˆ·æ˜¾ç¤ºç¤ºä¾‹è¡Œï¼Œå¹¶æ˜ç¡®æŒ‡å‡ºè¡¨æ ¼æœ‰åŠ©äºæé«˜æ€§èƒ½ã€‚æˆ‘ä»¬è¿˜å¯ä»¥æŸ¥çœ‹å®Œæ•´çš„æç¤ºï¼š

```python
chain.get_prompts()[0].pretty_print()
```

### æ‰§è¡Œ SQL æŸ¥è¯¢

ç°åœ¨æˆ‘ä»¬å·²ç»ç”Ÿæˆäº†ä¸€ä¸ª SQL æŸ¥è¯¢ï¼Œæˆ‘ä»¬å°†è¦æ‰§è¡Œå®ƒã€‚**è¿™æ˜¯åˆ›å»º SQL é“¾ä¸­æœ€å±é™©çš„éƒ¨åˆ†**ã€‚è¯·ä»”ç»†è€ƒè™‘æ˜¯å¦å¯ä»¥å®‰å…¨åœ°åœ¨æ•°æ®ä¸Šè¿è¡Œè‡ªåŠ¨æŸ¥è¯¢ã€‚å°½é‡å°½å¯èƒ½å‡å°‘æ•°æ®åº“è¿æ¥æƒé™ã€‚åœ¨æŸ¥è¯¢æ‰§è¡Œä¹‹å‰ï¼Œè€ƒè™‘æ·»åŠ ä¸€ä¸ªäººå·¥å®¡æ‰¹æ­¥éª¤ç»™æ‚¨çš„é“¾ï¼ˆå‚è§ä¸‹æ–‡ï¼‰ã€‚

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `QuerySQLDatabaseTool` æ–¹ä¾¿åœ°å°†æŸ¥è¯¢æ‰§è¡Œæ·»åŠ åˆ°æˆ‘ä»¬çš„é“¾ä¸­ï¼š

```python
from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool

execute_query = QuerySQLDataBaseTool(db=db)
write_query = create_sql_query_chain(llm, db)
chain = write_query | execute_query
chain.invoke({"question": "æœ‰å¤šå°‘å‘˜å·¥"})
```

è¿è¡Œç»“æœï¼š

```
'[(8,)]'
```

### å›ç­”é—®é¢˜

ç°åœ¨æˆ‘ä»¬å·²ç»æ‰¾åˆ°äº†ä¸€ç§è‡ªåŠ¨ç”Ÿæˆå’Œæ‰§è¡ŒæŸ¥è¯¢çš„æ–¹æ³•ï¼Œæˆ‘ä»¬åªéœ€è¦å°†åŸå§‹é—®é¢˜å’Œ SQL æŸ¥è¯¢ç»“æœç»„åˆèµ·æ¥ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡å†æ¬¡ä¼ é€’é—®é¢˜å’Œç»“æœåˆ° LLM æ¥å®ç°è¿™ä¸€ç‚¹ï¼š

```python
from operator import itemgetter

from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough

answer_prompt = PromptTemplate.from_template(
    """ç»™å®šä»¥ä¸‹ç”¨æˆ·é—®é¢˜ã€ç›¸åº”çš„ SQL æŸ¥è¯¢å’Œ SQL ç»“æœï¼Œè¯·å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

é—®é¢˜ï¼š{question}
SQL æŸ¥è¯¢ï¼š{query}
SQL ç»“æœï¼š{result}
ç­”æ¡ˆï¼š"""
)

answer = answer_prompt | llm | StrOutputParser()
chain = (
    RunnablePassthrough.assign(query=write_query).assign(
        result=itemgetter("query") | execute_query
    )
    | answer
)

chain.invoke({"question": "æœ‰å¤šå°‘å‘˜å·¥"})
```

è¿è¡Œç»“æœï¼š

```
'æœ‰ 8 åå‘˜å·¥ã€‚'
```
------
=======

### ä¸‹ä¸€æ­¥

å¯¹äºæ›´å¤æ‚çš„æŸ¥è¯¢ç”Ÿæˆï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºfew-shot promptsæˆ–æ·»åŠ æŸ¥è¯¢æ£€æŸ¥æ­¥éª¤ã€‚äº†è§£æ›´å¤šé«˜çº§æŠ€å·§ï¼Œè¯·æŸ¥çœ‹ä»¥ä¸‹å†…å®¹ï¼š

* [æç¤ºç­–ç•¥](/use_cases/sql/prompting)ï¼šé«˜çº§æç¤ºå·¥ç¨‹æŠ€æœ¯ã€‚
* [æŸ¥è¯¢æ£€æŸ¥](/use_cases/sql/query_checking)ï¼šæ·»åŠ æŸ¥è¯¢éªŒè¯å’Œé”™è¯¯å¤„ç†ã€‚
* [å¤§æ•°æ®åº“](/use_cases/sql/large_db)ï¼šå¤„ç†å¤§å‹æ•°æ®åº“çš„æŠ€æœ¯ã€‚

## Agents

LangChainå…·æœ‰SQL Agentï¼Œå®ƒæä¾›äº†ä¸€ç§ä¸SQLæ•°æ®åº“æ›´çµæ´»äº¤äº’çš„æ–¹å¼ã€‚ä½¿ç”¨SQL Agentçš„ä¸»è¦ä¼˜åŠ¿æ˜¯ï¼š

- å®ƒå¯ä»¥æ ¹æ®æ•°æ®åº“çš„æ¨¡å¼å’Œå†…å®¹å›ç­”é—®é¢˜ï¼ˆä¾‹å¦‚æè¿°ç‰¹å®šè¡¨ï¼‰ã€‚
- å®ƒå¯ä»¥é€šè¿‡è¿è¡Œç”Ÿæˆçš„æŸ¥è¯¢ã€æ•è·å›æº¯å¹¶æ­£ç¡®é‡æ–°ç”Ÿæˆæ¥ä»é”™è¯¯ä¸­æ¢å¤ã€‚
- å®ƒå¯ä»¥å›ç­”éœ€è¦å¤šä¸ªä¾èµ–æŸ¥è¯¢çš„é—®é¢˜ã€‚
- å®ƒå°†åªè€ƒè™‘ç›¸å…³è¡¨çš„æ¨¡å¼ï¼Œä»è€ŒèŠ‚çœä»¤ç‰Œã€‚

è¦åˆå§‹åŒ–ä»£ç†ï¼Œæˆ‘ä»¬ä½¿ç”¨`create_sql_agent`å‡½æ•°ã€‚æ­¤ä»£ç†åŒ…å«`SQLDatabaseToolkit`ï¼Œå…¶ä¸­åŒ…å«ä»¥ä¸‹å·¥å…·ï¼š

* åˆ›å»ºå’Œæ‰§è¡ŒæŸ¥è¯¢
* æ£€æŸ¥æŸ¥è¯¢è¯­æ³•
* æ£€ç´¢è¡¨æè¿°
* ...ç­‰ç­‰

### åˆå§‹åŒ–ä»£ç†


```python
from langchain_community.agent_toolkits import create_sql_agent

agent_executor = create_sql_agent(llm, db=db, agent_type="openai-tools", verbose=True)
```


```python
agent_executor.invoke(
    {
        "input": "åˆ—å‡ºæ¯ä¸ªå›½å®¶çš„æ€»é”€å”®é¢ã€‚å“ªä¸ªå›½å®¶çš„å®¢æˆ·æ¶ˆè´¹æœ€å¤šï¼Ÿ"
    }
)
```

    
    
    [1m> è¿›å…¥æ–°çš„ä»£ç†æ‰§è¡Œé“¾...[0m
    [32;1m[1;3m
    è°ƒç”¨: `sql_db_list_tables` ä½¿ç”¨ `{}`
    
    
    [0m[38;5;200m[1;3mAlbum, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track[0m[32;1m[1;3m
    è°ƒç”¨: `sql_db_schema` ä½¿ç”¨ `Invoice,Customer`
    
    
    [0m[33;1m[1;3m
    CREATE TABLE "Customer" (
    	"CustomerId" INTEGER NOT NULL, 
    	"FirstName" NVARCHAR(40) NOT NULL, 
    	"LastName" NVARCHAR(20) NOT NULL, 
    	"Company" NVARCHAR(80), 
    	"Address" NVARCHAR(70), 
    	"City" NVARCHAR(40), 
    	"State" NVARCHAR(40), 
    	"Country" NVARCHAR(40), 
    	"PostalCode" NVARCHAR(10), 
    	"Phone" NVARCHAR(24), 
    	"Fax" NVARCHAR(24), 
    	"Email" NVARCHAR(60) NOT NULL, 
    	"SupportRepId" INTEGER, 
    	PRIMARY KEY ("CustomerId"), 
    	FOREIGN KEY("SupportRepId") REFERENCES "Employee" ("EmployeeId")
    )
    
    /*
    Customerè¡¨çš„3è¡Œ:
    CustomerId	FirstName	LastName	Company	Address	City	State	Country	PostalCode	Phone	Fax	Email	SupportRepId
    1	LuÃ­s	GonÃ§alves	Embraer - Empresa Brasileira de AeronÃ¡utica S.A.	Av. Brigadeiro Faria Lima, 2170	SÃ£o JosÃ© dos Campos	SP	Brazil	12227-000	+55 (12) 3923-5555	+55 (12) 3923-5566	luisg@embraer.com.br	3
    2	Leonie	KÃ¶hler	None	Theodor-Heuss-StraÃŸe 34	Stuttgart	None	Germany	70174	+49 0711 2842222	None	leonekohler@surfeu.de	5
    3	FranÃ§ois	Tremblay	None	1498 rue BÃ©langer	MontrÃ©al	QC	Canada	H2G 1A7	+1 (514) 721-4711	None	ftremblay@gmail.com	3
    */
    
    
    CREATE TABLE "Invoice" (
    	"InvoiceId" INTEGER NOT NULL, 
    	"CustomerId" INTEGER NOT NULL, 
    	"InvoiceDate" DATETIME NOT NULL, 
    	"BillingAddress" NVARCHAR(70), 
    	"BillingCity" NVARCHAR(40), 
    	"BillingState" NVARCHAR(40), 
    	"BillingCountry" NVARCHAR(40), 
    	"BillingPostalCode" NVARCHAR(10), 
    	"Total" NUMERIC(10, 2) NOT NULL, 
    	PRIMARY KEY ("InvoiceId"), 
    	FOREIGN KEY("CustomerId") REFERENCES "Customer" ("CustomerId")
    )
    
    /*
    Invoiceè¡¨çš„3è¡Œ:
    InvoiceId	CustomerId	InvoiceDate	BillingAddress	BillingCity	BillingState	BillingCountry	BillingPostalCode	Total
    1	2	2009-01-01 00:00:00	Theodor-Heuss-StraÃŸe 34	Stuttgart	None	Germany	70174	1.98
    2	4	2009-01-02 00:00:00	UllevÃ¥lsveien 14	Oslo	None	Norway	0171	3.96
    3	8	2009-01-03 00:00:00	GrÃ©trystraat 63	Brussels	None	Belgium	1000	5.94
    */[0m[32;1m[1;3m
    è°ƒç”¨: `sql_db_query` ä½¿ç”¨ `SELECT c.Country, SUM(i.Total) AS TotalSales FROM Invoice i JOIN Customer c ON i.CustomerId = c.CustomerId GROUP BY c.Country ORDER BY TotalSales DESC LIMIT 10;`
    å“åº”: è¦åˆ—å‡ºæ¯ä¸ªå›½å®¶çš„æ€»é”€å”®é¢ï¼Œæˆ‘å¯ä»¥æŸ¥è¯¢â€œInvoiceâ€å’Œâ€œCustomerâ€è¡¨ã€‚æˆ‘å°†æ ¹æ®â€œCustomerIdâ€åˆ—è”æ¥è¿™äº›è¡¨ï¼Œå¹¶æŒ‰ç…§â€œBillingCountryâ€åˆ—å¯¹ç»“æœè¿›è¡Œåˆ†ç»„ã€‚ç„¶åï¼Œæˆ‘å°†è®¡ç®—â€œTotalâ€åˆ—çš„æ€»å’Œä»¥è·å–æ¯ä¸ªå›½å®¶çš„æ€»é”€å”®é¢ã€‚æœ€åï¼Œæˆ‘å°†æŒ‰ç…§æ€»é”€å”®é¢çš„é™åºå¯¹ç»“æœè¿›è¡Œæ’åºã€‚
    
    è¿™æ˜¯SQLæŸ¥è¯¢è¯­å¥ï¼š
    
    ```sql
    SELECT c.Country, SUM(i.Total) AS TotalSales
    FROM Invoice i
    JOIN Customer c ON i.CustomerId = c.CustomerId
    GROUP BY c.Country
    ORDER BY TotalSales DESC
    LIMIT 10;
    ```
    
    ç°åœ¨ï¼Œæˆ‘å°†æ‰§è¡Œæ­¤æŸ¥è¯¢ä»¥è·å–æ¯ä¸ªå›½å®¶çš„æ€»é”€å”®é¢ã€‚
    
    [0m[36;1m[1;3m[('USA', 523.0600000000003), ('Canada', 303.9599999999999), ('France', 195.09999999999994), ('Brazil', 190.09999999999997), ('Germany', 156.48), ('United Kingdom', 112.85999999999999), ('Czech Republic', 90.24000000000001), ('Portugal', 77.23999999999998), ('India', 75.25999999999999), ('Chile', 46.62)][0m[32;1m[1;3mæ¯ä¸ªå›½å®¶çš„æ€»é”€å”®é¢å¦‚ä¸‹ï¼š
    
    1. ç¾å›½ï¼š523.06ç¾å…ƒ
    2. åŠ æ‹¿å¤§ï¼š303.96ç¾å…ƒ
    3. æ³•å›½ï¼š195.10ç¾å…ƒ
    4. å·´è¥¿ï¼š190.10ç¾å…ƒ
    5. å¾·å›½ï¼š156.48ç¾å…ƒ
    6. è‹±å›½ï¼š112.86ç¾å…ƒ
    7. æ·å…‹å…±å’Œå›½ï¼š90.24ç¾å…ƒ
    8. è‘¡è„ç‰™ï¼š77.24ç¾å…ƒ
    9. å°åº¦ï¼š75.26ç¾å…ƒ
    10. æ™ºåˆ©ï¼š46.62ç¾å…ƒ
    
    å›ç­”ç¬¬äºŒä¸ªé—®é¢˜ï¼Œæ¶ˆè´¹æœ€å¤šçš„å›½å®¶æ˜¯ç¾å›½ï¼Œæ€»é”€å”®é¢ä¸º523.06ç¾å…ƒã€‚[0m
    
    [1m> å®Œæˆé“¾æ¡ã€‚[0m
    




    {'input': 'åˆ—å‡ºæ¯ä¸ªå›½å®¶çš„æ€»é”€å”®é¢ã€‚å“ªä¸ªå›½å®¶çš„å®¢æˆ·æ¶ˆè´¹æœ€å¤šï¼Ÿ',
     'output': 'æ¯ä¸ªå›½å®¶çš„æ€»é”€å”®é¢å¦‚ä¸‹ï¼š\n\n1. ç¾å›½ï¼š523.06ç¾å…ƒ\n2. åŠ æ‹¿å¤§ï¼š303.96ç¾å…ƒ\n3. æ³•å›½ï¼š195.10ç¾å…ƒ\n4. å·´è¥¿ï¼š190.10ç¾å…ƒ\n5. å¾·å›½ï¼š156.48ç¾å…ƒ\n6. è‹±å›½ï¼š112.86ç¾å…ƒ\n7. æ·å…‹å…±å’Œå›½ï¼š90.24ç¾å…ƒ\n8. è‘¡è„ç‰™ï¼š77.24ç¾å…ƒ\n9. å°åº¦ï¼š75.26ç¾å…ƒ\n10. æ™ºåˆ©ï¼š46.62ç¾å…ƒ\n\nå›ç­”ç¬¬äºŒä¸ªé—®é¢˜ï¼Œæ¶ˆè´¹æœ€å¤šçš„å›½å®¶æ˜¯ç¾å›½ï¼Œæ€»é”€å”®é¢ä¸º523.06ç¾å…ƒã€‚'}




```python
agent_executor.invoke({"input": "æè¿°playlisttrackè¡¨"})
```

    
    
    [1m> è¿›å…¥æ–°çš„ä»£ç†æ‰§è¡Œé“¾...[0m
    [32;1m[1;3m
    è°ƒç”¨: `sql_db_list_tables` ä½¿ç”¨ `{}`
    
    
    [0m[38;5;200m[1;3mAlbum, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track[0m[32;1m[1;3m
    è°ƒç”¨: `sql_db_schema` ä½¿ç”¨ `PlaylistTrack`
    
    
    [0m[33;1m[1;3m
    CREATE TABLE "PlaylistTrack" (
    	"PlaylistId" INTEGER NOT NULL, 
    	"TrackId" INTEGER NOT NULL, 
    	PRIMARY KEY ("PlaylistId", "TrackId"), 
    	FOREIGN KEY("TrackId") REFERENCES "Track" ("TrackId"), 
    	FOREIGN KEY("PlaylistId") REFERENCES "Playlist" ("PlaylistId")
    )
    
    /*
    PlaylistTrackè¡¨çš„3è¡Œ:
    PlaylistId	TrackId
    1	3402
    1	3389
    1	3390
    */[0m[32;1m[1;3m`PlaylistTrack`è¡¨æœ‰ä¸¤åˆ—ï¼š`PlaylistId`å’Œ`TrackId`ã€‚å®ƒæ˜¯ä¸€ä¸ªè”æ¥è¡¨ï¼Œè¡¨ç¤ºæ’­æ”¾åˆ—è¡¨å’ŒéŸ³è½¨ä¹‹é—´çš„å¤šå¯¹å¤šå…³ç³»ã€‚
    
    è¿™æ˜¯`PlaylistTrack`è¡¨çš„æ¨¡å¼ï¼š
    
    ```
    CREATE TABLE "PlaylistTrack" (
    	"PlaylistId" INTEGER NOT NULL, 
    	"TrackId" INTEGER NOT NULL, 
    	PRIMARY KEY ("PlaylistId", "TrackId"), 
    	FOREIGN KEY("TrackId") REFERENCES "Track" ("TrackId"), 
    	FOREIGN KEY("PlaylistId") REFERENCES "Playlist" ("PlaylistId")
    )
    ```
    
    `PlaylistId`åˆ—æ˜¯å¯¹`Playlist`è¡¨ä¸­çš„`PlaylistId`åˆ—çš„å¤–é”®å¼•ç”¨ã€‚`TrackId`åˆ—æ˜¯å¯¹`Track`è¡¨ä¸­çš„`TrackId`åˆ—çš„å¤–é”®å¼•ç”¨ã€‚
    
    è¿™æ˜¯`PlaylistTrack`è¡¨çš„ä¸‰ä¸ªç¤ºä¾‹è¡Œï¼š
    
    ```
    PlaylistId   TrackId
    1            3402
    1            3389
    1            3390
    ```
    
    å¦‚æœéœ€è¦å…¶ä»–å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚[0m
    
    [1m> å®Œæˆé“¾æ¡ã€‚[0m
    




    {'input': 'æè¿°playlisttrackè¡¨',
     'output': '`PlaylistTrack`è¡¨æœ‰ä¸¤åˆ—ï¼š`PlaylistId`å’Œ`TrackId`ã€‚å®ƒæ˜¯ä¸€ä¸ªè”æ¥è¡¨ï¼Œè¡¨ç¤ºæ’­æ”¾åˆ—è¡¨å’ŒéŸ³è½¨ä¹‹é—´çš„å¤šå¯¹å¤šå…³ç³»ã€‚\n\nè¿™æ˜¯`PlaylistTrack`è¡¨çš„æ¨¡å¼ï¼š\n\n```\nCREATE TABLE "PlaylistTrack" (\n\t"PlaylistId" INTEGER NOT NULL, \n\t"TrackId" INTEGER NOT NULL, \n\tPRIMARY KEY ("PlaylistId", "TrackId"), \n\tFOREIGN KEY("TrackId") REFERENCES "Track" ("TrackId"), \n\tFOREIGN KEY("PlaylistId") REFERENCES "Playlist" ("PlaylistId")\n)\n```\n\n`PlaylistId`åˆ—æ˜¯å¯¹`Playlist`è¡¨ä¸­çš„`PlaylistId`åˆ—çš„å¤–é”®å¼•ç”¨ã€‚`TrackId`åˆ—æ˜¯å¯¹`Track`è¡¨ä¸­çš„`TrackId`åˆ—çš„å¤–é”®å¼•ç”¨ã€‚\n\nè¿™æ˜¯`PlaylistTrack`è¡¨çš„ä¸‰ä¸ªç¤ºä¾‹è¡Œï¼š\n\n```\nPlaylistId   TrackId\n1            3402\n1            3389\n1            3390\n```\n\nå¦‚æœéœ€è¦å…¶ä»–å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚'}### ä¸‹ä¸€æ­¥

æœ‰å…³å¦‚ä½•ä½¿ç”¨å’Œè‡ªå®šä¹‰ä»£ç†çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[ä»£ç†](/use_cases/sql/agents)é¡µé¢ã€‚# å¿«é€Ÿå…¥é—¨

åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»åˆ›å»ºè°ƒç”¨å·¥å…·çš„é“¾å’Œä»£ç†çš„åŸºæœ¬æ–¹æ³•ã€‚å·¥å…·å¯ä»¥æ˜¯å‡ ä¹ä»»ä½•ä¸œè¥¿ - APIã€å‡½æ•°ã€æ•°æ®åº“ç­‰ã€‚å·¥å…·ä½¿æˆ‘ä»¬èƒ½å¤Ÿæ‰©å±•æ¨¡å‹çš„èƒ½åŠ›ï¼Œä½¿å…¶ä¸ä»…èƒ½å¤Ÿè¾“å‡ºæ–‡æœ¬/æ¶ˆæ¯ã€‚ä½¿ç”¨å·¥å…·ä¸æ¨¡å‹çš„å…³é”®æ˜¯æ­£ç¡®æç¤ºæ¨¡å‹å¹¶è§£æå…¶å“åº”ï¼Œä»¥ä¾¿é€‰æ‹©åˆé€‚çš„å·¥å…·å¹¶ä¸ºå…¶æä¾›åˆé€‚çš„è¾“å…¥ã€‚

## è®¾ç½®

æˆ‘ä»¬éœ€è¦å®‰è£…ä»¥ä¸‹è½¯ä»¶åŒ…æ¥å®Œæˆæœ¬æŒ‡å—ï¼š

```python
%pip install --upgrade --quiet langchain langchain-openai
```

å¹¶è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼š

```python
import getpass
import os

os.environ["OPENAI_API_KEY"] = getpass.getpass()

# å¦‚æœæ‚¨æƒ³ä½¿ç”¨LangSmithï¼Œè¯·å–æ¶ˆä¸‹é¢çš„æ³¨é‡Š
# os.environ["LANGCHAIN_TRACING_V2"] = "true"
# os.environ["LANGCHAIN_API_KEY"] = getpass.getpass()
```

## åˆ›å»ºå·¥å…·

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªè¦è°ƒç”¨çš„å·¥å…·ã€‚å¯¹äºæœ¬ç¤ºä¾‹ï¼Œæˆ‘ä»¬å°†ä»ä¸€ä¸ªå‡½æ•°åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰å·¥å…·ã€‚æœ‰å…³åˆ›å»ºè‡ªå®šä¹‰å·¥å…·çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[æ­¤æŒ‡å—](/modules/tools/)ã€‚


```python
from langchain_core.tools import tool


@tool
def multiply(first_int: int, second_int: int) -> int:
    """Multiply two integers together."""
    return first_int * second_int
```


```python
print(multiply.name)
print(multiply.description)
print(multiply.args)
```

    multiply
    multiply(first_int: int, second_int: int) -> int - Multiply two integers together.
    {'first_int': {'title': 'First Int', 'type': 'integer'}, 'second_int': {'title': 'Second Int', 'type': 'integer'}}
    


```python
multiply.invoke({"first_int": 4, "second_int": 5})
```




    20



## é“¾

å¦‚æœæˆ‘ä»¬çŸ¥é“åªéœ€è¦ä½¿ç”¨å·¥å…·å›ºå®šæ¬¡æ•°ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªé“¾æ¥å®ç°ã€‚è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç®€å•çš„é“¾ï¼Œåªéœ€å°†ç”¨æˆ·æŒ‡å®šçš„æ•°å­—ç›¸ä¹˜ã€‚

![chain](/img/tool_chain.svg)

### å‡½æ•°è°ƒç”¨
ä½¿ç”¨å·¥å…·ä¸LLMä¸€èµ·ä½¿ç”¨æœ€å¯é çš„æ–¹æ³•ä¹‹ä¸€æ˜¯ä½¿ç”¨å‡½æ•°è°ƒç”¨APIï¼ˆæœ‰æ—¶ä¹Ÿç§°ä¸ºå·¥å…·è°ƒç”¨æˆ–å¹¶è¡Œå‡½æ•°è°ƒç”¨ï¼‰ã€‚è¿™ä»…é€‚ç”¨äºæ˜¾å¼æ”¯æŒå‡½æ•°è°ƒç”¨ï¼ˆå¦‚OpenAIæ¨¡å‹ï¼‰çš„æ¨¡å‹ã€‚è¦äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[å‡½æ•°è°ƒç”¨æŒ‡å—](/modules/model_io/chat/function_calling)ã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬å°†å®šä¹‰æˆ‘ä»¬çš„æ¨¡å‹å’Œå·¥å…·ã€‚æˆ‘ä»¬å°†ä»ä¸€ä¸ªå•ä¸€å·¥å…· `multiply` å¼€å§‹ã€‚


```python
from langchain_openai.chat_models import ChatOpenAI

model = ChatOpenAI(model="gpt-3.5-turbo-1106")
```

ç„¶åï¼Œæˆ‘ä»¬å°†å°†æˆ‘ä»¬çš„LangChain Toolè½¬æ¢ä¸ºOpenAIæ ¼å¼çš„JSONSchemaå‡½æ•°ï¼Œå¹¶ç»‘å®šä¸º`tools`å‚æ•°ï¼Œä»¥ä¾›æ‰€æœ‰ChatOpenAIè°ƒç”¨ä½¿ç”¨ã€‚ç”±äºæˆ‘ä»¬åªæœ‰ä¸€ä¸ªå·¥å…·ï¼Œå¹¶ä¸”åœ¨è¿™ä¸ªåˆå§‹é“¾ä¸­æˆ‘ä»¬å¸Œæœ›ç¡®ä¿å®ƒå§‹ç»ˆè¢«ä½¿ç”¨ï¼Œæˆ‘ä»¬è¿˜å°†æŒ‡å®š `tool_choice`ã€‚æœ‰å…³è¿™äº›å‚æ•°çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[OpenAIèŠå¤©APIå‚è€ƒ](https://platform.openai.com/docs/api-reference/chat/create#chat-create-tool_choice)ï¼š


```python
model_with_tools = model.bind_tools([multiply], tool_choice="multiply")
```


```python
model_with_tools.kwargs["tools"]
```




    [{'type': 'function',
      'function': {'name': 'multiply',
       'description': 'multiply(first_int: int, second_int: int) -> int - Multiply two integers together.',
       'parameters': {'type': 'object',
        'properties': {'first_int': {'type': 'integer'},
         'second_int': {'type': 'integer'}},
        'required': ['first_int', 'second_int']}}}]




```python
model_with_tools.kwargs["tool_choice"]
```




    {'type': 'function', 'function': {'name': 'multiply'}}



ç°åœ¨ï¼Œæˆ‘ä»¬å°†ç”¨JsonOutputToolsParserå°†æˆ‘ä»¬çš„å·¥å…·è°ƒç”¨æ¨¡å‹ä¸ä¸€ä¸ªæ„æˆé“¾ã€‚JsonOutputToolsParseræ˜¯ä¸€ä¸ªå†…ç½®çš„LangChainè¾“å‡ºè§£æå™¨ï¼Œå®ƒå°†OpenAIå‡½æ•°è°ƒç”¨çš„å“åº”è½¬æ¢ä¸ºåŒ…å«å·¥å…·å’Œç”¨äºè°ƒç”¨å®ƒä»¬çš„å‚æ•°çš„`{"type": "TOOL_NAME", "args": {...}}`å­—å…¸çš„åˆ—è¡¨ã€‚


```python
from langchain.output_parsers import JsonOutputToolsParser

chain = model_with_tools | JsonOutputToolsParser()
chain.invoke("What's four times 23")
```




    [{'type': 'multiply', 'args': {'first_int': 4, 'second_int': 23}}]



ç”±äºæˆ‘ä»¬çŸ¥é“æˆ‘ä»¬æ€»æ˜¯è°ƒç”¨ `multiply` å·¥å…·ï¼Œæˆ‘ä»¬å¯ä»¥ç¨å¾®ç®€åŒ–æˆ‘ä»¬çš„è¾“å‡ºï¼Œåªè¿”å› `multiply` å·¥å…·çš„å‚æ•°ï¼Œä½¿ç”¨ `JsonOutputKeyToolsParser`ã€‚ä¸ºäº†è¿›ä¸€æ­¥ç®€åŒ–ï¼Œæˆ‘ä»¬è¿˜å°†æŒ‡å®š `first_tool_only=True`ï¼Œè¿™æ ·è¾“å‡ºè§£æå™¨è¿”å›çš„åªæ˜¯ç¬¬ä¸€ä¸ªå·¥å…·è°ƒç”¨ï¼Œè€Œä¸æ˜¯å·¥å…·è°ƒç”¨çš„åˆ—è¡¨ã€‚


```python
from langchain.output_parsers import JsonOutputKeyToolsParser

chain = model_with_tools | JsonOutputKeyToolsParser(
    key_name="multiply", first_tool_only=True
)
chain.invoke("What's four times 23")
```




    {'first_int': 4, 'second_int': 23}



### è°ƒç”¨å·¥å…·

å¤ªæ£’äº†ï¼æˆ‘ä»¬èƒ½å¤Ÿç”Ÿæˆå·¥å…·è°ƒç”¨ã€‚ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬æƒ³è¦å®é™…è°ƒç”¨å·¥å…·æ€ä¹ˆåŠï¼Ÿæˆ‘ä»¬åªéœ€è¦å°†å®ƒä»¬ä¼ é€’ç»™å·¥å…·å³å¯ï¼š


```python
from operator import itemgetter

# æ³¨æ„ï¼š`multiply` ç»“å°¾çš„ `.map()` å¯ä»¥å…è®¸æˆ‘ä»¬ä¼ å…¥ä¸€ä¸ª `multiply` å‚æ•°åˆ—è¡¨ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå•ç‹¬çš„å‚æ•°ã€‚
chain = (
    model_with_tools
    | JsonOutputKeyToolsParser(key_name="multiply", first_tool_only=True)
    | multiply
)
chain.invoke("What's four times 23")
```




    92



## ä»£ç†

å½“æˆ‘ä»¬çŸ¥é“ä»»ä½•ç”¨æˆ·è¾“å…¥æ‰€éœ€çš„ç‰¹å®šå·¥å…·ä½¿ç”¨é¡ºåºæ—¶ï¼Œé“¾éå¸¸æœ‰ç”¨ã€‚ä½†å¯¹äºæŸäº›ç”¨ä¾‹ï¼Œæˆ‘ä»¬ä½¿ç”¨å·¥å…·çš„æ¬¡æ•°å–å†³äºè¾“å…¥ã€‚åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›è®©æ¨¡å‹è‡ªå·±å†³å®šä½¿ç”¨å·¥å…·çš„æ¬¡æ•°å’Œé¡ºåºã€‚[ä»£ç†](/modules/agents/)å¯ä»¥å®ç°è¿™ä¸€ç‚¹ã€‚

LangChainæä¾›äº†è®¸å¤šå†…ç½®ä»£ç†ï¼Œé’ˆå¯¹ä¸åŒçš„ç”¨ä¾‹è¿›è¡Œäº†ä¼˜åŒ–ã€‚åœ¨è¿™é‡Œé˜…è¯»æ‰€æœ‰[ä»£ç†ç±»å‹](/modules/agents/agent_types/)çš„ç›¸å…³ä¿¡æ¯ã€‚

ä½œä¸ºç¤ºä¾‹ï¼Œè®©æˆ‘ä»¬è¯•è¯•OpenAIå·¥å…·ä»£ç†ï¼Œå®ƒåˆ©ç”¨äº†æ–°çš„OpenAIå·¥å…·è°ƒç”¨APIï¼ˆè¿™ä»…é€‚ç”¨äºæœ€æ–°çš„OpenAIæ¨¡å‹ï¼Œä¸å‡½æ•°è°ƒç”¨ä¸åŒï¼Œæ¨¡å‹å¯ä»¥ä¸€æ¬¡è¿”å›å¤šä¸ªå‡½æ•°è°ƒç”¨ï¼‰ã€‚

![agent](/img/tool_agent.svg)


```python
from langchain import hub
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_openai import ChatOpenAI
```


```python# è·å¾—è¦ä½¿ç”¨çš„æç¤º - æ‚¨å¯ä»¥ä¿®æ”¹å®ƒï¼
prompt = hub.pull("hwchase17/openai-tools-agent")
prompt.messages
```




    [SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),
     MessagesPlaceholder(variable_name='chat_history', optional=True),
     HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),
     MessagesPlaceholder(variable_name='agent_scratchpad')]



ä»£ç†å·¥å…·è¿˜å¾ˆæ£’ï¼Œå› ä¸ºå®ƒä»¬ä½¿ä½¿ç”¨å¤šä¸ªå·¥å…·å˜å¾—å®¹æ˜“ã€‚è¦äº†è§£å¦‚ä½•æ„å»ºä½¿ç”¨å¤šä¸ªå·¥å…·çš„é“¾å¼ç»“æ„ï¼Œè¯·æŸ¥çœ‹[Chains with multiple tools](/use_cases/tool_use/multiple_tools)é¡µé¢ã€‚


```python
@tool
def add(first_int: int, second_int: int) -> int:
    "Add two integers."
    return first_int + second_int


@tool
def exponentiate(base: int, exponent: int) -> int:
    "Exponentiate the base to the exponent power."
    return base**exponent


tools = [multiply, add, exponentiate]
```


```python
# é€‰æ‹©å°†é©±åŠ¨ä»£ç†çš„LLM
# åªæœ‰æŸäº›æ¨¡å‹æ”¯æŒè¿™ä¸ª
model = ChatOpenAI(model="gpt-3.5-turbo-1106", temperature=0)

# æ„å»ºOpenAI Toolsä»£ç†
agent = create_openai_tools_agent(model, tools, prompt)
```


```python
# é€šè¿‡ä¼ å…¥ä»£ç†å’Œå·¥å…·åˆ›å»ºä»£ç†æ‰§è¡Œå™¨
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
```

æœ‰äº†ä»£ç†ï¼Œæˆ‘ä»¬å¯ä»¥è¯¢é—®éœ€è¦ä»»æ„å¤šæ¬¡ä½¿ç”¨å·¥å…·çš„é—®é¢˜ï¼š


```python
agent_executor.invoke(
    {
        "input": "Take 3 to the fifth power and multiply that by the sum of twelve and three, then square the whole result"
    }
)
```

    
    
    [1m> è¿›å…¥æ–°çš„AgentExecutoré“¾...[0m
    [32;1m[1;3m
    è°ƒç”¨: `exponentiate` ä½¿ç”¨ `{'base': 3, 'exponent': 5}`
    
    
    [0m[38;5;200m[1;3m243[0m[32;1m[1;3m
    è°ƒç”¨: `add` ä½¿ç”¨ `{'first_int': 12, 'second_int': 3}`
    
    
    [0m[33;1m[1;3m15[0m[32;1m[1;3m
    è°ƒç”¨: `multiply` ä½¿ç”¨ `{'first_int': 243, 'second_int': 15}`
    
    
    [0m[36;1m[1;3m3645[0m[32;1m[1;3m
    è°ƒç”¨: `exponentiate` ä½¿ç”¨ `{'base': 3645, 'exponent': 2}`
    
    
    [0m[38;5;200m[1;3m13286025[0m[32;1m[1;3må°†3çš„äº”æ¬¡æ–¹ä¸12å’Œ3çš„å’Œç›¸ä¹˜ï¼Œç„¶åå°†æ•´ä¸ªç»“æœå¹³æ–¹çš„ç»“æœä¸º13,286,025ã€‚[0m
    
    [1m> å®Œæˆé“¾å¼ç»“æ„ã€‚[0m
    




    {'input': 'Take 3 to the fifth power and multiply that by the sum of twelve and three, then square the whole result',
     'output': 'å°†3çš„äº”æ¬¡æ–¹ä¸12å’Œ3çš„å’Œç›¸ä¹˜ï¼Œç„¶åå°†æ•´ä¸ªç»“æœå¹³æ–¹çš„ç»“æœä¸º13,286,025ã€‚'}



## ä¸‹ä¸€æ­¥æ“ä½œ

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å·²ç»ä»‹ç»äº†ä½¿ç”¨é“¾å¼ç»“æ„å’Œä»£ç†çš„åŸºæœ¬æ–¹æ³•ã€‚æˆ‘ä»¬å»ºè®®æ‚¨åœ¨ä¸‹é¢çš„ç« èŠ‚ä¸­ç»§ç»­æ¢ç´¢ï¼š

- [ä»£ç†å·¥å…·](/modules/agents/)ï¼šä¸ä»£ç†ç›¸å…³çš„ä¸€åˆ‡ã€‚
- [åœ¨å¤šä¸ªå·¥å…·ä¹‹é—´è¿›è¡Œé€‰æ‹©](/use_cases/tool_use/multiple_tools)ï¼šå¦‚ä½•åˆ›å»ºä»å¤šä¸ªå·¥å…·ä¸­é€‰æ‹©çš„å·¥å…·é“¾ã€‚
- [æç¤ºå·¥å…·ä½¿ç”¨](/use_cases/tool_use/prompting)ï¼šå¦‚ä½•åˆ›å»ºç›´æ¥æç¤ºæ¨¡å‹è€Œä¸ä½¿ç”¨å‡½æ•°è°ƒç”¨APIçš„å·¥å…·é“¾ã€‚
- [å¹¶è¡Œå·¥å…·ä½¿ç”¨](/use_cases/tool_use/parallel)ï¼šå¦‚ä½•ä¸€æ¬¡è°ƒç”¨å¤šä¸ªå·¥å…·çš„å·¥å…·é“¾ã€‚