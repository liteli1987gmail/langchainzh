
# è‡ªå®šä¹‰æ–‡æ¡£åŠ è½½å™¨

## æ¦‚è¿°

åŸºäºLLMsçš„åº”ç”¨ç¨‹åºé€šå¸¸æ¶‰åŠä»æ•°æ®åº“æˆ–æ–‡ä»¶ï¼ˆå¦‚PDFï¼‰ä¸­æå–æ•°æ®ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºLLMså¯ä»¥åˆ©ç”¨çš„æ ¼å¼ã€‚åœ¨LangChainä¸­ï¼Œè¿™é€šå¸¸æ¶‰åŠåˆ›å»ºæ–‡æ¡£å¯¹è±¡ï¼Œè¯¥å¯¹è±¡å°è£…äº†æå–çš„æ–‡æœ¬ï¼ˆ`page_content`ï¼‰ä»¥åŠåŒ…å«æœ‰å…³æ–‡æ¡£è¯¦ç»†ä¿¡æ¯çš„å…ƒæ•°æ® - ä¸€ä¸ªåŒ…å«æœ‰å…³æ–‡æ¡£çš„ä½œè€…å§“åæˆ–å‘å¸ƒæ—¥æœŸç­‰è¯¦ç»†ä¿¡æ¯çš„å­—å…¸ã€‚

`Document`å¯¹è±¡é€šå¸¸è¢«æ ¼å¼åŒ–ä¸ºæç¤ºï¼Œç„¶åè¢«é¦ˆé€åˆ°LLMä¸­ï¼Œå…è®¸LLMä½¿ç”¨`Document`ä¸­çš„ä¿¡æ¯ç”Ÿæˆæ‰€éœ€çš„å“åº”ï¼ˆä¾‹å¦‚ï¼Œå¯¹æ–‡æ¡£è¿›è¡Œæ€»ç»“ï¼‰ã€‚`Documents`å¯ä»¥ç«‹å³ä½¿ç”¨ï¼Œä¹Ÿå¯ä»¥ç´¢å¼•åˆ°çŸ¢é‡å­˜å‚¨ä»¥ä¾›å°†æ¥æ£€ç´¢å’Œä½¿ç”¨ã€‚

æ–‡æ¡£åŠ è½½çš„ä¸»è¦æŠ½è±¡ä¸ºï¼š

| ç»„ä»¶           | æè¿°                          |
|----------------|----------------------------|
| Document       | åŒ…å«`text`å’Œ`metadata`    |
| BaseLoader     | ç”¨äºå°†åŸå§‹æ•°æ®è½¬æ¢ä¸º`Documents`  |
| Blob           | äºŒè¿›åˆ¶æ•°æ®çš„è¡¨ç¤ºï¼Œå¯ä»¥ä½äºæ–‡ä»¶æˆ–å†…å­˜ä¸­  |
| BaseBlobParser | é€»è¾‘è§£æ`Blob`ä»¥äº§ç”Ÿ`Document`å¯¹è±¡ |

æœ¬æŒ‡å—å°†æ¼”ç¤ºå¦‚ä½•ç¼–å†™è‡ªå®šä¹‰æ–‡æ¡£åŠ è½½å’Œæ–‡ä»¶è§£æé€»è¾‘ï¼›å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•ï¼š

1. é€šè¿‡ä»`BaseLoader`ç»§æ‰¿è€Œåˆ›å»ºæ ‡å‡†æ–‡æ¡£åŠ è½½å™¨ã€‚
2. ä½¿ç”¨`BaseBlobParser`åˆ›å»ºè§£æå™¨ï¼Œå¹¶å°†å…¶ä¸`Blob`å’Œ`BlobLoaders`ä¸€èµ·ä½¿ç”¨ã€‚è¿™åœ¨å¤„ç†æ–‡ä»¶æ—¶éå¸¸æœ‰ç”¨ã€‚

## æ ‡å‡†æ–‡æ¡£åŠ è½½å™¨

æ–‡æ¡£åŠ è½½å™¨å¯é€šè¿‡ä»`BaseLoader`ç»§æ‰¿å®ç°ï¼Œåè€…æä¾›äº†åŠ è½½æ–‡æ¡£çš„æ ‡å‡†æ¥å£ã€‚

### æ¥å£

| æ–¹æ³•å      | è§£é‡Š        |
|-------------|-------------|
| lazy_load   | ç”¨äº**æƒ°æ€§**é€ä¸ªåŠ è½½æ–‡æ¡£ã€‚ç”¨äºç”Ÿäº§ä»£ç ã€‚ |
| alazy_load  | `lazy_load`çš„å¼‚æ­¥å˜ä½“ |
| load        | ç”¨äº**æ€¥æ€§**åŠ è½½æ‰€æœ‰æ–‡æ¡£åˆ°å†…å­˜ä¸­ã€‚ç”¨äºåŸå‹è®¾è®¡æˆ–äº¤äº’å·¥ä½œã€‚ |
| aload       | ç”¨äº**æ€¥æ€§**åŠ è½½æ‰€æœ‰æ–‡æ¡£åˆ°å†…å­˜ä¸­ã€‚ç”¨äºåŸå‹è®¾è®¡æˆ–äº¤äº’å·¥ä½œã€‚ **æ·»åŠ äºLangChainçš„2024å¹´04æœˆ**ã€‚ |

- `load`æ–¹æ³•ä»…é€‚ç”¨äºåŸå‹è®¾è®¡å·¥ä½œ - å®ƒåªè°ƒç”¨`list(self.lazy_load())`ã€‚
- `alazy_load`æœ‰ä¸€ä¸ªé»˜è®¤å®ç°ï¼Œä¼šå§”æ‰˜ç»™`lazy_load`ã€‚å¦‚æœæ‚¨ä½¿ç”¨å¼‚æ­¥æ“ä½œï¼Œå»ºè®®é‡å†™é»˜è®¤å®ç°å¹¶æä¾›æœ¬æœºå¼‚æ­¥å®ç°ã€‚

::: âš âš âš 
åœ¨å®ç°æ–‡æ¡£åŠ è½½å™¨æ—¶ï¼Œ**ä¸è¦**é€šè¿‡`lazy_load`æˆ–`alazy_load`æ–¹æ³•ä¼ é€’å‚æ•°ã€‚
é¢„æœŸæ‰€æœ‰é…ç½®é€šè¿‡åˆå§‹åŒ–ç¨‹åºï¼ˆ__init__ï¼‰ä¼ é€’ã€‚è¿™æ˜¯LangChainçš„è®¾è®¡é€‰æ‹©ï¼Œä»¥ç¡®ä¿ä¸€æ—¦å®ä¾‹åŒ–æ–‡æ¡£åŠ è½½å™¨ï¼Œå°±ä¼šå…·æœ‰åŠ è½½æ–‡æ¡£æ‰€éœ€çš„æ‰€æœ‰ä¿¡æ¯ã€‚
:::

### å®ç°

è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ ‡å‡†æ–‡æ¡£åŠ è½½å™¨çš„ç¤ºä¾‹ï¼Œè¯¥åŠ è½½å™¨ä¼šè¯»å–æ–‡ä»¶ï¼Œå¹¶ä¸ºæ–‡ä»¶ä¸­çš„æ¯ä¸€è¡Œåˆ›å»ºä¸€ä¸ªæ–‡æ¡£ã€‚


```python
from typing import AsyncIterator, Iterator

from langchain_core.document_loaders import BaseLoader
from langchain_core.documents import Document


class CustomDocumentLoader(BaseLoader):
    """è¯»å–æ–‡ä»¶çš„ç¤ºä¾‹æ–‡æ¡£åŠ è½½å™¨ï¼Œæ¯è¡Œåˆ›å»ºä¸€ä¸ªæ–‡æ¡£ã€‚"""

    def __init__(self, file_path: str) -> None:
        """ä½¿ç”¨æ–‡ä»¶è·¯å¾„åˆå§‹åŒ–åŠ è½½å™¨ã€‚

        Args:
            file_path: è¦åŠ è½½çš„æ–‡ä»¶çš„è·¯å¾„ã€‚
        """
        self.file_path = file_path

    def lazy_load(self) -> Iterator[Document]:  # <-- ä¸å¸¦ä»»ä½•å‚æ•°
        """é€è¡Œè¯»å–æ–‡ä»¶çš„æ‡’åŠ è½½å™¨ã€‚

        åœ¨å®ç°æƒ°æ€§åŠ è½½æ–¹æ³•æ—¶ï¼Œåº”ä½¿ç”¨ç”Ÿæˆå™¨é€ä¸ªç”Ÿæˆæ–‡æ¡£ã€‚
        """
        with open(self.file_path, encoding="utf-8") as f:
            line_number = 0
            for line in f:
                yield Document(
                    page_content=line,
                    metadata={"line_number": line_number, "source": self.file_path},
                )
                line_number += 1

    # alazy_loadæ˜¯å¯é€‰çš„ã€‚
    # å¦‚æœçœç•¥å®ç°ï¼Œåˆ™å°†ä½¿ç”¨ä¸€ä¸ªå§”æ‰˜ç»™lazy_loadçš„é»˜è®¤å®ç°ï¼
    async def alazy_load(
        self,
    ) -> AsyncIterator[Document]:  # <-- ä¸å¸¦ä»»ä½•å‚æ•°
        """é€è¡Œè¯»å–æ–‡ä»¶çš„å¼‚æ­¥æ‡’åŠ è½½å™¨ã€‚"""
        # éœ€è¦aiofiles
        # ä½¿ç”¨ `pip install aiofiles` å®‰è£…
        # https://github.com/Tinche/aiofiles
        import aiofiles

        async with aiofiles.open(self.file_path, encoding="utf-8") as f:
            line_number = 0
            async for line in f:
                yield Document(
                    page_content=line,
                    metadata={"line_number": line_number, "source": self.file_path},
                )
                line_number += 1
```

### æµ‹è¯• ğŸ§ª

è¦æµ‹è¯•æ–‡æ¡£åŠ è½½å™¨ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªåŒ…å«ä¸€äº›ä¼˜è´¨å†…å®¹çš„æ–‡ä»¶ã€‚


```python
with open("./meow.txt", "w", encoding="utf-8") as f:
    quality_content = "meow meowğŸ± \n meow meowğŸ± \n meowğŸ˜»ğŸ˜»"
    f.write(quality_content)

loader = CustomDocumentLoader("./meow.txt")
```


```python
## æµ‹è¯•æ‡’åŠ è½½æ¥å£
for doc in loader.lazy_load():
    print()
    print(type(doc))
    print(doc)
```

    
    <class 'langchain_core.documents.base.Document'>
    page_content='meow meowğŸ± \n' metadata={'line_number': 0, 'source': './meow.txt'}
    
    <class 'langchain_core.documents.base.Document'>
    page_content=' meow meowğŸ± \n' metadata={'line_number': 1, 'source': './meow.txt'}
    
    <class 'langchain_core.documents.base.Document'>
    page_content=' meowğŸ˜»ğŸ˜»' metadata={'line_number': 2, 'source': './meow.txt'}
    


```python
## æµ‹è¯•å¼‚æ­¥å®ç°
async for doc in loader.alazy_load():
    print()
    print(type(doc))
    print(doc)
```

    
    <class 'langchain_core.documents.base.Document'>
    page_content='meow meowğŸ± \n' metadata={'line_number': 0, 'source': './meow.txt'}
    
    <class 'langchain_core.documents.base.Document'>
    page_content=' meow meowğŸ± \n' metadata={'line_number': 1, 'source': './meow.txt'}
    
    <class 'langchain_core.documents.base.Document'>
    page_content=' meowğŸ˜»ğŸ˜»' metadata={'line_number': 2, 'source': './meow.txt'}
    

::: {.callout-tip}

`load()`åœ¨è¯¸å¦‚jupyterç¬”è®°æœ¬ä¹‹ç±»çš„äº¤äº’ç¯å¢ƒä¸­å¾ˆæœ‰ç”¨ã€‚

é¿å…ç”¨äºç”Ÿäº§ä»£ç ï¼Œå› ä¸ºæ€¥æ€§åŠ è½½å‡å®šæ‰€æœ‰å†…å®¹éƒ½å¯ä»¥é€‚åˆå†…å­˜ï¼Œè€Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼ˆç‰¹åˆ«æ˜¯ä¼ä¸šæ•°æ®ï¼‰ï¼Œæƒ…å†µå¹¶éæ€»æ˜¯å¦‚æ­¤ã€‚
:::


```python
loader.load()
```




    [Document(page_content='meow meowğŸ± \n', metadata={'line_number': 0, 'source': './meow.txt'}),
     Document(page_content=' meow meowğŸ± \n', metadata={'line_number': 1, 'source': './meow.txt'}),
     Document(page_content=' meowğŸ˜»ğŸ˜»', metadata={'line_number': 2, 'source': './meow.txt'})]



## ä½¿ç”¨æ–‡ä»¶

è®¸å¤šæ–‡æ¡£åŠ è½½å™¨æ¶‰åŠè§£ææ–‡ä»¶ã€‚è¿™äº›åŠ è½½å™¨ä¹‹é—´çš„åŒºåˆ«é€šå¸¸åœ¨äºå¦‚ä½•è§£ææ–‡ä»¶è€Œä¸æ˜¯å¦‚ä½•åŠ è½½æ–‡ä»¶ã€‚ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨`open`è¯»å–PDFæ–‡ä»¶æˆ–æ ‡è®°æ–‡ä»¶çš„äºŒè¿›åˆ¶å†…å®¹ï¼Œä½†æ‚¨éœ€è¦ä¸åŒçš„è§£æé€»è¾‘å°†äºŒè¿›åˆ¶æ•°æ®è½¬æ¢ä¸ºæ–‡æœ¬ã€‚

å› æ­¤ï¼Œå°†è§£æé€»è¾‘ä¸åŠ è½½é€»è¾‘åˆ†ç¦»å¯èƒ½éå¸¸æœ‰ç”¨ï¼Œè¿™æ ·ä¸€æ¥ï¼Œæ— è®ºæ•°æ®å¦‚ä½•åŠ è½½ï¼Œéƒ½å¯ä»¥æ›´å®¹æ˜“åœ°é‡ç”¨ç»™å®šçš„è§£æå™¨ã€‚

### BaseBlobParser

`BaseBlobParser`æ˜¯ä¸€ä¸ªæ¥å£ï¼Œæ¥å—ä¸€ä¸ª`blob`å¹¶è¾“å‡ºä¸€ä¸ª`Document`å¯¹è±¡åˆ—è¡¨ã€‚`blob`æ˜¯ä¸€ä¸ªè¡¨ç¤ºæ•°æ®çš„å®ä½“ï¼Œå¯ä»¥åœ¨å†…å­˜ä¸­æˆ–æ–‡ä»¶ä¸­å­˜åœ¨ã€‚LangChain pythonå…·æœ‰`Blob`åŸè¯­ï¼Œå—[Blob WebAPIè§„èŒƒ](https://developer.mozilla.org/zh-CN/docs/Web/API/Blob)çš„å¯å‘ã€‚

```python
from langchain_core.document_loaders import BaseBlobParser, Blob

class MyParser(BaseBlobParser):
    """ä¸€ä¸ªå°†æ¯è¡Œè½¬æ¢ä¸ºæ–‡æ¡£çš„ç®€å•è§£æå™¨ã€‚"""

    def lazy_parse(self, blob: Blob) -> Iterator[Document]:
        """å°†ä¸€ä¸ªblobé€è¡Œè§£æä¸ºæ–‡æ¡£ã€‚"""
        line_number = 0
        with blob.as_bytes_io() as f:
            for line in f:
                line_number += 1
                yield Document(
                    page_content=line,
                    metadata={"line_number": line_number, "source": blob.source},
                )
```

ä½¿ç”¨**blob** APIè¿˜å…è®¸ä»å†…å­˜ç›´æ¥åŠ è½½å†…å®¹ï¼Œè€Œæ— éœ€ä»æ–‡ä»¶ä¸­è¯»å–ï¼

```python
blob = Blob.from_path("./meow.txt")
parser = MyParser()
```


```python
list(parser.lazy_parse(blob))
```




    [Document(page_content='meow meowğŸ± \n', metadata={'line_number': 1, 'source': './meow.txt'}),
     Document(page_content=' meow meowğŸ± \n', metadata={'line_number': 2, 'source': './meow.txt'}),
     Document(page_content=' meowğŸ˜»ğŸ˜»', metadata={'line_number': 3, 'source': './meow.txt'})]



ä½¿ç”¨**blob** APIè¿˜å¯ä»¥ç›´æ¥ä»å†…å­˜åŠ è½½å†…å®¹ï¼Œè€Œæ— éœ€ä»æ–‡ä»¶ä¸­è¯»å–ï¼

```python
blob = Blob(data=b"some data from memory\nmeow")
list(parser.lazy_parse(blob))
```




    [Document(page_content='some data from memory\n', metadata={'line_number': 1, 'source': None}),
     Document(page_content='meow', metadata={'line_number': 2, 'source': None})=======

                

### Blob

è®©æˆ‘ä»¬ç®€è¦åœ°æµè§ˆä¸€ä¸‹ Blob API çš„ä¸€äº›å†…å®¹ã€‚

```python
blob = Blob.from_path("./meow.txt", metadata={"foo": "bar"})
```

```python
blob.encoding
```

'utf-8'

```python
blob.as_bytes()
```

b'meow meow\xf0\x9f\x90\xb1 \n meow meow\xf0\x9f\x90\xb1 \n meow\xf0\x9f\x98\xbb\xf0\x9f\x98\xbb'

```python
blob.as_string()
```

'meow meowğŸ± \n meow meowğŸ± \n meowğŸ˜»ğŸ˜»'

```python
blob.as_bytes_io()
```

<contextlib._GeneratorContextManager at 0x743f34324450>

```python
blob.metadata
```

{'foo': 'bar'}

```python
blob.source
```

'./meow.txt'

### Blob Loaders

è™½ç„¶è§£æå™¨å°è£…äº†å°†äºŒè¿›åˆ¶æ•°æ®è§£æä¸ºæ–‡æ¡£æ‰€éœ€çš„é€»è¾‘ï¼Œä½†æ˜¯ *blob loaders* å°è£…äº†ä»ç»™å®šå­˜å‚¨ä½ç½®åŠ è½½ blob æ‰€éœ€çš„é€»è¾‘ã€‚

ç›®å‰ï¼Œ `LangChain` ä»…æ”¯æŒ `FileSystemBlobLoader`ã€‚

æ‚¨å¯ä»¥ä½¿ç”¨ `FileSystemBlobLoader` æ¥åŠ è½½ blobï¼Œç„¶åä½¿ç”¨è§£æå™¨å¯¹å…¶è¿›è¡Œè§£æã€‚

```python
from langchain_community.document_loaders.blob_loaders import FileSystemBlobLoader

blob_loader = FileSystemBlobLoader(path=".", glob="*.mdx", show_progress=True)
```

```python
parser = MyParser()
for blob in blob_loader.yield_blobs():
    for doc in parser.lazy_parse(blob):
        print(doc)
        break
```
```
0%|          | 0/8 [00:00<?, ?it/s]

page_content='# Microsoft Office\n' metadata={'line_number': 1, 'source': 'office_file.mdx'}
page_content='# Markdown\n' metadata={'line_number': 1, 'source': 'markdown.mdx'}
page_content='# JSON\n' metadata={'line_number': 1, 'source': 'json.mdx'}
page_content='---\n' metadata={'line_number': 1, 'source': 'pdf.mdx'}
page_content='---\n' metadata={'line_number': 1, 'source': 'index.mdx'}
page_content='# File Directory\n' metadata={'line_number': 1, 'source': 'file_directory.mdx'}
page_content='# CSV\n' metadata={'line_number': 1, 'source': 'csv.mdx'}
page_content='# HTML\n' metadata={'line_number': 1, 'source': 'html.mdx'}
```

### Generic Loader

LangChain åœ¨ `GenericLoader` ä¸­ç»„åˆäº† `BlobLoader` å’Œ `BaseBlobParser` çš„æŠ½è±¡ã€‚

`GenericLoader` æ—¨åœ¨æä¾›æ ‡å‡†åŒ–çš„ç±»æ–¹æ³•ï¼Œä½¿ä½¿ç”¨ç°æœ‰çš„ `BlobLoader` å®ç°å˜å¾—å®¹æ˜“ã€‚ç›®å‰ï¼Œåªæ”¯æŒ `FileSystemBlobLoader`ã€‚

```python
from langchain_community.document_loaders.generic import GenericLoader

loader = GenericLoader.from_filesystem(
    path=".", glob="*.mdx", show_progress=True, parser=MyParser()
)

for idx, doc in enumerate(loader.lazy_load()):
    if idx < 5:
        print(doc)

print("... output truncated for demo purposes")
```
```
0%|          | 0/8 [00:00<?, ?it/s]

page_content='# Microsoft Office\n' metadata={'line_number': 1, 'source': 'office_file.mdx'}
page_content='\n' metadata={'line_number': 2, 'source': 'office_file.mdx'}
page_content='>[The Microsoft Office](https://www.office.com/) suite of productivity software includes Microsoft Word, Microsoft Excel, Microsoft PowerPoint, Microsoft Outlook, and Microsoft OneNote. It is available for Microsoft Windows and macOS operating systems. It is also available on Android and iOS.\n' metadata={'line_number': 3, 'source': 'office_file.mdx'}
page_content='\n' metadata={'line_number': 4, 'source': 'office_file.mdx'}
page_content='This covers how to load commonly used file formats including `DOCX`, `XLSX` and `PPTX` documents into a document format that we can use downstream.\n' metadata={'line_number': 5, 'source': 'office_file.mdx'}
... output truncated for demo purposes
```

#### Custom Generic Loader

å¦‚æœæ‚¨å–œæ¬¢åˆ›å»ºç±»ï¼Œå¯ä»¥åˆ›å»ºä¸€ä¸ªç±»æ¥å°è£…ä¸€èµ·çš„é€»è¾‘ã€‚

æ‚¨å¯ä»¥ä»è¿™ä¸ªç±»ç»§æ‰¿ä»¥ä½¿ç”¨ç°æœ‰çš„åŠ è½½å™¨åŠ è½½å†…å®¹ã€‚

```python
from typing import Any


class MyCustomLoader(GenericLoader):
    @staticmethod
    def get_parser(**kwargs: Any) -> BaseBlobParser:
        """Override this method to associate a default parser with the class."""
        return MyParser()
```

```python
loader = MyCustomLoader.from_filesystem(path=".", glob="*.mdx", show_progress=True)

for idx, doc in enumerate(loader.lazy_load()):
    if idx < 5:
        print(doc)

print("... output truncated for demo purposes")
```
```
0%|          | 0/8 [00:00<?, ?it/s]

page_content='# Microsoft Office\n' metadata={'line_number': 1, 'source': 'office_file.mdx'}
page_content='\n' metadata={'line_number': 2, 'source': 'office_file.mdx'}
page_content='>[The Microsoft Office](https://www.office.com/) suite of productivity software includes Microsoft Word, Microsoft Excel, Microsoft PowerPoint, Microsoft Outlook, and Microsoft OneNote. It is available for Microsoft Windows and macOS operating systems. It is also available on Android and iOS.\n' metadata={'line_number': 3, 'source': 'office_file.mdx'}
page_content='\n' metadata={'line_number': 4, 'source': 'office_file.mdx'}
page_content='This covers how to load commonly used file formats including `DOCX`, `XLSX` and `PPTX` documents into a document format that we can use downstream.\n' metadata={'line_number': 5, 'source': 'office_file.mdx'}
... output truncated for demo purposes# è‡ªå®šä¹‰è¾“å‡ºè§£æå™¨
```

åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæ‚¨å¯èƒ½å¸Œæœ›å®ç°ä¸€ä¸ªè‡ªå®šä¹‰è§£æå™¨ï¼Œä»¥å°†æ¨¡å‹è¾“å‡ºç»“æ„åŒ–ä¸ºè‡ªå®šä¹‰æ ¼å¼ã€‚

å®ç°è‡ªå®šä¹‰è§£æå™¨æœ‰ä¸¤ç§æ–¹å¼ï¼š

1. åœ¨ LCEL ä¸­ä½¿ç”¨ `RunnableLambda` æˆ– `RunnableGenerator` -- æˆ‘ä»¬å¼ºçƒˆæ¨èåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ä½¿ç”¨è¿™ç§æ–¹å¼
2. é€šè¿‡ç»§æ‰¿åŸºç±»ä¹‹ä¸€æ¥å®ç°è§£æå™¨ -- è¿™æ˜¯ä¸€ç§æ¯”è¾ƒå›°éš¾çš„æ–¹å¼

è¿™ä¸¤ç§æ–¹å¼çš„åŒºåˆ«ä¸»è¦åœ¨äºè§¦å‘çš„å›è°ƒæ–¹å¼ï¼ˆä¾‹å¦‚ `on_chain_start` ä¸ `on_parser_start`ï¼‰ï¼Œä»¥åŠå¯è¿½è¸ªå¹³å°ä¸­åƒ LangSmith è¿™æ ·çš„å¯è¿è¡Œ lambda ä¸è§£æå™¨çš„å¯è§†åŒ–æ–¹å¼ã€‚

## å¯è¿è¡Œçš„ Lambda å’Œç”Ÿæˆå™¨

æ¨èçš„è§£ææ–¹å¼æ˜¯ä½¿ç”¨ **å¯è¿è¡Œçš„ lambda** å’Œ **å¯è¿è¡Œçš„ç”Ÿæˆå™¨**ï¼

è¿™é‡Œï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªç®€å•çš„è§£æå™¨ï¼Œå°†æ¨¡å‹è¾“å‡ºçš„å¤§å°å†™é¢ å€’ã€‚

ä¾‹å¦‚ï¼Œå¦‚æœæ¨¡å‹è¾“å‡ºä¸ºï¼šâ€œå–µâ€ï¼Œåˆ™è§£æå™¨å°†ç”Ÿæˆâ€œmEOWâ€ã€‚

```python
from typing import Iterable

from langchain_anthropic.chat_models import ChatAnthropic
from langchain_core.messages import AIMessage, AIMessageChunk

model = ChatAnthropic(model_name="claude-2.1")

def parse(ai_message: AIMessage) -> str:
    """è§£æ AI æ¶ˆæ¯ã€‚"""
    return ai_message.content.swapcase()

chain = model | parse
chain.invoke("hello")
```

    'hELLO!'

:::âš âš âš 



LCEL åœ¨ä½¿ç”¨ `|` è¯­æ³•è¿›è¡Œç»„åˆæ—¶ï¼Œä¼šè‡ªåŠ¨å°†å‡½æ•° `parse` å‡çº§ä¸º `RunnableLambda(parse)`ã€‚

å¦‚æœä½ ä¸å–œæ¬¢è¿™ç§æ–¹å¼ï¼Œä½ å¯ä»¥æ‰‹åŠ¨å¯¼å…¥ `RunnableLambda`ï¼Œç„¶åè¿è¡Œ `parse = RunnableLambda(parse)`ã€‚
:::

æµå¼å·¥ä½œå—ï¼Ÿ

```python
for chunk in chain.stream("tell me about yourself in one sentence"):
    print(chunk, end="|", flush=True)
```

    i'M cLAUDE, AN ai ASSISTANT CREATED BY aNTHROPIC TO BE HELPFUL, HARMLESS, AND HONEST!|

ä¸è¡Œï¼Œå› ä¸ºè§£æå™¨ä¼šåœ¨è§£æè¾“å‡ºä¹‹å‰èšåˆè¾“å…¥ã€‚

å¦‚æœæˆ‘ä»¬æƒ³è¦å®ç°æµå¼è§£æå™¨ï¼Œå¯ä»¥ä½¿è§£æå™¨æ¥å—è¾“å…¥çš„å¯è¿­ä»£å¯¹è±¡ï¼Œå¹¶åœ¨ç»“æœå¯ç”¨æ—¶ç”Ÿæˆç»“æœã€‚

```python
from langchain_core.runnables import RunnableGenerator

def streaming_parse(chunks: Iterable[AIMessageChunk]) -> Iterable[str]:
    for chunk in chunks:
        yield chunk.content.swapcase()

streaming_parse = RunnableGenerator(streaming_parse)
```

:::âš âš âš 



è¯·å°†æµå¼è§£æå™¨åŒ…è£…åœ¨ `RunnableGenerator` ä¸­ï¼Œå› ä¸ºæˆ‘ä»¬å¯èƒ½ä¸å†è‡ªåŠ¨ä½¿ç”¨ `|` è¯­æ³•å‡çº§å®ƒã€‚
:::

```python
chain = model | streaming_parse
chain.invoke("hello")
```

    'hELLO!'

è®©æˆ‘ä»¬ç¡®è®¤ä¸€ä¸‹æµå¼å·¥ä½œï¼

```python
for chunk in chain.stream("tell me about yourself in one sentence"):
        print(chunk, end="|", flush=True)
```

    i|'M| cLAUDE|,| AN| ai| ASSISTANT| CREATED| BY| aN|THROP|IC| TO| BE| HELPFUL|,| HARMLESS|,| AND| HONEST|.!|

## ç»§æ‰¿è§£æåŸºç±»

å¦ä¸€ç§å®ç°è§£æå™¨çš„æ–¹æ³•æ˜¯é€šè¿‡ç»§æ‰¿ `BaseOutputParser`ã€`BaseGenerationOutputParser` æˆ–å…¶ä»–ä¸€ä¸ªåŸºæœ¬è§£æå™¨ä¸­çš„ç±»ï¼Œå…·ä½“å–å†³äºæ‚¨éœ€è¦åšä»€ä¹ˆã€‚

ä¸€èˆ¬æ¥è¯´ï¼Œ**æˆ‘ä»¬ä¸å»ºè®®**ä½¿ç”¨è¿™ç§æ–¹å¼ï¼Œå› ä¸ºè¿™æ ·ä¼šå¯¼è‡´æ›´å¤šéœ€è¦ç¼–å†™çš„ä»£ç ï¼Œè€Œä¸”å¹¶æ²¡æœ‰æ˜¾è‘—çš„å¥½å¤„ã€‚

æœ€ç®€å•çš„è¾“å‡ºè§£æå™¨æ‰©å±•äº† `BaseOutputParser` ç±»ï¼Œå¹¶ä¸”å¿…é¡»å®ç°ä»¥ä¸‹æ–¹æ³•ï¼š

* `parse`ï¼šæ¥æ”¶æ¨¡å‹çš„å­—ç¬¦ä¸²è¾“å‡ºå¹¶å¯¹å…¶è¿›è¡Œè§£æ
* ï¼ˆå¯é€‰ï¼‰`_type`ï¼šæ ‡è¯†è§£æå™¨çš„åç§°

å½“èŠå¤©æ¨¡å‹æˆ– LLM çš„è¾“å‡ºæ ¼å¼ä¸æ­£ç¡®æ—¶ï¼Œå¯ä»¥æŠ›å‡º `OutputParserException` æ¥æŒ‡ç¤ºè§£æå¤±è´¥æ˜¯ç”±äºé”™è¯¯çš„è¾“å…¥ã€‚ä½¿ç”¨æ­¤å¼‚å¸¸å¯ä»¥è®©åˆ©ç”¨è§£æå™¨çš„ä»£ç ä»¥ä¸€è‡´çš„æ–¹å¼å¤„ç†å¼‚å¸¸ã€‚

:::âš âš âš 

 è§£æå™¨ä¹Ÿæ˜¯å¯è¿è¡Œçš„ï¼ğŸƒ

ç”±äº `BaseOutputParser` å®ç°äº† `Runnable` æ¥å£ï¼Œæ‚¨é€šè¿‡è¿™ç§æ–¹å¼åˆ›å»ºçš„ä»»ä½•è‡ªå®šä¹‰è§£æå™¨éƒ½å°†æˆä¸ºæœ‰æ•ˆçš„ LangChain å¯è¿è¡Œå¯¹è±¡ï¼Œå¹¶ä¸”å°†ä»è‡ªåŠ¨å¼‚æ­¥æ”¯æŒã€æ‰¹å¤„ç†æ¥å£ã€æ—¥å¿—æ”¯æŒç­‰ä¸­å—ç›Šã€‚
:::

### ç®€å•è§£æå™¨

è¿™æ˜¯ä¸€ä¸ªç®€å•çš„è§£æå™¨ï¼Œå¯ä»¥è§£æè¡¨ç¤ºå¸ƒå°”å€¼çš„ **å­—ç¬¦ä¸²**ï¼ˆä¾‹å¦‚ `YES` æˆ– `NO`ï¼‰å¹¶å°†å…¶è½¬æ¢ä¸ºç›¸åº”çš„ `boolean` ç±»å‹ã€‚

```python
from langchain_core.exceptions import OutputParserException
from langchain_core.output_parsers import BaseOutputParser

# [bool] æè¿°äº†ä¸€ä¸ªæ³›å‹çš„å‚æ•°åŒ–ã€‚
# è¿™åŸºæœ¬ä¸Šè¡¨ç¤º parse çš„è¿”å›ç±»å‹ï¼Œå³ True æˆ– False
class BooleanOutputParser(BaseOutputParser[bool]):
    """è‡ªå®šä¹‰å¸ƒå°”è§£æå™¨ã€‚"""

    true_val: str = "YES"
    false_val: str = "NO"

    def parse(self, text: str) -> bool:
        cleaned_text = text.strip().upper()
        if cleaned_text not in (self.true_val.upper(), self.false_val.upper()):
            raise OutputParserException(
                f"BooleanOutputParser æœŸæœ›è¾“å‡ºå€¼ä¸º "
                f"{self.true_val} æˆ– {self.false_val}ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰ã€‚ "
                f"æ¥æ”¶åˆ° {cleaned_text}ã€‚"
            )
        return cleaned_text == self.true_val.upper()

    @property
    def _type(self) -> str:
        return "boolean_output_parser"
```

```python
parser = BooleanOutputParser()
parser.invoke("YES")
```

    True

```python
try:
    parser.invoke("MEOW")
except Exception as e:
    print(f"è§¦å‘äº† {type(e)} ç±»å‹çš„å¼‚å¸¸")
```

    è§¦å‘äº† <class 'langchain_core.exceptions.OutputParserException'> ç±»å‹çš„å¼‚å¸¸

è®©æˆ‘ä»¬æµ‹è¯•ä¸€ä¸‹æ›´æ”¹å‚æ•°åŒ–æ˜¯å¦æœ‰æ•ˆ

```python
parser = BooleanOutputParser(true_val="OKAY")
parser.invoke("OKAY")
```

    True

è®©æˆ‘ä»¬ç¡®è®¤å…¶ä»– LCEL æ–¹æ³•æ˜¯å¦å­˜åœ¨

```python
parser.batch(["OKAY", "NO"])
```

    [True, False]

```python
await parser.abatch(["OKAY", "NO"])
```

    [True, False]

```python
from langchain_anthropic.chat_models import ChatAnthropic

anthropic = ChatAnthropic(model_name="claude-2.1")
anthropic.invoke("say OKAY or NO")
```

    AIMessage(content='OKAY')

è®©æˆ‘ä»¬æµ‹è¯•ä¸€ä¸‹æˆ‘ä»¬çš„è§£æå™¨æ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œï¼

```python
chain = anthropic | parser
chain.invoke("say OKAY or NO")
```

    True

:::{.callout-note}
è§£æå™¨å¯ä»¥å¤„ç† LLM çš„è¾“å‡ºï¼ˆå­—ç¬¦ä¸²ï¼‰æˆ–èŠå¤©æ¨¡å‹çš„è¾“å‡ºï¼ˆ`AIMessage`ï¼‰ï¼
:::

### è§£æåŸå§‹æ¨¡å‹è¾“å‡º

æœ‰æ—¶é™¤äº†åŸå§‹æ–‡æœ¬ä¹‹å¤–ï¼Œè¿˜æœ‰ä¸€äº›é‡è¦çš„æ¨¡å‹è¾“å‡ºå…ƒæ•°æ®ã€‚ä¸€ä¸ªä¾‹å­æ˜¯å·¥å…·è°ƒç”¨ï¼Œå…¶ä¸­ç”¨äºä¼ é€’ç»™è°ƒç”¨å‡½æ•°çš„å‚æ•°è¢«è¿”å›åˆ°ä¸€ä¸ªå•ç‹¬çš„å±æ€§ä¸­ã€‚å¦‚æœæ‚¨éœ€è¦è¿™ç§æ›´ç²¾ç»†çš„æ§åˆ¶ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç»§æ‰¿`BaseGenerationOutputParser`ç±»ã€‚

è¿™ä¸ªç±»éœ€è¦ä¸€ä¸ªåä¸º`parse_result`çš„æ–¹æ³•ã€‚è¿™ä¸ªæ–¹æ³•æ¥å—åŸå§‹æ¨¡å‹è¾“å‡ºï¼ˆä¾‹å¦‚ï¼Œ`Generation`æˆ–`ChatGeneration`çš„åˆ—è¡¨ï¼‰å¹¶è¿”å›è§£æåçš„è¾“å‡ºã€‚

æ”¯æŒ`Generation`å’Œ`ChatGeneration`ä¸¤ç§ç±»å‹ï¼Œä½¿è§£æå™¨å¯ä»¥åŒæ—¶ä¸æ™®é€šè¯­è¨€æ¨¡å‹å’ŒèŠå¤©æ¨¡å‹ä¸€èµ·ä½¿ç”¨ã€‚

```python
from typing import List

from langchain_core.exceptions import OutputParserException
from langchain_core.messages import AIMessage
from langchain_core.output_parsers import BaseGenerationOutputParser
from langchain_core.outputs import ChatGeneration, Generation


class StrInvertCase(BaseGenerationOutputParser[str]):
    """ä¸€ä¸ªç¤ºä¾‹è§£æå™¨ï¼Œç¿»è½¬æ¶ˆæ¯ä¸­å­—ç¬¦çš„å¤§å°å†™ã€‚

    è¿™æ˜¯ä¸€ä¸ªæ¼”ç¤ºç¤ºä¾‹ï¼Œç›®çš„æ˜¯å±•ç¤ºç®€å•ã€‚
    """

    def parse_result(self, result: List[Generation], *, partial: bool = False) -> str:
        """å°†æ¨¡å‹ç”Ÿæˆçš„ç»“æœè§£ææˆç‰¹å®šæ ¼å¼çš„æ–¹æ³•ã€‚

        å‚æ•°:
            result: ä¸€ä¸ªå¾…è§£æçš„Generationåˆ—è¡¨ã€‚å‡å®šè¿™äº›Generationæ˜¯ç”¨äºå•ä¸ªæ¨¡å‹è¾“å…¥çš„ä¸åŒå€™é€‰è¾“å‡ºã€‚
                    è®¸å¤šè§£æå™¨å‡å®šåªä¼ å…¥ä¸€ä¸ªå•ä¸€ç”Ÿæˆã€‚
                    æˆ‘ä»¬ä¼šå¯¹æ­¤è¿›è¡Œæ–­è¨€
            partial: æ˜¯å¦å…è®¸éƒ¨åˆ†ç»“æœã€‚è¿™ç”¨äºæ”¯æŒæµå¼å¤„ç†çš„è§£æå™¨ã€‚
        """
        if len(result) != 1:
            raise NotImplementedError(
                "æ­¤è¾“å‡ºè§£æå™¨åªèƒ½ç”¨äºå•ä¸ªç”Ÿæˆã€‚"
            )
        generation = result[0]
        if not isinstance(generation, ChatGeneration):
            # è¡¨ç¤ºæ­¤è§£æå™¨åªèƒ½ç”¨äºèŠå¤©ç”Ÿæˆ
            raise OutputParserException(
                "æ­¤è¾“å‡ºè§£æå™¨åªèƒ½ç”¨äºèŠå¤©ç”Ÿæˆã€‚"
            )
        return generation.message.content.swapcase()


chain = anthropic | StrInvertCase()
```

è®©æˆ‘ä»¬å°è¯•ä¸€ä¸‹æ–°çš„è§£æå™¨ï¼å®ƒåº”è¯¥ä¼šç¿»è½¬æ¨¡å‹çš„è¾“å‡ºã€‚

```python
chain.invoke("Tell me a short sentence about yourself")
```

'HELLO! MY NAME IS CLAUDE.'


