# è‡ªé—®è‡ªç­”å¸¦æœç´¢

è¿™ä¸ªæ¼”ç¤ºå±•ç¤ºäº†å¸¦æœç´¢ä»£ç†çš„è‡ªé—®è‡ªç­”åŠŸèƒ½ã€‚

```python
from langchain import hub
from langchain.agents import AgentExecutor, create_self_ask_with_search_agent
from langchain_community.llms import Fireworks
from langchain_community.tools.tavily_search import TavilyAnswer
```

## åˆå§‹åŒ–å·¥å…·

æˆ‘ä»¬å°†åˆå§‹åŒ–æˆ‘ä»¬æƒ³è¦ä½¿ç”¨çš„å·¥å…·ã€‚è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å·¥å…·ï¼Œå› ä¸ºå®ƒç»™æˆ‘ä»¬æä¾›äº†**ç­”æ¡ˆ**ï¼ˆè€Œä¸æ˜¯æ–‡æ¡£ï¼‰

å¯¹äºè¿™ä¸ªä»£ç†ï¼Œåªèƒ½ä½¿ç”¨ä¸€ä¸ªå·¥å…·ï¼Œå®ƒéœ€è¦è¢«å‘½åä¸º"Intermediate Answer"ã€‚

```python
tools = [TavilyAnswer(max_results=1, name="Intermediate Answer")]
```

## åˆ›å»ºä»£ç†

```python
# è·å–è¦ä½¿ç”¨çš„æç¤º - æ‚¨å¯ä»¥ä¿®æ”¹è¿™ä¸ªæç¤ºï¼
prompt = hub.pull("hwchase17/self-ask-with-search")
```


```python
# é€‰æ‹©å°†é©±åŠ¨ä»£ç†çš„LLM
llm = Fireworks()

# æ„å»ºè‡ªé—®è‡ªç­”å¸¦æœç´¢ä»£ç†
agent = create_self_ask_with_search_agent(llm, tools, prompt)
```

## è¿è¡Œä»£ç†

```python
# é€šè¿‡ä¼ å…¥ä»£ç†å’Œå·¥å…·æ¥åˆ›å»ºä¸€ä¸ªä»£ç†æ‰§è¡Œå™¨
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
```


```python
agent_executor.invoke(
    {"input": "What is the hometown of the reigning men's U.S. Open champion?"}
)
```

    
    
    [1m> è¿›å…¥æ–°çš„ä»£ç†æ‰§è¡Œå™¨é“¾...[0m
    [32;1m[1;3mæ˜¯çš„ã€‚
    è¿½é—®ï¼šè°æ˜¯ç°ä»»ç¾å›½ç½‘çƒå…¬å¼€èµ›ç”·å•å† å†›ï¼Ÿ[0m[36;1m[1;3mç°ä»»ç¾å›½ç½‘çƒå…¬å¼€èµ›ç”·å•å† å†›æ˜¯è¯ºç“¦å…‹Â·å¾·çº¦ç§‘ç»´å¥‡ã€‚ä»–åœ¨2023å¹´ç¾å›½ç½‘çƒå…¬å¼€èµ›çš„å†³èµ›ä¸­å‡»è´¥ä¸¹å°¼å°”Â·æ¢…å¾·éŸ¦æ°å¤«èµ¢å¾—äº†ä»–çš„ç¬¬24ä¸ªå¤§æ»¡è´¯å•æ‰“å† å†›ã€‚[0m[32;1m[1;3m
    æ‰€ä»¥æœ€ç»ˆç­”æ¡ˆæ˜¯ï¼šè¯ºç“¦å…‹Â·å¾·çº¦ç§‘ç»´å¥‡ã€‚[0m
    
    [1m> å®Œæˆé“¾æ¡ã€‚[0m
    




    {'input': "What is the hometown of the reigning men's U.S. Open champion?",
     'output': 'Novak Djokovic.'}




```python

```