
import Head from 'next/head'

<Head>
  <script>
    {
      `(function() {
         var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?e60fb290e204e04c5cb6f79b0ac1e697";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
       })();`
    }
  </script>
</Head>

![LangChain](https://pica.zhimg.com/50/v2-56e8bbb52aa271012541c1fe1ceb11a2_r.gif)





如何序列化LLM类[#](#how-to-serialize-llm-classes "本标题的永久链接")
======================================================

本教程演示了如何将LLM配置写入磁盘并从磁盘中读取。如果您想保存给定LLM的配置（例如提供程序、温度（temperature）等），则这非常有用。

```python
from langchain.llms import OpenAI
from langchain.llms.loading import load_llm

```

加载[#](#loading "本标题的永久链接")
--------------------------

首先，让我们讨论从磁盘加载LLM。LLMs可以以json或yaml格式保存在磁盘上。无论扩展名如何，它们都以相同的方式加载。

```python
!cat llm.json

```

```python
{
    "model_name": "text-davinci-003",
    "temperature": 0.7,
    "max_tokens": 256,
    "top_p": 1.0,
    "frequency_penalty": 0.0,
    "presence_penalty": 0.0,
    "n": 1,
    "best_of": 1,
    "request_timeout": null,
    "_type": "openai"
}

```

```python
llm = load_llm("llm.json")

```

```python
!cat llm.yaml

```

```python
_type: openai
best_of: 1
frequency_penalty: 0.0
max_tokens: 256
model_name: text-davinci-003
n: 1
presence_penalty: 0.0
request_timeout: null
temperature: 0.7
top_p: 1.0

```

```python
llm = load_llm("llm.yaml")

```

保存[#](#saving "本标题的永久链接")
-------------------------

如果您想从内存中的LLM转换为其序列化版本，可以通过调用`.save`方法轻松完成。同样，它支持json和yaml。

```python
llm.save("llm.json")

```

```python
llm.save("llm.yaml")

```

